[
  {
    "path": "posts/2021-04-18-tcc-jean-carlo/",
    "title": "Análise de Desempenhos na NBA com Regressão Linear",
    "description": "TCC em Regressão Linear - curso-R.",
    "author": [
      {
        "name": "Jean Carlo Nunes da Silva",
        "url": "https://www.linkedin.com/in/jeancarlonds/"
      }
    ],
    "date": "2021-04-18",
    "categories": [],
    "contents": "\n\nContents\nIntrodução\nAnálise Exploratória\nPensando na modelagem\nAprofundando a modelagem com interações\nDiagnóstico do modelo\nConclusão\n\nIntrodução\nA NBA é uma das ligas esportivas mais competitivas do Mundo. O basquete - esporte não tão popular em outros países - faz grande sucesso na região norte das Américas. Além de todo grande investimento e estrutura, a liga também tem uma forte influência dos números. Isso é facilmente notado pelos fãs, pois, em todo jogo, é possível observar a divulgação dos dados históricos e da partida em si. Para quem trabalha com dados, isso se torna ainda mais atrativo.\nDado esse contexto, a principal motivação neste trabalho está, exatamente, em responder questões sobre a forma que as estatísticas do jogo podem (ou não) exercer efeitos sobre os resultados. Para isso, utilizarei regressão linear múltipla para análise das influências das variáveis sobre a variável resposta “teamaprov” - desempenho e aproveitamento das equipes ao longo das temporadas. Pretendo, também, aproveitar das técnicas de interações para aprofundar a análise entre algumas variáveis categóricas - como a separação entre o melhor atleta da temporada e jogadores regulares, o jovem da temporada e os atletas regulares e assim por diante.\nAnálise Exploratória\nPara o trabalho, utilizarei a base de dados denominada “nbadb”. Esse conjunto de informações foi extraído, utilizando técnicas de WebScraping, do portal “basketball-reference”, que organiza um grande acervo de dados sobre o basquete estadunidense. Trata-se de informações das temporadas completas da NBA - princial liga de basquete dos Estados Unidos. Ou seja, contém informações da temporada regular e de playoffs. Para este trabalho, utilizei dados das últimas 30 temporadas (de 1990 até 2020), desconsiderando possíveis desvios contextuais de cada competição (por exemplo, temporadas que tiveram menos jogos, menos participantes e etc.). A base conta com 903 observações e 29 variáveis. Cada linha da base representa os dados de uma equipe em determinada temporada. As variáveis representam estatísticas de jogo das equipes (arremessos, bloqueios, roubadas de bola, faltas e etc.).\nAs variáveis da base\nteam: equipe;\nchampion: equipe foi campeã ou não;\nplayoff: jogador foi pro playoff ou não;\nseason: temporada;\nmvp: teve atleta eleito melhor atleta da temporada ou não;\nroty: teve atleta eleito jovem atleta da temporada ou não;\nage: média de idade dos atletas na temporada;\nmp: média de minutos jogados por jogo pela equipe na temporada;\nwin: vitórias da equipe na temporada;\nloss: derrotas da equipe na temporada;\ng: partidas jogadas pela equipe;\nfg: média de acertos em arremessos por jogo;\nfga: média de tentativas de arremessos por jogo;\nx3p: média de acertos em arremessos de três pontos por jogo;\nx3pa: média de tentativas de arremessos de três pontos por jogo;\nx2p: média de acertos em arremessos de dois pontos por jogo;\nx2pa: média de tentativas de arremessos de dois pontos por jogo;\nft: média de acertos em tiro livre por jogo;\nfta: média de tentativas de tiro livre por jogo;\norb: média de rebotes ofensivos por jogo;\ndrb: média de rebotes defensivos por jogo;\ntrb: média de rebotes por jogo;\nast: média de assistências por jogo;\nstl: média de roubadas de bola por jogo;\nblk: média de bloqueios por jogo;\ntov: média de turnovers por jogo;\npf: média de faltas por jogo;\npts: média de pontos por jogo;\nA tabela abaixo sumariza os dados descritivos para cada uma das variáveis citadas acima:\n\n\nShow code\n\nsumarizacao_nbadb <- nbadb %>%\n  dplyr::select(where(is.numeric)) %>% \n  tidyr::pivot_longer(cols = everything()) %>% \n  dplyr::group_by(name) %>% \n  dplyr::summarise_at(\"value\",\n                      list(\n    minimo = ~min(.),\n    Q1 = ~quantile(., 0.25),\n    med = ~median(.),\n    media = ~mean(.),\n    Q3 = ~quantile(., 0.75),\n    maximo = ~max(.),\n    desvio = ~sd(.))) %>%  \n  dplyr::mutate_if(is.numeric, \n                   format, \n                   digits = 3,\n                   nsmall = 2) \n\ncolnames(sumarizacao_nbadb) <- c('Var', 'Mín', 'Q1', 'Mediana',\n                      'Média', 'Q3', 'Máx',\n                      'Des. Pad.')\n\nkbl(sumarizacao_nbadb, \n    booktabs = T,\n    caption = 'Tabela 1. Estatísticas descritivas das variáveis da base', \n    longtable = F) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 1: Tabela 1. Estatísticas descritivas das variáveis da base\n\n\nVar\n\n\nMín\n\n\nQ1\n\n\nMediana\n\n\nMédia\n\n\nQ3\n\n\nMáx\n\n\nDes. Pad.\n\n\nage\n\n\n23.06\n\n\n25.88\n\n\n26.78\n\n\n26.88\n\n\n27.81\n\n\n31.50\n\n\n1.371\n\n\nast\n\n\n15.64\n\n\n20.82\n\n\n22.17\n\n\n22.41\n\n\n23.87\n\n\n30.38\n\n\n2.272\n\n\nblk\n\n\n2.38\n\n\n4.34\n\n\n4.90\n\n\n4.98\n\n\n5.52\n\n\n8.37\n\n\n0.883\n\n\ndrb\n\n\n24.93\n\n\n29.09\n\n\n30.37\n\n\n30.65\n\n\n31.95\n\n\n42.23\n\n\n2.294\n\n\nfg\n\n\n30.78\n\n\n35.95\n\n\n37.39\n\n\n37.71\n\n\n39.32\n\n\n47.57\n\n\n2.551\n\n\nfga\n\n\n71.22\n\n\n79.73\n\n\n82.38\n\n\n82.68\n\n\n85.55\n\n\n108.15\n\n\n4.075\n\n\nft\n\n\n12.24\n\n\n17.23\n\n\n18.57\n\n\n18.76\n\n\n20.11\n\n\n28.21\n\n\n2.169\n\n\nfta\n\n\n16.57\n\n\n22.98\n\n\n24.68\n\n\n24.90\n\n\n26.71\n\n\n34.85\n\n\n2.849\n\n\ng\n\n\n50.00\n\n\n82.00\n\n\n82.00\n\n\n80.06\n\n\n82.00\n\n\n82.00\n\n\n6.508\n\n\nloss\n\n\n9.00\n\n\n30.00\n\n\n39.00\n\n\n40.03\n\n\n49.00\n\n\n72.00\n\n\n12.936\n\n\nmp\n\n\n240.00\n\n\n241.22\n\n\n241.83\n\n\n241.77\n\n\n242.32\n\n\n244.98\n\n\n0.869\n\n\norb\n\n\n7.65\n\n\n10.61\n\n\n11.70\n\n\n11.83\n\n\n12.88\n\n\n18.54\n\n\n1.763\n\n\npf\n\n\n16.59\n\n\n20.29\n\n\n21.50\n\n\n21.60\n\n\n22.84\n\n\n28.07\n\n\n1.899\n\n\npts\n\n\n81.90\n\n\n95.81\n\n\n99.65\n\n\n100.36\n\n\n104.34\n\n\n119.85\n\n\n6.426\n\n\nseason\n\n\n1990.00\n\n\n1998.00\n\n\n2005.00\n\n\n2005.30\n\n\n2013.00\n\n\n2020.00\n\n\n8.883\n\n\nstl\n\n\n5.54\n\n\n7.16\n\n\n7.80\n\n\n7.86\n\n\n8.48\n\n\n12.84\n\n\n1.008\n\n\nteamapv\n\n\n0.11\n\n\n0.38\n\n\n0.51\n\n\n0.50\n\n\n0.62\n\n\n0.89\n\n\n0.157\n\n\ntov\n\n\n10.71\n\n\n13.42\n\n\n14.22\n\n\n14.31\n\n\n15.20\n\n\n18.46\n\n\n1.311\n\n\ntrb\n\n\n35.63\n\n\n40.99\n\n\n42.35\n\n\n42.48\n\n\n43.89\n\n\n51.70\n\n\n2.131\n\n\nwin\n\n\n7.00\n\n\n30.00\n\n\n41.00\n\n\n40.03\n\n\n50.00\n\n\n73.00\n\n\n12.997\n\n\nx2p\n\n\n23.11\n\n\n29.34\n\n\n30.87\n\n\n31.52\n\n\n32.59\n\n\n43.91\n\n\n3.465\n\n\nx2pa\n\n\n41.90\n\n\n60.65\n\n\n64.32\n\n\n65.21\n\n\n68.32\n\n\n95.23\n\n\n7.461\n\n\nx3p\n\n\n0.45\n\n\n4.16\n\n\n5.93\n\n\n6.19\n\n\n7.74\n\n\n16.13\n\n\n2.766\n\n\nx3pa\n\n\n2.40\n\n\n12.25\n\n\n16.61\n\n\n17.46\n\n\n21.41\n\n\n45.38\n\n\n7.434\n\n\nA tabela permite observar como a variável de interesse da análise (teamapv) possui um desvio padrão de 0.16, com média e mediana bem próximos (respectivamente, 0.50 e 0.51). Também é interessante observar que 25% das equipes somaram, ao menos, 89% de aproveitamento ao longo das temporadas; por outro lado, 25% da primeira faixa dos atletas esteve envolvido em um desempenho de 38% de vitórias. Essas variações respondem a um comportamento comum na liga. Há uma separação marcada entre equipes com mais e menos vitórias, pois, a liga é separada em fases. Da mesma forma, também é comum observar algumas equipes que optam por abrir mão da temporada, esperando melhores condições de escolha de atletas nos drafts das temporadas seguintes. Dessa forma, é importante observar que há uma relação direta entre a classificação na liga e vitórias.\nDe toda forma, Figura 1 exibe o Histograma de vitórias, facilitando a observação de uma curva normal. Assim, mesmo que existam essas nuances em classificações das equipes, é possível observar uma distribuição normal.\n\n\nShow code\n\nnbadb %>% \n  ggplot2::ggplot(aes(x = teamapv, y=..density..)) +\n  ggplot2::geom_histogram(color = \"black\",\n                          fill = \"white\") +\n  geom_density(alpha= .1, fill=\"gray\") +\n  ggplot2::theme_minimal() +\n  labs(\n    y = \"Densidade\",\n    x = \"Aproveitamento das equipes (% de vitórias)\",\n    title = \"Figura 1. Histograma de aproveitamento das equipes\"\n  )\n\n\n\n\nNa figura abaixo (Figura 2), apresento uma matriz de correlação com as possibilidades das variáveis explicativas, recortando as estatísticas de desempenho no jogo. Por meio do gráfico, observa-se que existem variáveis explicativas com alta correlação (muitas aparecem com índice acima de 0.7). Portanto, é importante ter muita atenção com problemas de multicolinearidade. Essa correlação alta entre as variáveis já era esperada, já que, no jogo, existem movimentos que com relação clara. Por exemplo, a variável fg (acertos em arremessos) certamente estaria diretamente associada aos acertos de lances livres (ft), já que são movimentos semelhantes na partida.\n\n\nShow code\n\n#Organiza a tabela para montar a correlação\ncor_nba <- nbadb %>% \n  dplyr::select(\n    -c(age, pts, mp, g, win, loss, season, mvp, roty, teamapv)\n  ) %>% \n  dplyr::select(\n    where(is.numeric)\n  )\n\n#Cria a correlação\ncor_nba <- round(cor(cor_nba), 2)\n\n#Plota a correlação entre as variáveis numéricas\ncorrplot::corrplot(cor_nba,\n                   method = \"square\",\n                   type = \"lower\",\n                   addCoef.col = \"black\",\n                   number.digits = 1,\n                   tl.col = \"black\",\n                   tl.srt = 0,\n                  title = \"\n                  Figura 2. Matriz de correlação entre as variáveis explicativas\")\n\n\n\n\nDessa forma, para observar a relação da variável resposta com as outras variáveis, decidi, através da observação das estatísticas descritivas e em relação ao interesse inicial da hipótese de pesquisa, observar algumas variáveis em específico: acertos em arremessos e tentativas de arremessos (livres(ft e fta), de três pontos (x3p e x3pa), de dois pontos (x2p e x2pa)); roubadas de bola (stl); turnovers (tov); bloqueios (blk), rebotes (trb) e assistências (ast). Também incrementei a análise para média de idade (age) das equipes. Essas opções foram definidas por conterem dados das particularidades do jogo e não necessariamente um indicador que sumariza desempenhos dos atletas (como ações defensivas e ofensivas).\nA Figura 3 ajuda a analisar a relação dois a dois entre a variável resposta e às variáveis explicativas selecionadas.\n\n\nShow code\n\ngraph1 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = ft)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Lances livres\",\n    y = \"% de vitórias\"\n  )\n\ngraph2 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = x3p)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"3 pontos\",\n    y = \"% de vitórias\"\n  )\n\ngraph3 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = x2p)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"2 pontos\",\n    y = \"% de vitórias\"\n  )\n\ngraph4 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = fta)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Tentativas de Lances livres\",\n    y = \"% de vitórias\"\n  )\n\ngraph5 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = x3pa)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Tentativas de 3 pontos\",\n    y = \"% de vitórias\"\n  )\n\ngraph6 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = x2pa)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Tentativas de 2 pontos\",\n    y = \"% de vitórias\"\n  )\n\ngraph7 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = stl)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Roubadas de bola\",\n    y = \"% de vitórias\"\n  )\n\ngraph8 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = tov)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Turnovers\",\n    y = \"% de vitórias\"\n  )\n\ngraph9 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = blk)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Bloqueios\",\n    y = \"% de vitórias\"\n  )\n\ngraph10 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = trb)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Rebotes\",\n    y = \"% de vitórias\"\n  )\n\ngraph11 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = ast)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Assistências\",\n    y = \"% de vitórias\"\n  )\n\n\ngraph12 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = age)) +\n  ggplot2::geom_point() +\n  labs(\n    x = \"Idade\",\n    y = \"% de vitórias\"\n  )\n\ngridExtra::grid.arrange(top = \"Figura 3. Gráficos de dispersão entre variável resposta e variáveis explicativas\",\n                        graph1, \n                        graph2,\n                        graph3,\n                        graph4,\n                        graph5,\n                        graph6,\n                        graph7,\n                        graph8,\n                        graph9,\n                        graph10,\n                        graph11,\n                        graph12,\n                        ncol = 3, \n                        nrow = 4)\n\n\n\n\nObservando os gráficos de dispersão das variáveis explicativas em relação à variável resposta, podemos notar um ponto importante: visualmente, pode-se dizer que existem algumas relações lineares. Mesmo que de forma bastante subjetiva, é possível ter uma primeira análise de que essas variáveis podem surtir efeitos sobre o desempenho das equipes na temporada. Assim, chego a um limite da compreensão visual da relação dos dados. Necessitando, assim, um aprofundamento para a modelagem.\nPensando na modelagem\nDessa forma, realizei o primeiro teste de regressão utilizando a forma mais simples de regressão múltipla. Por isso, optei por analisar as variáveis através do modelo completo de regressão. No caso, observei as estatísticas das ações de jogo como variáveis explicativas da variável resposta aproveitamento.\nNo caso, a fórmula ficou da seguinte maneira:\nteamapv = β0 + β1ft + β2fta + β3x3p + β4x3pa + β5x2p + β6x2pa + β7stl + β8tov + β9blk + β10trb + β11ast + β12age + εi\nO retorno da fórmula pode ser visto na Tabela 2.\n\n\nShow code\n\nmodelo_nba <- nbadb %>% \n  dplyr::select(\n    c(teamapv, ft, fta, x3p, x3pa, x2p, x2pa, stl, tov, blk, trb, ast, age)\n  )\n\n#Organiza a tabela para montar a correlação\nmodelo_nba <- lm(teamapv ~ ., data = modelo_nba)\nsummary(modelo_nba) %>% \n  xtable::xtable() %>% \n  kable(caption = \"Tabela 2. Regressão múltipla com as variáveis das equipes\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 2: Tabela 2. Regressão múltipla com as variáveis das equipes\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n0.0667888\n\n\n0.0903777\n\n\n0.7389969\n\n\n0.4601037\n\n\nft\n\n\n0.0121260\n\n\n0.0031707\n\n\n3.8243588\n\n\n0.0001403\n\n\nfta\n\n\n-0.0055713\n\n\n0.0025952\n\n\n-2.1467713\n\n\n0.0320811\n\n\nx3p\n\n\n0.1097854\n\n\n0.0071076\n\n\n15.4462847\n\n\n0.0000000\n\n\nx3pa\n\n\n-0.0660681\n\n\n0.0026554\n\n\n-24.8802759\n\n\n0.0000000\n\n\nx2p\n\n\n0.0462030\n\n\n0.0022500\n\n\n20.5343469\n\n\n0.0000000\n\n\nx2pa\n\n\n-0.0456323\n\n\n0.0014251\n\n\n-32.0206631\n\n\n0.0000000\n\n\nstl\n\n\n0.0584270\n\n\n0.0026520\n\n\n22.0314042\n\n\n0.0000000\n\n\ntov\n\n\n-0.0502939\n\n\n0.0021138\n\n\n-23.7936349\n\n\n0.0000000\n\n\nblk\n\n\n0.0052190\n\n\n0.0027441\n\n\n1.9018826\n\n\n0.0575091\n\n\ntrb\n\n\n0.0473068\n\n\n0.0015668\n\n\n30.1935183\n\n\n0.0000000\n\n\nast\n\n\n0.0045753\n\n\n0.0015088\n\n\n3.0323682\n\n\n0.0024968\n\n\nage\n\n\n0.0171241\n\n\n0.0018851\n\n\n9.0840307\n\n\n0.0000000\n\n\nO modelo generalizado, tendo como preditoras as variáveis escolhidas acima, apresentou valores significativos para quase todas as variáveis. Somente a variável de tentativas de arremessos em tiro livre, bloqueios e assistências por jogo apresentaram significância menor. As demais variáveis, apresentaram significância, com valor-p < 0,05. Cabe ressaltar, também, que o valor do R2 pode ser considerado um bom valor. 0.81 para o R22 e para o R2 ajustado, indicando uma boa aderência deste modelo.\nEntretanto, por se tratar de lances de jogo - e como já observado com a utilização da correlação na análise exploratória - pode ser que exista algum problema de multicolinearidade. Por isso, utilizei o vif para observar esse comportamento.\n\n\nShow code\n\nvif1 <- car::vif(modelo_nba)\n\nkbl(vif1, \n    booktabs = T, \n    longtable = T,\n    col.names = c('VIF')) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \n                                  \"hold_position\"))\n\n\n\n\n\nVIF\n\n\nft\n\n\n9.976623\n\n\nfta\n\n\n11.527646\n\n\nx3p\n\n\n81.501143\n\n\nx3pa\n\n\n82.166519\n\n\nx2p\n\n\n12.814557\n\n\nx2pa\n\n\n23.835844\n\n\nstl\n\n\n1.505386\n\n\ntov\n\n\n1.619725\n\n\nblk\n\n\n1.238009\n\n\ntrb\n\n\n2.350897\n\n\nast\n\n\n2.478891\n\n\nage\n\n\n1.407552\n\n\nComo é possível observar, algumas variáveis apresentaram VIF acima do adequado (acima de 5). No caso, as variáveis de tentativas de arremessos são valores significativos. Isso, possivelmente, ocorre porque as tentativas de arremesso são movimentos parecidos, independentemente do tipo de arremesso (na zona dois ou três pontos, por exemplo). Para resolver isso, testarei um novo modelo utilizando a variável de arremessos em geral (fg e fga) no lugar dos arremessos específicos. O objetivo dessa busca é encontrar um modelo reduzido para a regressão.\nDessa maneira, o modelo reduzido pode ser representado da seguinte maneira:\nteamapv = β0 + β1fg + β2fga + β3stl + β4tov + β5blk + β6trb + β9ast + β10age + εi\n\n\nShow code\n\nmodelo_nba_2 <- nbadb %>% \n  dplyr::select(\n    c(teamapv, fg, fga, stl, tov, blk, trb, ast, age)\n  )\n\n#Organiza a tabela para montar a correlação\nmodelo_nba_2 <- lm(teamapv ~ ., data = modelo_nba_2)\nsummary(modelo_nba_2) %>% \n  xtable::xtable() %>% \n  kable(caption = \"Tabela 3. Regressão múltipla com as variáveis das equipes sem arremessos específicos\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 3: Tabela 3. Regressão múltipla com as variáveis das equipes sem arremessos específicos\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n0.3547121\n\n\n0.0934418\n\n\n3.7960750\n\n\n0.0001569\n\n\nfg\n\n\n0.0552572\n\n\n0.0021212\n\n\n26.0498535\n\n\n0.0000000\n\n\nfga\n\n\n-0.0502356\n\n\n0.0013268\n\n\n-37.8628378\n\n\n0.0000000\n\n\nstl\n\n\n0.0540744\n\n\n0.0027766\n\n\n19.4747391\n\n\n0.0000000\n\n\ntov\n\n\n-0.0576072\n\n\n0.0020312\n\n\n-28.3612652\n\n\n0.0000000\n\n\nblk\n\n\n0.0012081\n\n\n0.0029335\n\n\n0.4118497\n\n\n0.6805483\n\n\ntrb\n\n\n0.0485813\n\n\n0.0015996\n\n\n30.3700692\n\n\n0.0000000\n\n\nast\n\n\n0.0051827\n\n\n0.0016160\n\n\n3.2070893\n\n\n0.0013885\n\n\nage\n\n\n0.0159192\n\n\n0.0020118\n\n\n7.9127461\n\n\n0.0000000\n\n\nCom esse novo modelo, foi possível perceber um ajuste na significância das variáveis, pois, agora, uma única referência para arremessos já representa e demonstra significância em relação à variável resposta. Neste caso, o valor de R2 teve uma leve queda e o erro médio dos resíduos também aumentou. Agora, temos um R22 de 0.79. Esse fato poderia ser uma preocupação na análise, pois entende-se que perdemos qualidade do modelo. Porém, avançarei com a análise, pois, as variáveis bloqueio e assistência continuam com uma baixa significância, por isso testarei um novo modelo sem a presença dessas variáveis.\nAgora, o modelo se dá da seguinte maneira:\nteamapv = β0 + β1fg + β2fga + β3stl + β4tov + β6trb + β7age + εi\n\n\nShow code\n\nmodelo_nba_3 <- nbadb %>% \n  dplyr::select(\n    c(teamapv, fg, fga, stl, tov, trb, age)\n  )\n\n#Organiza a tabela para montar a correlação\nmodelo_nba_3 <- lm(teamapv ~ ., data = modelo_nba_3)\nsummary(modelo_nba_3) %>% \n  xtable::xtable() %>% \n  kable(caption = \"Tabela 4. Regressão múltipla com as variáveis das equipes sem arremessos específicos, bloqueios e assistências\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 4: Tabela 4. Regressão múltipla com as variáveis das equipes sem arremessos específicos, bloqueios e assistências\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n0.3238515\n\n\n0.0926737\n\n\n3.494534\n\n\n0.0004982\n\n\nfg\n\n\n0.0595506\n\n\n0.0016759\n\n\n35.534190\n\n\n0.0000000\n\n\nfga\n\n\n-0.0511374\n\n\n0.0012684\n\n\n-40.316596\n\n\n0.0000000\n\n\nstl\n\n\n0.0554290\n\n\n0.0027548\n\n\n20.121090\n\n\n0.0000000\n\n\ntov\n\n\n-0.0569510\n\n\n0.0020278\n\n\n-28.085579\n\n\n0.0000000\n\n\ntrb\n\n\n0.0489035\n\n\n0.0015124\n\n\n32.335775\n\n\n0.0000000\n\n\nage\n\n\n0.0171082\n\n\n0.0019709\n\n\n8.680493\n\n\n0.0000000\n\n\nCom isso, o terceiro modelo teve um aumento no R2 (0.79) e uma redução nos erros em relação ao modelo 2. Ao mesmo passo, todas as variáveis demonstraram significância de efeito. Dessa forma, consideraremos o modelo 3 como o mais adequado para compreensão do aproveitamento dos times.\nPara atestar que não há mais problemas com as variáveis, retorno ao VIF, tentando evitar problemas de multicolinearidade que apareceram nos modelos anteriores.\n\n\nShow code\n\nvif2 <- car::vif(modelo_nba_3)\n\nkbl(vif2, \n    booktabs = T, \n    longtable = T,\n    col.names = c('VIF')) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \n                                  \"hold_position\"))\n\n\n\n\n\nVIF\n\n\nfg\n\n\n3.242289\n\n\nfga\n\n\n4.739400\n\n\nstl\n\n\n1.366855\n\n\ntov\n\n\n1.254337\n\n\ntrb\n\n\n1.843204\n\n\nage\n\n\n1.294714\n\n\nAssim, além do modelo ganhar em aderência, com um leve aumento nos valores de R2, mantendo a significância para todas as variáveis, também apresenta índices VIF abaixo de 5.\nAprofundando a modelagem com interações\nComo foi tratado sobre desempenho das equipes ao longo das temporadas, é importante ressanter que alguns fatores podem influenciar tais dados. Na NBA, temos a separação entre fases da liga: os equipes que jogam somente a temporada regular e os que se classificam para os playoffs. Consequentemente, isso consiste em mais jogos e, consequentemente, mais vitórias - pois isso é definido através de um ranking dos melhores clubes das conferências. Da mesma maneira, também existem outras premiações que também indicam qualidade e podem indicar resultados. Trata-se das premiações de melhor jogador da temporada (MVP) e melhor jovem da temporada (ROTY). É importante considerar esses itens, pois, em geral, tende-se a premiar os jogadores mais vencedores.\nPor isso, na Figura 5, utilizei boxplot para observar se há alguma diferença nos desempenhos das equipes dentro de cada uma das categorias citadas acima.\n\n\nShow code\n\ngraph13 <- nbadb %>% \n  ggplot2::ggplot(aes(x = teamapv, y = playoff)) +\n  ggplot2::geom_boxplot() +\n  ggplot2::coord_flip() +\n  labs(\n    x = \"% de Vitórias\",\n    y = \"Classificação para playoff\"\n  )\n\ngraph14 <- nbadb %>% \n  ggplot2::ggplot(aes(x = teamapv, y = mvp)) +\n  ggplot2::geom_boxplot() +\n  ggplot2::coord_flip() +\n  labs(\n    x = \"% de Vitórias\",\n    y = \"Melhor atleta da temporada\"\n  )\n\ngraph15 <- nbadb %>% \n  ggplot2::ggplot(aes(x = teamapv, y = roty)) +\n  ggplot2::geom_boxplot() +\n  ggplot2::coord_flip() +\n  labs(\n    x = \"% de Vitórias\",\n    y = \"Jovem atleta da temporada\"\n  )\n\ngridExtra::grid.arrange(top = \"Figura 5. Gráficos de boxplot entre variável resposta e variáveis categóricas\",\n                        graph13,\n                        graph14,\n                        graph15,\n                        ncol = 3, \n                        nrow = 1)\n\n\n\n\nO que observa-se, através da análise visual, é que há uma diferença de mediana entre as equipes que possuem os melhores jogadores da temporada. Para os casos dos atletas jovens da temporada, isso não se aplica. Assim, a fim de validar os testes, criarei outro modelo. Utilizarei, assim, o modelo reduzido encontrado no tópico anterior, interagindo com a variável de MVP (mvp).\nÉ importante ressaltar que o caso dos playoffs pode gerar uma compreensão um tanto quanto ambígua. Isso, pois, como dito, a definição das equipes que vão aos playoffs depende diretamente da sua classificação e, consequentemente, sua quantidade de vitórias. Por isso, acredito que seja uma relação pré-estabelecida, que pode enviesar o modelo.\nA tabela 5 exibe a utilização do modelo reduzido com a interação com a variável MVP.\n\n\nShow code\n\nmodelo_nba_4 <- nbadb %>% \n  dplyr::mutate(\n    mvp = forcats::fct_relevel(mvp, \"Regular\")) %>% \n  dplyr::select(\n    c(teamapv, fg, fga, stl, tov, trb, age, mvp)\n  )\n\n#Organiza a tabela para montar a correlação\nmodelo_nba_4 <- lm(teamapv ~ . * mvp, data = modelo_nba_4)\nsummary(modelo_nba_4) %>% \n  xtable::xtable() %>% \n  kable(caption = \"Tabela 5. Modelo reduzido com interação com a variável mvp\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 5: Tabela 5. Modelo reduzido com interação com a variável mvp\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n0.3360315\n\n\n0.0930851\n\n\n3.6099403\n\n\n0.0003234\n\n\nfg\n\n\n0.0587293\n\n\n0.0017101\n\n\n34.3417769\n\n\n0.0000000\n\n\nfga\n\n\n-0.0505881\n\n\n0.0012923\n\n\n-39.1472148\n\n\n0.0000000\n\n\nstl\n\n\n0.0553006\n\n\n0.0027549\n\n\n20.0736413\n\n\n0.0000000\n\n\ntov\n\n\n-0.0565401\n\n\n0.0020299\n\n\n-27.8530427\n\n\n0.0000000\n\n\ntrb\n\n\n0.0484087\n\n\n0.0015463\n\n\n31.3061365\n\n\n0.0000000\n\n\nage\n\n\n0.0166533\n\n\n0.0019718\n\n\n8.4455740\n\n\n0.0000000\n\n\nmvpMVP\n\n\n-0.0731252\n\n\n0.5434656\n\n\n-0.1345534\n\n\n0.8929954\n\n\nfg:mvpMVP\n\n\n-0.0338796\n\n\n0.0123795\n\n\n-2.7367489\n\n\n0.0063288\n\n\nfga:mvpMVP\n\n\n0.0332898\n\n\n0.0100547\n\n\n3.3108567\n\n\n0.0009676\n\n\nstl:mvpMVP\n\n\n-0.0346271\n\n\n0.0207027\n\n\n-1.6725894\n\n\n0.0947600\n\n\ntov:mvpMVP\n\n\n0.0290985\n\n\n0.0158390\n\n\n1.8371412\n\n\n0.0665227\n\n\ntrb:mvpMVP\n\n\n-0.0342176\n\n\n0.0098739\n\n\n-3.4654539\n\n\n0.0005547\n\n\nage:mvpMVP\n\n\n0.0027886\n\n\n0.0128617\n\n\n0.2168124\n\n\n0.8284043\n\n\nA Figura 6 representam os gráficos com a presença das interações pela variável categórica MVP. Isso ajuda a compreender o efeito dessa variável no restante da análise.\n\n\nShow code\n\ngraph16 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = fg)) +\n  ggplot2::geom_point() +\n  geom_smooth(method = lm, aes(colour = factor(mvp)), se = FALSE) +\n  labs(\n    x = \"Acertos em arremessos\",\n    y = \"% de vitórias\"\n  ) +\n  theme(legend.position = \"none\")\n\ngraph17 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = fga)) +\n  ggplot2::geom_point() +\n  geom_smooth(method = lm, aes(colour = factor(mvp)), se = FALSE) +\n  labs(\n    x = \"Tentativas de arremessos\",\n    y = \"% de vitórias\"\n  ) +\n  theme(legend.position = \"none\")\n\ngraph18 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = stl)) +\n  ggplot2::geom_point() +\n  geom_smooth(method = lm, aes(colour = factor(mvp)), se = FALSE) +\n  labs(\n    x = \"Roubadas de bola\",\n    y = \"% de vitórias\"\n  ) +\n  theme(legend.position = \"none\")\n\ngraph19 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = tov)) +\n  ggplot2::geom_point() +\n  geom_smooth(method = lm, aes(colour = factor(mvp)), se = FALSE) +\n  labs(\n    x = \"Turnovers\",\n    y = \"% de vitórias\"\n  ) +\n  theme(legend.position = \"none\")\n\ngraph20 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = trb)) +\n  ggplot2::geom_point() +\n  geom_smooth(method = lm, aes(colour = factor(mvp)), se = FALSE) +  \n  labs(\n    x = \"Rebotes\",\n    y = \"% de vitórias\",\n    colour = \"Categoria\"\n  ) +\n  theme(legend.position = \"bottom\")\n\ngraph21 <- nbadb %>% \n  ggplot2::ggplot(aes(y = teamapv, x = age)) +\n  ggplot2::geom_point() +\n  geom_smooth(method = lm, aes(colour = factor(mvp)), se = FALSE) +\n  labs(\n    x = \"Idade\",\n    y = \"% de vitórias\"\n  ) +\n  theme(legend.position = \"none\")\n\ngridExtra::grid.arrange(top = \"Figura 6. Gráficos de dispersão com interação com MVP\",\n                        graph16,\n                        graph17,\n                        graph18,\n                        graph19,\n                        graph20,\n                        graph21,\n                        ncol = 3, \n                        nrow = 2)\n\n\n\n\nDessa forma, é importante entender o modelo com a interação com a variável MVP. O resultado do modelo manteve as signifiâncias para as variáveis do modelo otimizado. Então, podemos dizer que há efeito das variáveis explicativas na variável resposta (aproveitamento das equipes), como já fora notado anteriormente. Já sobre o efeito da variável MVP em relação às variável explicativas, podemos dizer que se aplica somente para alguns casos, como tentativas de arremessos e rebotes. Para o restante, as retas se mantiveram paralelas. Dessa forma, por mais que tenha aumentado do R22 levemente (0.80), considerarei que essa interação não é relevante para esse modelo.\nDiagnóstico do modelo\nPor fim, para concluir, realizarei uma análise diagnóstica do modelo, a fim de entender se esse realmente é o melhor caminho para seguir, concluindo com o que fora compreendido desse estudo.\nDessa maneira, utilizarei o modelo que pôde ser considerado como ótimo para analisa-lo.\nRelembrando,\nteamapv = β0 + β1fg + β2fga + β3stl + β4tov + β6trb + β7age + εi\nAssim, utilizarei a análise de resíduos para observar a presença de outliers e analisar como o modelo se comportou.\n\n\nShow code\n\npar(mfrow = c(2,2))\nplot(modelo_nba_3, which = (1:4), pch=20)\n\n\n\n\nA análise de resíduos ajuda a entender a presença de outliers e o comportamento dos mesmos. Observando o gráfico de qq-plot, podemos observar que a curva tende à normalidade. A núvem de resíduos e preditos também indica a normalidade e mostra como à homogeneidade na variação do que foi predicto e o que foi observado, mesmo com um leve desvio com o aumento dos valores preditos.\nNa Figura 7, desenhei um histograma para observar a curva de distribuição dos resíduos. Nota-se, novamente, uma curva normal.\n\n\nShow code\n\nhist_residuals <- modelo_nba_3$residuals %>% \n  tibble::as_tibble()\n\nhist_residuals %>% \n  ggplot2::ggplot(aes(x = value, y=..density..)) +\n  ggplot2::geom_histogram(color = \"black\",\n                          fill = \"white\") +\n  geom_density(alpha= .1, fill=\"gray\") +\n  ggplot2::theme_minimal() +\n  labs(\n    y = \"Densidade\",\n    x = \"Resíduos\",\n    title = \"Figura 7. Histograma dos resíduos\"\n  )\n\n\n\n\nO teste de Shapiro-Wilk permite garantir, estatisticamente, de que há normalidade dos resíduos nesse modelo de regressão. Portanto, o valor-p do teste permite garantir esse resultado.\n\n\nShow code\n\nshapiro.test(modelo_nba_3$residuals)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_nba_3$residuals\nW = 0.99872, p-value = 0.7782\n\nA distância de Cook permite observar que existem outliers na base. Entretanto, o que é apontado pelo teste está dentro da compreensão das análises, visto que considera campanhas fora da curva normal, como desempenhos marcados históricamente pelos próprios desempenhos. Porém, acredito que essas campanhas podem fazer parte do jogo, já que alguns fatores não são tão controláveis (como a quantidade de arremessos, quantidade de acertos de bolas de três e etc). Dessa forma, considerarei que não há pontos influentes no modelo, aceitando os desvios como algo normal.\nConclusão\nHá um grau de complexidade na análise desses dados, principalmente por serem dados esportivos, que mudam com alta velocidade e dependem de fatores não tão controlados (como lesões de atletas, negociações, psicológico, presença da torcida e etc.). Além disso, corre-se o risco de ser redundante, visto que certamente quanto mais perfeito seu jogo for, maior a chance de vencer você terá. Entretanto, acredito que foi possível mensurar algumas variáveis que influenciam em nossa variável resposta: o desempenho da equipe ao longo da temporada.\nObservando todos os dados do jogo, foi possível reduzir uma fórmula que melhor representava efeitos no desempenho da equipe. Assim, chegamos à conclusão que o modelo que considerava acertos e tentativas de arremessos em geral por jogo, roubadas de bolas por jogo, turnovers por jogo, rebotes por jogo e média de idade da equipe é a melhor forma para entender a relação linear com o aproveitamento da equipe.\nO modelo não levou em consideração as interações, visto que não foi possível observar ganhos significativos com a inclusão de alguns testes. Observei se seria teria muito efeito ter a presença do MVP da temporada ou não, porém, o retorno não foi significativo para ser levado em consideração.\nPor fim, considero que essa análise mereça um estudo mais aprofundado e detalhado, de forma que, talvez, seja necessário realizar novos testes, utilizando novas técnicas. Porém, a regressão linear permitiu observar que algumas variáveis podem surtir efeito se a equipe eleva seu desempenho no jogo.\nPara concluir, a expressão do modelo ajustado é a seguinte:\naproveitamento = 0.323852 + 0.059551fg - 0.051137fga + 0.05542stl - 0.056951tov + 0.048903trb + 0.017108age\nEsse modelo teve um R22 de 0.79, com um erro médio de 0.071 e significância para todas as variáveis.\n\n\nShow code\n\nsummary(modelo_nba_3)\n\n\n\nCall:\nlm(formula = teamapv ~ ., data = modelo_nba_3)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.220868 -0.046998 -0.002114  0.049579  0.227538 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.323852   0.092674   3.495 0.000498 ***\nfg           0.059551   0.001676  35.534  < 2e-16 ***\nfga         -0.051137   0.001268 -40.317  < 2e-16 ***\nstl          0.055429   0.002755  20.121  < 2e-16 ***\ntov         -0.056951   0.002028 -28.086  < 2e-16 ***\ntrb          0.048903   0.001512  32.336  < 2e-16 ***\nage          0.017108   0.001971   8.680  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0713 on 896 degrees of freedom\nMultiple R-squared:  0.7941,    Adjusted R-squared:  0.7927 \nF-statistic: 575.9 on 6 and 896 DF,  p-value: < 2.2e-16\n\n\n\n\n",
    "preview": "posts/2021-04-18-tcc-jean-carlo/99-tcc-JeanCarlo_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-05-05T13:50:43-03:00",
    "input_file": "99-tcc-JeanCarlo.utf8.md"
  },
  {
    "path": "posts/2021-04-18-tcc-cesar-lemos/",
    "title": "Análise do Consumo de Combustível",
    "description": {},
    "author": [
      {
        "name": "César Lemos",
        "url": "https://www.linkedin.com/in/cesar-lemos-4a8b124b/"
      }
    ],
    "date": "2021-04-18",
    "categories": [],
    "contents": "\n\nContents\nIntrodução\nAnálise exploratória dos dados\nModelagem\nConclusão\n\nIntrodução\nEm outubro de 1973 ocorreu uma grande crise petrolífera fruto de embargo as nações apoiadoras de Israel durante a guerra do Yom Kippur (Smith, 2006). Os responsáveis por estes embargos foram os países membros da Organização dos Países Árabes Exportadores de Petróleo (OPAEP). As nações alvos deste embargo foram o Canadá, Japão, Holanda, Reino Unido, Estados Unidos e, posteriormente, Portugal, Rodésia e África do Sul.\nDurante o período do embargo, que foi até março de 1974, o preço médio do barril de petróleo subiu de US$ 3,00 para aproximandamente US$ 12,00, o que representa um aumento de 3%. Foi neste período que a revista Motor Trend US de 1974 publicou em uma de suas edições uma tabela informativa contendo dados de consumo de combustível (necessário, visto o alto valor do combustível fóssil) jutamente com outros 10 aspectos de desempenhos para 32 veículos produzidos entre 1973 e 1974.\nEstes são os dados que compõe a base mtcars, objeto de estudo deste trabalho. O estudo consistirá em verificar se as variáveis que compõe esta base podem explicar o consumo de combustível, medido em milhas por galão, dentro de um intervalo de confiança de 90%. Para esta análise foi utilizado o software R na versão 4.0.4.\nAnálise exploratória dos dados\nAnalisando a base mtcars, é possível observar que ela é composta por 32 observações e 11 colundas e apresenta as seguintes variáveis:\n\n\nShow code\n\nglimpse(mtcars)\n\n\nRows: 32\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 1…\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4…\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7,…\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180…\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3…\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190,…\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00,…\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1…\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4…\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2…\n\n\nOnde:\nmpg: é o consumo medido em milhas por galões;\ncyl: é o número de cilindos que o motor do veículo possui;\ndisp: é a cilindrada do veículo, medido em polegadas cúbicas;\nhp: é a potência bruta, medida em cavalos (horse power);\ndrat: é a relação do eixo traseiro do veículo;\nwt: é o peso, medido em 1 mil libras;\nqsec: é o tempo no quarto de milha;\nvs: indica se o motor é em V (vs = 0) ou em linha (vs = 1);\nam: informa se a transmissão é automática (am = 0) ou manual (am = 1);\ngear: indica o número de marchas, excluindo a ré;\ncarb: informa o número de carburadores do veículo.\nAs estatísticas univariadas das variáveis, que se encontram na tabela 1, mostra que não há valores nulos e por isso não há necessidade de realizar algum processo de interpolação ou exclusão de valores.\n\n\nShow code\n\nstat.desc(mtcars) %>% \n  mutate(medida = rownames(.)) %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>%\n  pivot_longer(!medida, names_to = \"Caracteristicas\", values_to = \"Valor\") %>% \n  pivot_wider(names_from = medida, values_from = Valor) %>% \n  select(-nbr.val, -nbr.null, -SE.mean, -var, -sum) %>% \n  rename(Valores_NA = nbr.na,\n         Minimo = min,\n         Maximo = max,\n         Intervalo = range,\n         Mediana = median,\n         Media = mean,\n         C.I.Media_0.95 = CI.mean.0.95,\n         Desvio_Padrao = std.dev,\n         Coef_Variacao = coef.var) %>% \n  kable(caption = \"Tabela 1: Estatística univariada das variáveis\") %>% \n  kable_paper(\"hover\", full_width = F)\n\n\n\nTable 1: Tabela 1: Estatística univariada das variáveis\n\n\nCaracteristicas\n\n\nValores_NA\n\n\nMinimo\n\n\nMaximo\n\n\nIntervalo\n\n\nMediana\n\n\nMedia\n\n\nC.I.Media_0.95\n\n\nDesvio_Padrao\n\n\nCoef_Variacao\n\n\nmpg\n\n\n0\n\n\n10.400\n\n\n33.900\n\n\n23.500\n\n\n19.200\n\n\n20.0906\n\n\n2.17295\n\n\n6.02695\n\n\n0.29999\n\n\ndisp\n\n\n0\n\n\n71.100\n\n\n472.000\n\n\n400.900\n\n\n196.300\n\n\n230.7219\n\n\n44.68466\n\n\n123.93869\n\n\n0.53718\n\n\nhp\n\n\n0\n\n\n52.000\n\n\n335.000\n\n\n283.000\n\n\n123.000\n\n\n146.6875\n\n\n24.71955\n\n\n68.56287\n\n\n0.46741\n\n\ndrat\n\n\n0\n\n\n2.760\n\n\n4.930\n\n\n2.170\n\n\n3.695\n\n\n3.5966\n\n\n0.19277\n\n\n0.53468\n\n\n0.14866\n\n\nwt\n\n\n0\n\n\n1.513\n\n\n5.424\n\n\n3.911\n\n\n3.325\n\n\n3.2172\n\n\n0.35277\n\n\n0.97846\n\n\n0.30413\n\n\nqsec\n\n\n0\n\n\n14.500\n\n\n22.900\n\n\n8.400\n\n\n17.710\n\n\n17.8487\n\n\n0.64426\n\n\n1.78694\n\n\n0.10012\n\n\n\nPara fins de análise, as variáveis vs, am, gear, carb e cyl serão tratadas como dummies. Embora gear, carb e cyl sejam numéricas, representam uma categoria de carros. Não tem como dizer que os carros possuem 3,69 marchas, em média. Ou os carros possuem uma média de 2,8 cilindros. Neste caso, uma tabela de frequência seria o mais adequado para analisar estas variáveis.\nA figura 1 mostra a distribuição e correlações entre as variáveis quantitativas na base de dados. Esta figura evidencia que há um problema de multicolinearidade. Além disto, a vairável resposta aparenta não ter uma correlação linear entre algumas variáveis.\n\n\nShow code\n\nmtcars %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>% \n  ggpairs()\n\n\n\n\nFigure 1: Figura 1: Matriz de correlação com histograma e scatter plot das variáveis quantiativas\n\n\n\n\nA figura 2 mostra uma série de gráficos de correlação entre a variável dependente e as variáveis explicativas. Em alguns casos é possível perceber que a correlação não é linear, como no caso de mpg e disp, por exemplo. Isto pode ser fruto de interação entre estas variáveis e alguma outra categórica, como gear.\n\n\nShow code\n\np1 <- mtcars %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e dist\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np2 <- mtcars %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>% \n  ggplot(aes(x = hp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e hp\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np3 <- mtcars %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>% \n  ggplot(aes(x = drat, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e drat\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np4 <- mtcars %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>% \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e wt\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np5 <- mtcars %>% \n  select(-vs, -am, -cyl, -carb, -gear) %>% \n  ggplot(aes(x = qsec, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e qsec\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\ngrid.arrange(p1, p2, p3, p4, p5, nrow = 2)\n\n\n\n\nFigure 2: Figura 2: Correlação entre a variável dependente e demais variáveis explicativas\n\n\n\n\nAnálise das interações\nQuando suspeita-se que os coeficientes de inclinação podem variar entre as categorias da variável preditora então aconselha-se testar a interação entre as duas variáveis. Graficamente é possível ver estas interações ao colorir os pontos do gráfico de dispersão de acordo com a classe desejada.\nNas figuras 3 a 7, é possível ver que há interações com as variáveis dummies em muitos casos. Com as interações, é possível utilizar toda a variância do banco de dados para calcular o impacto destas variáveis categóricas nos coeficientes das retas, criando uma reta para cada situação.\n\n\nShow code\n\np1 <- mtcars %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point(aes(color = as.factor(vs))) +\n  geom_smooth(aes(color = as.factor(vs)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e dist\") +\n  labs(color = \"Motor Linha = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np2 <- mtcars %>% \n  ggplot(aes(x = hp, y = mpg)) +\n  geom_point(aes(color = as.factor(vs))) +\n  geom_smooth(aes(color = as.factor(vs)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e hp\") +\n  labs(color = \"Motor Linha = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np3 <- mtcars %>% \n  ggplot(aes(x = drat, y = mpg)) +\n  geom_point(aes(color = as.factor(vs))) +\n  geom_smooth(aes(color = as.factor(vs)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e drat\") +\n  labs(color = \"Motor Linha = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np4 <- mtcars %>% \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = as.factor(vs))) +\n  geom_smooth(aes(color = as.factor(vs)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e wt\") +\n  labs(color = \"Motor Linha = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np5 <- mtcars %>% \n  ggplot(aes(x = qsec, y = mpg)) +\n  geom_point(aes(color = as.factor(vs))) +\n  geom_smooth(aes(color = as.factor(vs)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e qsec\") +\n  labs(color = \"Motor Linha = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\ngrid.arrange(p1, p2, p3, p4, p5, nrow = 2)\n\n\n\n\nFigure 3: Figura 3: Interação das variáveis com o tipo do motor\n\n\n\n\n\n\nShow code\n\np1 <- mtcars %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point(aes(color = as.factor(gear))) +\n  geom_smooth(aes(color = as.factor(gear)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e dist\") +\n  labs(color = \"Qtd. Marchas\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np2 <- mtcars %>% \n  ggplot(aes(x = hp, y = mpg)) +\n  geom_point(aes(color = as.factor(gear))) +\n  geom_smooth(aes(color = as.factor(gear)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e hp\") +\n  labs(color = \"Qtd. Marchas\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np3 <- mtcars %>% \n  ggplot(aes(x = drat, y = mpg)) +\n  geom_point(aes(color = as.factor(gear))) +\n  geom_smooth(aes(color = as.factor(gear)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e drat\") +\n  labs(color = \"Qtd. Marchas\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np4 <- mtcars %>% \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = as.factor(gear))) +\n  geom_smooth(aes(color = as.factor(gear)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e wt\") +\n  labs(color = \"Qtd. Marchas\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np5 <- mtcars %>% \n  ggplot(aes(x = qsec, y = mpg)) +\n  geom_point(aes(color = as.factor(gear))) +\n  geom_smooth(aes(color = as.factor(gear)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e qsec\") +\n  labs(color = \"Qtd. Marchas\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\ngrid.arrange(p1, p2, p3, p4, p5, nrow = 2)\n\n\n\n\nFigure 4: Figura 4: Interação das variáveis com a quantidade de marcha\n\n\n\n\n\n\nShow code\n\np1 <- mtcars %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point(aes(color = as.factor(cyl))) +\n  geom_smooth(aes(color = as.factor(cyl)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e dist\") +\n  labs(color = \"Qtd. Cilindros\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np2 <- mtcars %>% \n  ggplot(aes(x = hp, y = mpg)) +\n  geom_point(aes(color = as.factor(cyl))) +\n  geom_smooth(aes(color = as.factor(cyl)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e hp\") +\n  labs(color = \"Qtd. Cilindros\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np3 <- mtcars %>% \n  ggplot(aes(x = drat, y = mpg)) +\n  geom_point(aes(color = as.factor(cyl))) +\n  geom_smooth(aes(color = as.factor(cyl)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e drat\") +\n  labs(color = \"Qtd. Cilindros\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np4 <- mtcars %>% \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = as.factor(cyl))) +\n  geom_smooth(aes(color = as.factor(cyl)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e wt\") +\n  labs(color = \"Qtd. Cilindros\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np5 <- mtcars %>% \n  ggplot(aes(x = qsec, y = mpg)) +\n  geom_point(aes(color = as.factor(cyl))) +\n  geom_smooth(aes(color = as.factor(cyl)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e qsec\") +\n  labs(color = \"Qtd. Cilindros\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\ngrid.arrange(p1, p2, p3, p4, p5, nrow = 2)\n\n\n\n\nFigure 5: Figura 5: Interação das variáveis com a quantidade de cilindros\n\n\n\n\n\n\nShow code\n\np1 <- mtcars %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point(aes(color = as.factor(carb))) +\n  geom_smooth(aes(color = as.factor(carb)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e dist\") +\n  labs(color = \"Qtd. Carburadores\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np2 <- mtcars %>% \n  ggplot(aes(x = hp, y = mpg)) +\n  geom_point(aes(color = as.factor(carb))) +\n  geom_smooth(aes(color = as.factor(carb)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e hp\") +\n  labs(color = \"Qtd. Carburadores\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np3 <- mtcars %>% \n  ggplot(aes(x = drat, y = mpg)) +\n  geom_point(aes(color = as.factor(carb))) +\n  geom_smooth(aes(color = as.factor(carb)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e drat\") +\n  labs(color = \"Qtd. Carburadores\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np4 <- mtcars %>% \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = as.factor(carb))) +\n  geom_smooth(aes(color = as.factor(carb)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e wt\") +\n  labs(color = \"Qtd. Carburadores\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np5 <- mtcars %>% \n  ggplot(aes(x = qsec, y = mpg)) +\n  geom_point(aes(color = as.factor(carb))) +\n  geom_smooth(aes(color = as.factor(carb)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e qsec\") +\n  labs(color = \"Qtd. Carburadores\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\ngrid.arrange(p1, p2, p3, p4, p5, nrow = 2)\n\n\n\n\nFigure 6: Figura 6: Interação das variáveis com a quantidade de carburador\n\n\n\n\n\n\nShow code\n\np1 <- mtcars %>% \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point(aes(color = as.factor(am))) +\n  geom_smooth(aes(color = as.factor(am)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e dist\") +\n  labs(color = \"Transm. Manual = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np2 <- mtcars %>% \n  ggplot(aes(x = hp, y = mpg)) +\n  geom_point(aes(color = as.factor(am))) +\n  geom_smooth(aes(color = as.factor(am)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e hp\") +\n  labs(color = \"Transm. Manual = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np3 <- mtcars %>% \n  ggplot(aes(x = drat, y = mpg)) +\n  geom_point(aes(color = as.factor(am))) +\n  geom_smooth(aes(color = as.factor(am)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e drat\") +\n  labs(color = \"Transm. Manual = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np4 <- mtcars %>% \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = as.factor(am))) +\n  geom_smooth(aes(color = as.factor(am)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e wt\") +\n  labs(color = \"Transm. Manual = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\np5 <- mtcars %>% \n  ggplot(aes(x = qsec, y = mpg)) +\n  geom_point(aes(color = as.factor(am))) +\n  geom_smooth(aes(color = as.factor(am)), method = \"lm\", se = F) +\n  ggtitle(\"Correlação entre mpg e qsec\") +\n  labs(color = \"Transm. Manual = 1\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(panel.border = element_blank(),\n        title = element_text(size = 10))\n\ngrid.arrange(p1, p2, p3, p4, p5, nrow = 2)\n\n\n\n\nFigure 7: Figura 7: Interação das variáveis com o tipo de transmissão\n\n\n\nModelagem\nConforme Moretin e Singer (2019), a reta de regrssão é dada por:\n\\(y_i = \\alpha + \\beta x_i + \\epsilon_i , i = 1,...,n.\\)\nOnde:\n\\(y\\) é a variável resposta;\n\\(x\\) é o vetor de variável explicativa;\n\\(\\alpha\\) e \\(\\beta\\) são os parâmetros estimados;\n\\(\\epsilon\\) são os erros aleatórios do modelo.\nPara modelar a base mtcars, será feito a utilização do método de stepwise com o critério de informação de Akaike para selecionar as variáveis mais importantes, além de considerar as interações vistas anteriormente.\nComo visto na matriz de correlação, existe autocorrelação entre algumas variáveis explicativas quantitativas. Para identificar qual remover, vamos verificar o fator de inflação da variância (VIF). Segundo James et al. (2013), valores acima de 5 podem ser removidos para solucionar este problema. Entretanto, segundo a tabela 2, três variáveis possuem valores acima do recomendado. Como a exclusão de uma variável pode impactar na variância geral, será removido o que apresenta o maior valor e depois será verificado as variáveis restantes.\n\n\nShow code\n\nvif(lm(mpg ~ hp + drat + qsec + disp + wt, data = mtcars)) %>% \n  kable(caption = \"Tabela 2: Fator de inflação das variância\") %>% \n  kable_paper(\"hover\", full_width = T)\n\n\n\nTable 2: Tabela 2: Fator de inflação das variância\n\n\n\n\nx\n\n\nhp\n\n\n5.2018\n\n\ndrat\n\n\n2.3223\n\n\nqsec\n\n\n3.1919\n\n\ndisp\n\n\n9.1109\n\n\nwt\n\n\n7.0127\n\n\nApós remover a variável disp, a variável hp ainda possui um valor elevado se aproximando muito de 5, conforme tabela 3. Logo, ela será excluida.\n\n\nShow code\n\nvif(lm(mpg ~ hp + drat + qsec + wt, data = mtcars)) %>% \n  kable(caption = \"Tabela 3: Fator de inflação das variância ajustado\") %>% \n  kable_paper(\"hover\", full_width = T)\n\n\n\nTable 3: Tabela 3: Fator de inflação das variância ajustado\n\n\n\n\nx\n\n\nhp\n\n\n4.9220\n\n\ndrat\n\n\n2.0355\n\n\nqsec\n\n\n2.8761\n\n\nwt\n\n\n3.5827\n\n\nO modelo contará então com as variáveis quantitativas listadas na tabela 4.\n\n\nShow code\n\nvif(lm(mpg ~ drat + qsec + wt, data = mtcars)) %>% \n  kable(caption = \"Tabela 4: Fator de inflação das variância após segundo ajuste\") %>% \n  kable_paper(\"hover\", full_width = T)\n\n\n\nTable 4: Tabela 4: Fator de inflação das variância após segundo ajuste\n\n\n\n\nx\n\n\ndrat\n\n\n2.0355\n\n\nqsec\n\n\n1.0339\n\n\nwt\n\n\n2.0821\n\n\nRodando o modelo com o procedimento stepwise temos que o modelo proposto não não possui significância estatística em quase nenhuma variável. Isso pode acontecer devido a variabilidade causada pela presença de uma variável e que não identificada pelo método stepwise. Como a variável wt não apresenta nenhuma significância estatística, ela será removida e depois o modelo será rodado novamente.\n\n\nShow code\n\nsummary(modelo)\n\n\n\nCall:\nlm(formula = mpg ~ drat + carb + qsec + wt + gear + cyl + vs + \n    am + wt:gear + gear:cyl + wt:am, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.473 -0.971  0.000  0.896  3.047 \n\nCoefficients: (2 not defined because of singularities)\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)    23.84      24.32    0.98    0.346  \ndrat            7.89       3.77    2.09    0.058 .\ncarb2          -5.27       2.88   -1.83    0.092 .\ncarb3          -7.08       3.61   -1.96    0.074 .\ncarb4          -9.35       5.11   -1.83    0.092 .\ncarb6          65.15      38.72    1.68    0.118  \ncarb8          42.08      26.36    1.60    0.136  \nqsec            1.82       1.45    1.26    0.232  \nwt             -1.43       2.11   -0.68    0.512  \ngear4        -689.48     445.71   -1.55    0.148  \ngear5        -504.61     351.19   -1.44    0.176  \ncyl6            5.97       4.37    1.37    0.197  \ncyl8          -51.41      32.08   -1.60    0.135  \nvs1           -64.52      37.01   -1.74    0.107  \nam1           698.38     441.50    1.58    0.140  \nwt:gear4      219.05     140.26    1.56    0.144  \nwt:gear5      104.40      80.45    1.30    0.219  \ngear4:cyl6    -61.46      38.04   -1.62    0.132  \ngear5:cyl6        NA         NA      NA       NA  \ngear4:cyl8        NA         NA      NA       NA  \ngear5:cyl8    172.13      95.74    1.80    0.097 .\nwt:am1       -220.61     138.22   -1.60    0.136  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.32 on 12 degrees of freedom\nMultiple R-squared:  0.943, Adjusted R-squared:  0.851 \nF-statistic: 10.4 on 19 and 12 DF,  p-value: 0.0000918\n\nRodando um segundo modelo temos significância estatística em todas as variáveis quantitativas, mesmo que só nas interações. Embora alguma categoria da variável dummy não apresente significância estatística, ela não será removida. A significância estatística de alguma categoria está relacionada com qual variável está na casela de referência, além disto, a remoção de outra categoria fará com que a casela de referência contemple duas categorias, o que gera uma inconsistência no modelo. Este segundo modelo apresenta um R² de 0.959 e interações com as variáveis gear, cly e am.\nImportante ressaltar que os NA gerados na regressão informam apenas que as interações observadas não adicionam informação ao modelo.\n\n\nShow code\n\nsummary(modelo)\n\n\n\nCall:\nlm(formula = mpg ~ drat + carb + qsec + gear + cyl + vs + am + \n    qsec:gear + gear:cyl + qsec:am, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.974 -0.376  0.000  0.639  2.176 \n\nCoefficients: (2 not defined because of singularities)\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     3.612     23.428    0.15  0.87985    \ndrat            8.081      2.348    3.44  0.00438 ** \ncarb2          -3.231      2.417   -1.34  0.20409    \ncarb3          -4.603      3.051   -1.51  0.15524    \ncarb4          -9.191      2.921   -3.15  0.00773 ** \ncarb6         170.136     38.465    4.42  0.00069 ***\ncarb8         -19.308      4.605   -4.19  0.00105 ** \nqsec            0.394      0.904    0.44  0.67014    \ngear4          38.950     28.833    1.35  0.19979    \ngear5       -2349.529    507.052   -4.63  0.00047 ***\ncyl6            4.624      3.006    1.54  0.14796    \ncyl8          -14.474      7.029   -2.06  0.06011 .  \nvs1           -19.891      5.104   -3.90  0.00183 ** \nam1          -134.278     37.897   -3.54  0.00360 ** \nqsec:gear4     -1.633      1.355   -1.21  0.24948    \nqsec:gear5    140.873     30.360    4.64  0.00046 ***\ngear4:cyl6     -8.226      4.758   -1.73  0.10748    \ngear5:cyl6         NA         NA      NA       NA    \ngear4:cyl8         NA         NA      NA       NA    \ngear5:cyl8    337.798     73.622    4.59  0.00051 ***\nqsec:am1        6.854      1.982    3.46  0.00424 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.88 on 13 degrees of freedom\nMultiple R-squared:  0.959, Adjusted R-squared:  0.902 \nF-statistic: 16.9 on 18 and 13 DF,  p-value: 0.0000032\n\nAnalisando os resíduos do modelo é possível verificar que os resíduos aparentam estar distribuídos de forma aleatória, estão acompanhando bem a linha de normalidade no gráfico Q-Q (embora alguns pontos estejam mais afastados) e possuem alguns veículos perto da linha de 0.5 na distância de Cook, sendo o Camaro Z28 o único a possuir este valor. Embora apresente outliers, eles não serão removidos devido a quantidade pequena da amostra.\n\n\nShow code\n\npar(mfrow = c(2, 2))\nplot(modelo)\n\n\n\n\nPor fim, é possível comprovar a normalidade dos resíduos utilizando o teste de Shapiro-Wilk onde um p-value > 0.05 indica que a distribuição é gaussiana.\n\n\nShow code\n\nshapiro.test(modelo$residuals)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo$residuals\nW = 0.948, p-value = 0.13\n\nConclusão\nDas variáveis explicativas, as que mais contribuem para uma redução no mpg são possuir uma quinta marcha (\\(\\beta = - 2349,529\\)), possuir câmbio manual (\\(\\beta = - 134,278\\)), motor em linha (\\(\\beta = - 19,891\\)) e possuir 8 carburadores (\\(\\beta = - 19,308\\)). Uma hipótese que pode explicar este fato é que carros com essas características são mais modernos e eficientes, corroborando para um menor consumo de combustível.\nJá as variáveis que mais contribuem para aumentar o consumo de milhas por galão são possuir 6 carburadores (\\(\\beta = 170,136\\)), possuir 5 marchas e 8 cilindros (\\(\\beta = 337,798\\)) ou possuir 4 marchas (\\(\\beta = 38,950\\)).\n\n\n\n",
    "preview": "posts/2021-04-18-tcc-cesar-lemos/cesar-lemos-tcc_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-05-05T14:02:16-03:00",
    "input_file": "cesar-lemos-tcc.utf8.md"
  },
  {
    "path": "posts/2021-04-18-carlos-eduardo/",
    "title": "TCC",
    "description": {},
    "author": [
      {
        "name": "Carlos Eduardo Cardoso",
        "url": {}
      }
    ],
    "date": "2021-03-27",
    "categories": [],
    "contents": "\n\nContents\n1. Introdução\n2. Gráficos e tabelas descritivos:\n3. MODELAGEM\n4. Diagnóstico do modelo:\n5. Conclusão e discussão\n\n1. Introdução\nOs dados utilizados nesse estudo foram extraídos da revista Motor Trend US de 1974 e abrangem o consumo de combustível e 10 aspectos do design e desempenho de automóveis para 32 automóveis (modelos de 1973 a 1974). Nossa base contém 32 observações (linhas) de 11 variáveis numéricas (colunas). São elas:\n1. mpg: consumo de combustível em milhas por galão;\n2. cyl: número de cilindros;\n3. disp: deslocamento;\n4. hp: potência bruta;\n5. drat: relação do eixo traseiro;\n6. wt: Peso (1000 libras);\n7. qsec: 1/4 de milha;\n8. vs: Motor (0 = em forma de V, 1 = reto);\n9. am: Transmissão (0 = automático, 1 = manual);\n10. gear: Número de marchas (para frente);\n11. carb: número de carburadores.\nPretendemos com esse estudo identificar quais características do carro explicam sua eficiência (mpg) analisando o comportamento de cada variável e construindo então um modelo linear que possa quantificar quantas e quais são essas variáveis.\n2. Gráficos e tabelas descritivos:\n\n\nShow code\n\nlibrary(Amelia)\nmissmap(mtcars)\n\n\n\nShow code\n\nsummary(mtcars[,-c(8,9)])\n\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec            gear      \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :3.000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:3.000  \n Median :3.695   Median :3.325   Median :17.71   Median :4.000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :3.688  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:4.000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:2.000  \n Median :2.000  \n Mean   :2.812  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\nNão há dados faltantes em nossa base. Com relação as informações acima, destaca-se:\n1. Temos carros entre 4 e 8 cilindros;\n2. Temos carros com o número de marchas entre 3 e 5;\n3. Temos também carros com carburadores variando entre 1 e 8;\n4. Em relação a variável wt que, por hipóstese, consideramos significativa para explicar a eficiência do veículo, podemos notar que os pesos variam de 1.513 até 5.424, tendo a média e a mediana com valores próximos (3.217 e 3.352, respectivamente).\n5. Em todas as variáveis podemos perceber uma relativa proximidade entre a média e a mediana, o que pode ser uma indício de baixa dispersão em nossos dados.\nVamos analisar o comportamento de cada uma dessas variáveis, duas a duas:\n\n\nShow code\n\nlibrary(corrplot)\nlibrary(GGally)\n\ndf_correlacao = data.frame(scale(mtcars))\ncorrplot.mixed(cor(df_correlacao), order=\"hclust\", tl.col=\"black\")\n\n\n\nShow code\n\nggpairs(df_correlacao, lower = list(continuous = \"smooth\"))\n\n\n\n\nCom os dados normalizados podemos percerber que a variável mpg se correlaciona com todas as outras (algumas de forma positiva e forte, como por exemplo drat e vs e outras negativamente, como disp, cyl e wt). Porém, algumas dessas variáveis também se correlacionam entre si de forma considerável, o que pode ser um problema na construção de um possível modelo linear múltiplo.\nA variável vs apresenta informações sobre o formato do motor, podendo o mesmo ser em formato “v” ou “reto”, enquanto am nos informa se temos um veículo automático ou mecânico. Vamos olhar separadamente para cada uma delas.\n\n\nShow code\n\ndf_am_vs = mtcars\ndf_am_vs$am = as.factor(df_am_vs$am)\ndf_am_vs$vs = as.factor(df_am_vs$vs)\n\n\nggpairs(data=df_am_vs[,c(1,6,9)],\n        title=\"Carros\", \n        colour = \"am\", ggplot2::aes(colour=am)) \n\n\n\n\nNa análise de correlação, wt foi a variável que apresentou maior correlação negativa com mpg. Quando separamos os carros em dois grupos através de am (automáticos ou não) podemos perceber que que existe uma certa divisão em relação a cada um desses grupos, o que pode ser um indício de ganho com essa possível interação na construção do modelo.\nDe forma análoga vamos analisar a variável vs:\n\n\nShow code\n\nggpairs(data=df_am_vs[,c(1,6,8)],\n        title=\"Carros\", \n        colour = \"vs\", ggplot2::aes(colour=vs)) \n\n\n\n\nA separação dos dados considerando-se os dois tipos de motores também pode ser um ganho na construção do nosso modelo.\n3. MODELAGEM\nNossa modelagem terá variável resposta mpg. Para tentar explicar tal variável através de um modelo linear, analisaremos quais as variáveis que apresentam melhor desempenho e seu impacto nessa explicação. Com os dados normalizados, nossa primeira tentativa consiste na construção de um modelo que leva em consideração todas as outras variáveis para essa explicação.\n\n\nShow code\n\n#normalizando\n\ndf_cars_norm = data.frame(scale(mtcars))\n\n#modelando\n\nmodel_cars = lm(mpg~., df_cars_norm)\nsummary(model_cars)\n\n\n\nCall:\nlm(formula = mpg ~ ., data = df_cars_norm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.57254 -0.26620 -0.01985  0.20230  0.76773 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept) -1.613e-17  7.773e-02   0.000   1.0000  \ncyl         -3.302e-02  3.097e-01  -0.107   0.9161  \ndisp         2.742e-01  3.672e-01   0.747   0.4635  \nhp          -2.444e-01  2.476e-01  -0.987   0.3350  \ndrat         6.983e-02  1.451e-01   0.481   0.6353  \nwt          -6.032e-01  3.076e-01  -1.961   0.0633 .\nqsec         2.434e-01  2.167e-01   1.123   0.2739  \nvs           2.657e-02  1.760e-01   0.151   0.8814  \nam           2.087e-01  1.703e-01   1.225   0.2340  \ngear         8.023e-02  1.828e-01   0.439   0.6652  \ncarb        -5.344e-02  2.221e-01  -0.241   0.8122  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4397 on 21 degrees of freedom\nMultiple R-squared:  0.869, Adjusted R-squared:  0.8066 \nF-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07\n\nO primeiro modelo tendo como preditoras todas as demais variáveis apresentou valores não significativos para cada uma delas. O comando summary nos permite concluir a partir do teste de hipótese (olhando para o p-valor) que, juntas, elas não tem poder de explicação. Provelmente isso se deve ao fato de existirem muitas variáveis correlacionadas entre si, quando olhamos para as variáveis preditoras.\nVoltando para a análise de correlação, observa-se que mpg tem forte correlação positiva com vs, drat, am, gear e que essas variáveis, entre si, não se correlaciona tão bem assim. Vamos para um novo teste de modelagem.\n\n\nShow code\n\nmodel_cars2 = lm(mpg~vs+am+gear+drat, df_cars_norm)\nsummary(model_cars2)\n\n\n\nCall:\nlm(formula = mpg ~ vs + am + gear + drat, data = df_cars_norm)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0859 -0.4173  0.0132  0.3340  0.9418 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  9.126e-17  1.024e-01   0.000 1.000000    \nvs           5.181e-01  1.191e-01   4.350 0.000174 ***\nam           4.889e-01  1.863e-01   2.624 0.014131 *  \ngear        -1.721e-01  1.803e-01  -0.955 0.348251    \ndrat         2.250e-01  1.750e-01   1.286 0.209375    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5791 on 27 degrees of freedom\nMultiple R-squared:  0.7079,    Adjusted R-squared:  0.6647 \nF-statistic: 16.36 on 4 and 27 DF,  p-value: 6.423e-07\n\nNotamos uma representatividade apenas com vs e am no modelo. Apesar do R2 ajustado ter apresentado um valor menor que o do modelo anterior, aqui obtivemos coeficientes mais representativos para essas variáveis. Porém essas duas variáveis apresentam características binárias que, isoladamente, não seriam capazes de explicar o desempenho de um veículo.\nEm se tratando de desempenho veicular, estudos mostram que o peso (wt), a quantidade de cilindros (cyl) e a potência bruta (hp) podem ser influenciadores diretos de desempenho. Vamos verificar:\n\n\nShow code\n\nmodel_cars3 = lm(mpg~wt+cyl+hp, df_cars_norm)\nsummary(model_cars3)\n\n\n\nCall:\nlm(formula = mpg ~ wt + cyl + hp, data = df_cars_norm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.65191 -0.25880 -0.08813  0.19662  0.97870 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.676e-17  7.367e-02   0.000 1.000000    \nwt          -5.141e-01  1.202e-01  -4.276 0.000199 ***\ncyl         -2.790e-01  1.632e-01  -1.709 0.098480 .  \nhp          -2.052e-01  1.351e-01  -1.519 0.140015    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4167 on 28 degrees of freedom\nMultiple R-squared:  0.8431,    Adjusted R-squared:  0.8263 \nF-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11\n\nApenas wt apresentou significância. A correlação entre as outras certamente impacta na nossa construção.\nQuando olhamos separadamente para am percebemos uma divisão bem definida em relação as duas características dessa variável. Como wt é o fator com maior correlação com nossa variável resposta, vamos construir um modelo com essa interação e analisar as métricas.\n\n\nShow code\n\ndf_interacao = data.frame(scale(mtcars[,c(1,6)]))\ndf_interacao = cbind(df_interacao, mtcars$am)\nnames(df_interacao)[3]='am'\ndf_interacao$am = ifelse(df_interacao$am==0, 'automatico', 'manual')\n\nmodel_cars4 = lm(mpg~wt*am, df_interacao)\nsummary(model_cars4)\n\n\n\nCall:\nlm(formula = mpg ~ wt * am, data = df_interacao)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.59738 -0.25628 -0.08836  0.14953  1.01061 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.1418     0.1221  -1.162  0.25509    \nwt           -0.6146     0.1275  -4.819 4.55e-05 ***\nammanual     -0.3597     0.2354  -1.528  0.13779    \nwt:ammanual  -0.8602     0.2345  -3.667  0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4299 on 28 degrees of freedom\nMultiple R-squared:  0.833, Adjusted R-squared:  0.8151 \nF-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11\n\nNessa situação podemos notar que o coeficiente ammanual não possui significância para o modelo e o R2 ajustado apresenta resultado siginificativo (0.8151).\nDe forma análoga, vamos promover a interação de wt com a variável vs:\n\n\nShow code\n\ndf_interacao_2 = cbind(df_interacao[,c(1,2)], mtcars$vs)\nnames(df_interacao_2)[3]='vs'\ndf_interacao_2$vs = ifelse(df_interacao_2$vs==0, 'v', 'reto')\n\nmodel_cars5 = lm(mpg~wt*vs, df_interacao_2)\nsummary(model_cars5)\n\n\n\nCall:\nlm(formula = mpg ~ wt * vs, data = df_interacao_2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6629 -0.2967 -0.0568  0.2146  0.8638 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.09651    0.15222   0.634   0.5312    \nwt          -1.04081    0.16232  -6.412 6.08e-07 ***\nvsv         -0.39911    0.19041  -2.096   0.0452 *  \nwt:vsv       0.47238    0.19736   2.393   0.0236 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4277 on 28 degrees of freedom\nMultiple R-squared:  0.8348,    Adjusted R-squared:  0.8171 \nF-statistic: 47.16 on 3 and 28 DF,  p-value: 4.497e-11\n\nPercebe-se que todos os coeficientes tem significância para o modelo e que o mesmo apresentou um bom valor do R2 ajustado (0,8171).\n4. Diagnóstico do modelo:\nCom base nos testes realizados e nas métricas avaliadas, o model_cars5, que foi o último modelo construído e que leva em consideração a interação de vs com wt para uma possível explicação de mpg, foi o que apresentou melhor desempenho até agora. Continuaremos nossas análises com o diagnóstico residual desse modelo.\n\n\nShow code\n\npar(mfrow = c(2,2))\nplot(model_cars5, which = (1:4), pch=20)\n\n\n\nShow code\n\nshapiro.test(model_cars5$residuals)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  model_cars5$residuals\nW = 0.95567, p-value = 0.2084\n\nPodemos perceber uma distribuição aleatória dos resíduos com alguns pontos no gráfico Normal Q-Q que podem indicar uma não normalidade dos resíduos, porém o teste de normalidade nos mostra que não devemos rejeitar a hipótese de que essa distribuição é normal. Vamos verificar uma possível presença de outliers para buscar um melhor ajuste.\n\n\nShow code\n\nlibrary(plotly)\na = ggplot(df_interacao_2)+\n  geom_boxplot(aes(x = vs, y=mpg))\n\nggplotly(a)\n\n\n\n{\"x\":{\"data\":[{\"x\":[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.150884824647657,0.150884824647657,-0.960788934955696,-0.612353875975541,-0.230734525663942,-0.811459623964201,-1.60788261591884,-1.60788261591884,-0.463024564984046,-0.761683186967036,-0.811459623964201,-1.12671039161291,-0.89442035229281,-0.0648130690067253,0.980492107933741,-0.147773797335334,-0.844643915295645,-0.711906749969871,0.217253407310543,-0.330287399658272,0.715017777282194,-0.147773797335334,0.449543446630647,2.29127161552575,0.449543446630647,2.04238943053993,-0.380063836655437,1.7105465172255,0.233845552976265,1.19619000158812,1.7105465172255,0.217253407310543],\"hoverinfo\":\"y\",\"type\":\"box\",\"fillcolor\":\"rgba(255,255,255,1)\",\"marker\":{\"opacity\":null,\"outliercolor\":\"rgba(0,0,0,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"},\"size\":5.66929133858268},\"line\":{\"color\":\"rgba(51,51,51,1)\",\"width\":1.88976377952756},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":28.1765601217656,\"r\":7.30593607305936,\"b\":42.130898021309,\"l\":37.2602739726027},\"plot_bgcolor\":\"rgba(235,235,235,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,2.6],\"tickmode\":\"array\",\"ticktext\":[\"reto\",\"v\"],\"tickvals\":[1,2],\"categoryorder\":\"array\",\"categoryarray\":[\"reto\",\"v\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"vs\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-1.80284032749107,2.48622932709798],\"tickmode\":\"array\",\"ticktext\":[\"-1\",\"0\",\"1\",\"2\"],\"tickvals\":[-1,0,1,2],\"categoryorder\":\"array\",\"categoryarray\":[\"-1\",\"0\",\"1\",\"2\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"mpg\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.88976377952756,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"81675bd3020c\":{\"x\":{},\"y\":{},\"type\":\"box\"}},\"cur_data\":\"81675bd3020c\",\"visdat\":{\"81675bd3020c\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nEm relação a variável mpg podemos notar a presença de um outlier em motores do tipo v. Vamos substituir esse valor pela média e analisar o comportamento do nosso modelo.\n\n\nShow code\n\ndf_interacao_2$mpg[27]= mean(df_interacao_2$mpg)\n\nnovo_model_car = lm(mpg~wt*vs, df_interacao_2)\nsummary(novo_model_car)\n\n\n\nCall:\nlm(formula = mpg ~ wt * vs, data = df_interacao_2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6629 -0.2656 -0.1185  0.2787  0.8638 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.09651    0.14386   0.671  0.50781    \nwt          -1.04081    0.15341  -6.784 2.28e-07 ***\nvsv         -0.50509    0.17996  -2.807  0.00901 ** \nwt:vsv       0.57931    0.18653   3.106  0.00432 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4042 on 28 degrees of freedom\nMultiple R-squared:  0.8476,    Adjusted R-squared:  0.8312 \nF-statistic: 51.89 on 3 and 28 DF,  p-value: 1.469e-11\n\nShow code\n\npar(mfrow = c(2,2))\nplot(novo_model_car, which = (1:4), pch=20)\n\n\n\nShow code\n\nshapiro.test(novo_model_car$residuals)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  novo_model_car$residuals\nW = 0.95634, p-value = 0.2176\n\nApós o tratamento desse ponto, notamos que houve uma melhora em relação ao R2 ajustado e em relação aos resíduos, podemos perceber um ajuste mais suave e uma melhor distribuição.\nGraficamente:\n\n\nShow code\n\nlibrary(plotly)\nplot_final = df_interacao_2 %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(colour = vs)) +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"black\")+\n  geom_abline(intercept =  0.09651, slope = -1.04081, colour = \"red\") + # reto\n  geom_abline(intercept =  0.09651-0.50509 , slope = -1.04081+0.57931 , colour = \"green\")+ # v\n  theme(legend.position = \"bottom\")\n\nggplotly(plot_final)\n\n\n\n{\"x\":{\"data\":[{\"x\":[-0.917004624399846,-0.00229953792688741,0.248094591889733,-0.0278499593367465,-0.0687306335925212,0.227654254761845,0.227654254761845,-1.03964664716717,-1.63752650815787,-1.41268279975111,-0.768812180222662,-1.31048111411168,-1.7417722275101,-0.446876870458437],\"y\":[0.449543446630647,0.217253407310543,-0.330287399658272,0.715017777282194,0.449543446630647,-0.147773797335334,-0.380063836655437,2.04238943053993,1.7105465172255,2.29127161552575,0.233845552976265,1.19619000158812,1.7105465172255,0.217253407310543],\"text\":[\"vs: reto<br />wt: -0.917004624<br />mpg:  4.495434e-01\",\"vs: reto<br />wt: -0.002299538<br />mpg:  2.172534e-01\",\"vs: reto<br />wt:  0.248094592<br />mpg: -3.302874e-01\",\"vs: reto<br />wt: -0.027849959<br />mpg:  7.150178e-01\",\"vs: reto<br />wt: -0.068730634<br />mpg:  4.495434e-01\",\"vs: reto<br />wt:  0.227654255<br />mpg: -1.477738e-01\",\"vs: reto<br />wt:  0.227654255<br />mpg: -3.800638e-01\",\"vs: reto<br />wt: -1.039646647<br />mpg:  2.042389e+00\",\"vs: reto<br />wt: -1.637526508<br />mpg:  1.710547e+00\",\"vs: reto<br />wt: -1.412682800<br />mpg:  2.291272e+00\",\"vs: reto<br />wt: -0.768812180<br />mpg:  2.338456e-01\",\"vs: reto<br />wt: -1.310481114<br />mpg:  1.196190e+00\",\"vs: reto<br />wt: -1.741772228<br />mpg:  1.710547e+00\",\"vs: reto<br />wt: -0.446876870<br />mpg:  2.172534e-01\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(248,118,109,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(248,118,109,1)\"}},\"hoveron\":\"points\",\"name\":\"reto\",\"legendgroup\":\"reto\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[-0.610399567481535,-0.349785269100972,0.227654254761845,0.360516446093113,0.871524874290296,0.524039143116211,0.57513998593593,2.07750476483565,2.25533569784827,2.17459636619311,0.309415603273395,0.222544170479873,0.636460997319592,0.641571081601564,-1.10096765855083,-0.0482902964646338,-0.45709703902238,0.360516446093113],\"y\":[0.150884824647657,0.150884824647657,-0.230734525663942,-0.960788934955696,-0.612353875975541,-0.463024564984046,-0.811459623964201,-1.60788261591884,-1.60788261591884,-0.89442035229281,-0.761683186967036,-0.811459623964201,-1.12671039161291,-0.147773797335334,7.11236625150491e-17,-0.711906749969871,-0.0648130690067253,-0.844643915295645],\"text\":[\"vs: v<br />wt: -0.610399567<br />mpg:  1.508848e-01\",\"vs: v<br />wt: -0.349785269<br />mpg:  1.508848e-01\",\"vs: v<br />wt:  0.227654255<br />mpg: -2.307345e-01\",\"vs: v<br />wt:  0.360516446<br />mpg: -9.607889e-01\",\"vs: v<br />wt:  0.871524874<br />mpg: -6.123539e-01\",\"vs: v<br />wt:  0.524039143<br />mpg: -4.630246e-01\",\"vs: v<br />wt:  0.575139986<br />mpg: -8.114596e-01\",\"vs: v<br />wt:  2.077504765<br />mpg: -1.607883e+00\",\"vs: v<br />wt:  2.255335698<br />mpg: -1.607883e+00\",\"vs: v<br />wt:  2.174596366<br />mpg: -8.944204e-01\",\"vs: v<br />wt:  0.309415603<br />mpg: -7.616832e-01\",\"vs: v<br />wt:  0.222544170<br />mpg: -8.114596e-01\",\"vs: v<br />wt:  0.636460997<br />mpg: -1.126710e+00\",\"vs: v<br />wt:  0.641571082<br />mpg: -1.477738e-01\",\"vs: v<br />wt: -1.100967659<br />mpg:  7.112366e-17\",\"vs: v<br />wt: -0.048290296<br />mpg: -7.119067e-01\",\"vs: v<br />wt: -0.457097039<br />mpg: -6.481307e-02\",\"vs: v<br />wt:  0.360516446<br />mpg: -8.446439e-01\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,191,196,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,191,196,1)\"}},\"hoveron\":\"points\",\"name\":\"v\",\"legendgroup\":\"v\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[-1.7417722275101,-1.69117592465746,-1.64057962180482,-1.58998331895219,-1.53938701609955,-1.48879071324691,-1.43819441039427,-1.38759810754164,-1.337001804689,-1.28640550183636,-1.23580919898372,-1.18521289613109,-1.13461659327845,-1.08402029042581,-1.03342398757317,-0.982827684720536,-0.932231381867898,-0.881635079015261,-0.831038776162623,-0.780442473309985,-0.729846170457348,-0.67924986760471,-0.628653564752073,-0.578057261899435,-0.527460959046798,-0.47686465619416,-0.426268353341522,-0.375672050488885,-0.325075747636247,-0.27447944478361,-0.223883141930972,-0.173286839078334,-0.122690536225697,-0.0720942333730594,-0.0214979305204217,0.0290983723322158,0.0796946751848533,0.130290978037491,0.180887280890129,0.231483583742766,0.282079886595404,0.332676189448041,0.383272492300679,0.433868795153316,0.484465098005954,0.535061400858591,0.585657703711229,0.636254006563867,0.686850309416504,0.737446612269142,0.78804291512178,0.838639217974417,0.889235520827055,0.939831823679692,0.99042812653233,1.04102442938497,1.09162073223761,1.14221703509024,1.19281333794288,1.24340964079552,1.29400594364816,1.34460224650079,1.39519854935343,1.44579485220607,1.49639115505871,1.54698745791134,1.59758376076398,1.64818006361662,1.69877636646926,1.74937266932189,1.79996897217453,1.85056527502717,1.90116157787981,1.95175788073244,2.00235418358508,2.05295048643772,2.10354678929036,2.15414309214299,2.20473939499563,2.25533569784827],\"y\":[1.4199721789521,1.37783370004365,1.3356952211352,1.29355674222675,1.25141826331831,1.20927978440986,1.16714130550141,1.12500282659296,1.08286434768451,1.04072586877606,0.998587389867613,0.956448910959164,0.914310432050715,0.872171953142266,0.830033474233817,0.787894995325368,0.745756516416919,0.703618037508471,0.661479558600022,0.619341079691573,0.577202600783124,0.535064121874675,0.492925642966226,0.450787164057777,0.408648685149328,0.366510206240879,0.324371727332431,0.282233248423982,0.240094769515533,0.197956290607084,0.155817811698635,0.113679332790186,0.0715408538817373,0.0294023749732885,-0.0127361039351605,-0.0548745828436093,-0.0970130617520581,-0.139151540660507,-0.181290019568956,-0.223428498477405,-0.265566977385854,-0.307705456294303,-0.349843935202751,-0.3919824141112,-0.434120893019649,-0.476259371928098,-0.518397850836547,-0.560536329744996,-0.602674808653445,-0.644813287561894,-0.686951766470343,-0.729090245378791,-0.77122872428724,-0.813367203195689,-0.855505682104138,-0.897644161012587,-0.939782639921036,-0.981921118829485,-1.02405959773793,-1.06619807664638,-1.10833655555483,-1.15047503446328,-1.19261351337173,-1.23475199228018,-1.27689047118863,-1.31902895009708,-1.36116742900552,-1.40330590791397,-1.44544438682242,-1.48758286573087,-1.52972134463932,-1.57185982354777,-1.61399830245622,-1.65613678136467,-1.69827526027312,-1.74041373918156,-1.78255221809001,-1.82469069699846,-1.86682917590691,-1.90896765481536],\"text\":[\"wt: -1.74177223<br />mpg:  1.41997218\",\"wt: -1.69117592<br />mpg:  1.37783370\",\"wt: -1.64057962<br />mpg:  1.33569522\",\"wt: -1.58998332<br />mpg:  1.29355674\",\"wt: -1.53938702<br />mpg:  1.25141826\",\"wt: -1.48879071<br />mpg:  1.20927978\",\"wt: -1.43819441<br />mpg:  1.16714131\",\"wt: -1.38759811<br />mpg:  1.12500283\",\"wt: -1.33700180<br />mpg:  1.08286435\",\"wt: -1.28640550<br />mpg:  1.04072587\",\"wt: -1.23580920<br />mpg:  0.99858739\",\"wt: -1.18521290<br />mpg:  0.95644891\",\"wt: -1.13461659<br />mpg:  0.91431043\",\"wt: -1.08402029<br />mpg:  0.87217195\",\"wt: -1.03342399<br />mpg:  0.83003347\",\"wt: -0.98282768<br />mpg:  0.78789500\",\"wt: -0.93223138<br />mpg:  0.74575652\",\"wt: -0.88163508<br />mpg:  0.70361804\",\"wt: -0.83103878<br />mpg:  0.66147956\",\"wt: -0.78044247<br />mpg:  0.61934108\",\"wt: -0.72984617<br />mpg:  0.57720260\",\"wt: -0.67924987<br />mpg:  0.53506412\",\"wt: -0.62865356<br />mpg:  0.49292564\",\"wt: -0.57805726<br />mpg:  0.45078716\",\"wt: -0.52746096<br />mpg:  0.40864869\",\"wt: -0.47686466<br />mpg:  0.36651021\",\"wt: -0.42626835<br />mpg:  0.32437173\",\"wt: -0.37567205<br />mpg:  0.28223325\",\"wt: -0.32507575<br />mpg:  0.24009477\",\"wt: -0.27447944<br />mpg:  0.19795629\",\"wt: -0.22388314<br />mpg:  0.15581781\",\"wt: -0.17328684<br />mpg:  0.11367933\",\"wt: -0.12269054<br />mpg:  0.07154085\",\"wt: -0.07209423<br />mpg:  0.02940237\",\"wt: -0.02149793<br />mpg: -0.01273610\",\"wt:  0.02909837<br />mpg: -0.05487458\",\"wt:  0.07969468<br />mpg: -0.09701306\",\"wt:  0.13029098<br />mpg: -0.13915154\",\"wt:  0.18088728<br />mpg: -0.18129002\",\"wt:  0.23148358<br />mpg: -0.22342850\",\"wt:  0.28207989<br />mpg: -0.26556698\",\"wt:  0.33267619<br />mpg: -0.30770546\",\"wt:  0.38327249<br />mpg: -0.34984394\",\"wt:  0.43386880<br />mpg: -0.39198241\",\"wt:  0.48446510<br />mpg: -0.43412089\",\"wt:  0.53506140<br />mpg: -0.47625937\",\"wt:  0.58565770<br />mpg: -0.51839785\",\"wt:  0.63625401<br />mpg: -0.56053633\",\"wt:  0.68685031<br />mpg: -0.60267481\",\"wt:  0.73744661<br />mpg: -0.64481329\",\"wt:  0.78804292<br />mpg: -0.68695177\",\"wt:  0.83863922<br />mpg: -0.72909025\",\"wt:  0.88923552<br />mpg: -0.77122872\",\"wt:  0.93983182<br />mpg: -0.81336720\",\"wt:  0.99042813<br />mpg: -0.85550568\",\"wt:  1.04102443<br />mpg: -0.89764416\",\"wt:  1.09162073<br />mpg: -0.93978264\",\"wt:  1.14221704<br />mpg: -0.98192112\",\"wt:  1.19281334<br />mpg: -1.02405960\",\"wt:  1.24340964<br />mpg: -1.06619808\",\"wt:  1.29400594<br />mpg: -1.10833656\",\"wt:  1.34460225<br />mpg: -1.15047503\",\"wt:  1.39519855<br />mpg: -1.19261351\",\"wt:  1.44579485<br />mpg: -1.23475199\",\"wt:  1.49639116<br />mpg: -1.27689047\",\"wt:  1.54698746<br />mpg: -1.31902895\",\"wt:  1.59758376<br />mpg: -1.36116743\",\"wt:  1.64818006<br />mpg: -1.40330591\",\"wt:  1.69877637<br />mpg: -1.44544439\",\"wt:  1.74937267<br />mpg: -1.48758287\",\"wt:  1.79996897<br />mpg: -1.52972134\",\"wt:  1.85056528<br />mpg: -1.57185982\",\"wt:  1.90116158<br />mpg: -1.61399830\",\"wt:  1.95175788<br />mpg: -1.65613678\",\"wt:  2.00235418<br />mpg: -1.69827526\",\"wt:  2.05295049<br />mpg: -1.74041374\",\"wt:  2.10354679<br />mpg: -1.78255222\",\"wt:  2.15414309<br />mpg: -1.82469070\",\"wt:  2.20473939<br />mpg: -1.86682918\",\"wt:  2.25533570<br />mpg: -1.90896765\"],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"fitted values\",\"line\":{\"width\":3.77952755905512,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[-1.94162762377802,2.45519109411619],\"y\":[2.1173754471044,-2.45887744266707],\"text\":\"intercept: 0.09651<br />slope: -1.04081\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[-1.94162762377802,2.45519109411619],\"y\":[0.487481148373555,-1.54165068993462],\"text\":\"intercept: -0.40858<br />slope: -0.4615\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,255,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":28.1765601217656,\"r\":7.30593607305936,\"b\":42.130898021309,\"l\":37.2602739726027},\"plot_bgcolor\":\"rgba(235,235,235,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-1.94162762377802,2.45519109411619],\"tickmode\":\"array\",\"ticktext\":[\"-1\",\"0\",\"1\",\"2\"],\"tickvals\":[-1,0,1,2],\"categoryorder\":\"array\",\"categoryarray\":[\"-1\",\"0\",\"1\",\"2\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"wt\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-2.11897961833242,2.50128357904281],\"tickmode\":\"array\",\"ticktext\":[\"-2\",\"-1\",\"0\",\"1\",\"2\"],\"tickvals\":[-2,-1,0,1,2],\"categoryorder\":\"array\",\"categoryarray\":[\"-2\",\"-1\",\"0\",\"1\",\"2\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"mpg\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.88976377952756,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"y\":0.972933070866142},\"annotations\":[{\"text\":\"vs\",\"x\":1.02,\"y\":1,\"showarrow\":false,\"ax\":0,\"ay\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xref\":\"paper\",\"yref\":\"paper\",\"textangle\":-0,\"xanchor\":\"left\",\"yanchor\":\"bottom\",\"legendTitle\":true}],\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"81674b16c77\":{\"colour\":{},\"x\":{},\"y\":{},\"type\":\"scatter\"},\"816775fc9fb7\":{\"x\":{},\"y\":{}},\"81672a869457\":{\"intercept\":{},\"slope\":{}},\"816740a98ae7\":{\"intercept\":{},\"slope\":{}}},\"cur_data\":\"81674b16c77\",\"visdat\":{\"81674b16c77\":[\"function (y) \",\"x\"],\"816775fc9fb7\":[\"function (y) \",\"x\"],\"81672a869457\":[\"function (y) \",\"x\"],\"816740a98ae7\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\n5. Conclusão e discussão\nTodas as variáveis analisadas possuem correlação com a nossa variável resposta, ou seja, o desempenho veicular poderia ser explicado de inúmeras formas. Após alguns testes com essas variáveis foi possível perceber que o peso (wt) era a variável que melhor se comportava nessa explicação e que, quando combinada com outras variáveis acabava tendo um desempenho inferior. Porém o formato do motor (vs) quando combinado com o peso (wt) apresentava uma ganho nas métricas do nosso modelo.\nAssim o modelo final leva em consideração a interação entre as variáveis wt e vs, apresentando coeficentes significantes para ambas, e melhores métricas conforme verificado em nossos testes de hipóteses através do comando summary. Segue os detalhes do nosso modelo final:\n\n\nShow code\n\nmodelo_final = novo_model_car\nsummary(modelo_final)\n\n\n\nCall:\nlm(formula = mpg ~ wt * vs, data = df_interacao_2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6629 -0.2656 -0.1185  0.2787  0.8638 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.09651    0.14386   0.671  0.50781    \nwt          -1.04081    0.15341  -6.784 2.28e-07 ***\nvsv         -0.50509    0.17996  -2.807  0.00901 ** \nwt:vsv       0.57931    0.18653   3.106  0.00432 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4042 on 28 degrees of freedom\nMultiple R-squared:  0.8476,    Adjusted R-squared:  0.8312 \nF-statistic: 51.89 on 3 and 28 DF,  p-value: 1.469e-11\n\nShow code\n\nmodelo_final$coefficients\n\n\n(Intercept)          wt         vsv      wt:vsv \n 0.09651164 -1.04080989 -0.50509226  0.57931189 \n\nComo mencionado, nosso modelo final construído com a interação entre wt e vs leva como casela de referência motores do tipo reto e está representado da seguinte forma:\nmpg = 0.09651 - 1.0481 beta1 + (0.09651 - 0.50509) + (-1.0481 + 0.57931) beta2.\n\n\n\n",
    "preview": "posts/2021-04-18-carlos-eduardo/carlos-eduardo-tcc_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-05-05T14:15:44-03:00",
    "input_file": "carlos-eduardo-tcc.utf8.md"
  },
  {
    "path": "posts/2021-02-05-anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974/",
    "title": "Análise do Consumo Médio de Combustível de Carros Modelos 1973/1974",
    "description": "O conjunto de dados, denominado de `mtcars`, foi obtido a partir das edições de março, abril, junho e julho de 1974 da revista *Motor Trend* para um estudo realizado por Hocking (1976) e posteriormente, reportado por Henderson e Velleman (1981). Os dados, em questão, são referentes ao consumo de gasolina e dez características físicas de 32 automóveis modelos 1973-1974.",
    "author": [
      {
        "name": "Elizabeth Mie Hashimoto",
        "url": "https://www.linkedin.com/in/elizabeth-mie-hashimoto-a416a917/"
      }
    ],
    "date": "2021-02-05",
    "categories": [],
    "contents": "\n\nContents\nIntrodução\nAnálise Exploratória\nModelagem\nDiagnóstico do Modelo\nDados completo\nDados reduzidos\n\nConclusão e Discussão\nAgradecimentos\nReferências bibliográficas\n\n\n\nShow code\n\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(gtsummary)\nlibrary(xtable)\n\n\n\nVERSÃO PDF\nIntrodução\nNa crise petrolífera de 1973, membros da Organização dos Países Árabes Exportadores de Petróleo (OPAEP) aplicaram sanções em protesto ao apoio dos Estados Unidos e outras nações à Israel durante a Guerra do Yom Kippur. O conflito resultou no aumento do preço do petróleo de três dólares por barril para cerca de 12 doláres no mundo inteiro, sendo que os preços fixados para os Estados Unidos foram ainda maiores.\nComo uma alternativa à alta do preço do petróleo no mercado mundial, os Estados Unidos iniciaram um programa de eficiência energética, conhecido como Corporate Average Fuel Economy (CAFE), com o propósito de reduzir o consumo de combustível de carros, pick-ups, minivans e SUVs (Almeida Filho, 2018).\nAcredita-se que a melhoria no consumo médio de combustível dos automóveis leva à redução das contas de importação de petróleo, ou seja, pode resultar em economias estimadas nas contas anuais de importação de petróleo no valor de 300 bilhões de dólares em 2025 e 600 bilhões em 2050 (Global fuel economy initiative, 2021). Por outro lado, a eficiência do combustível depende de muitas características do veículo, incluindo as especificações do motor, resistência aerodinâmica, peso, combustível e entre outros atributos.\nNesse contexto, buscou-se validar a hipótese de que modificações na estrutura do automóvel aumenta o seu consumo médio. Portanto, o presente trabalho teve como objetivo identificar quais características do carro explica a sua eficiência medida em milhas por galão. As análises foram feitas utilizando o software R versão 4.0.3, considerando um nível de significância de 5%.\nAnálise Exploratória\nO conjunto de dados, denominado de mtcars, foi obtido a partir das edições de março, abril, junho e julho de 1974 da revista Motor Trend para um estudo realizado por Hocking (1976) e posteriormente, reportado por Henderson e Velleman (1981). Os dados, em questão, são referentes ao consumo de gasolina e dez características físicas de 32 automóveis modelos 1973-1974. O mesmo está disponível na biblioteca datasets do software R para consulta.\nDessa forma, de acordo com a hipótese formulada, as variáveis observadas no conjunto de dados são definidas como:\n\\(\\checkmark\\) Variável resposta\nmpg: eficiência (milhas por galão de combustível).\n\\(\\checkmark\\) Variável explicativa\ncyl: número de cilindros.\ndisp: cilindradas (polegada cúbica).\nhp: potência bruta (HP).\ndrat: relação de eixo traseiro.\nwt: peso (1000 libras).\nqsec: tempo no quarto de milha (segundos).\nvs: formato do motor (0 = V e 1 = linha).\nam: tipo de transmissão (0 = automático e 1 = manual).\ngear: número de marchas para frente.\ncarb: número de carburadores.\nPara reduzir as informações do conjunto de dados, estatísticas descritivas de cada uma das variáveis quantitativas foram obtidas e apresentadas na Tabela 1. Os resultados mostram que não há nenhuma dado faltante e portanto, não há necessidade de imputar valores. Além disso, em média, a eficiência dos carros é de 20,09 mpg e são carros com 2 carburadores, seis cilindros e peso de 3,22 \\(\\times 1000\\) libras.\n\n\nShow code\n\nresumo <- mtcars %>%\n  select(-am,-vs) %>% \n  pivot_longer(everything()) %>%\n  group_by(name) %>% \n  summarise_at(\"value\", \n               list(Missing =~sum(is.na(.)),media=~mean(.),\n                    desvPad=~sd(.), minimo=~min(.),\n                    Q1=~quantile(.,0.25),med=~median(.),\n                    Q3=~quantile(.,0.75),maxi=~max(.))) %>% \n  mutate_if(is.numeric, format, digits=3,nsmall = 2)\n\ncolnames(resumo) <- c('Variável', 'Missing', 'Média',\n                      'Desvio padrão', 'Mínimo', 'Q1',\n                      'Mediana', 'Q3', 'Máximo')\nkbl(resumo, booktabs = T, caption = 'Estatísticas descritivas das variáveis de natureza quantitativa', longtable = T) %>% \n  kable_styling(position = 'center',latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 1: Estatísticas descritivas das variáveis de natureza quantitativa\n\n\nVariável\n\n\nMissing\n\n\nMédia\n\n\nDesvio padrão\n\n\nMínimo\n\n\nQ1\n\n\nMediana\n\n\nQ3\n\n\nMáximo\n\n\ncarb\n\n\n0\n\n\n2.81\n\n\n1.615\n\n\n1.00\n\n\n2.00\n\n\n2.00\n\n\n4.00\n\n\n8.00\n\n\ncyl\n\n\n0\n\n\n6.19\n\n\n1.786\n\n\n4.00\n\n\n4.00\n\n\n6.00\n\n\n8.00\n\n\n8.00\n\n\ndisp\n\n\n0\n\n\n230.72\n\n\n123.939\n\n\n71.10\n\n\n120.83\n\n\n196.30\n\n\n326.00\n\n\n472.00\n\n\ndrat\n\n\n0\n\n\n3.60\n\n\n0.535\n\n\n2.76\n\n\n3.08\n\n\n3.70\n\n\n3.92\n\n\n4.93\n\n\ngear\n\n\n0\n\n\n3.69\n\n\n0.738\n\n\n3.00\n\n\n3.00\n\n\n4.00\n\n\n4.00\n\n\n5.00\n\n\nhp\n\n\n0\n\n\n146.69\n\n\n68.563\n\n\n52.00\n\n\n96.50\n\n\n123.00\n\n\n180.00\n\n\n335.00\n\n\nmpg\n\n\n0\n\n\n20.09\n\n\n6.027\n\n\n10.40\n\n\n15.43\n\n\n19.20\n\n\n22.80\n\n\n33.90\n\n\nqsec\n\n\n0\n\n\n17.85\n\n\n1.787\n\n\n14.50\n\n\n16.89\n\n\n17.71\n\n\n18.90\n\n\n22.90\n\n\nwt\n\n\n0\n\n\n3.22\n\n\n0.978\n\n\n1.51\n\n\n2.58\n\n\n3.33\n\n\n3.61\n\n\n5.42\n\n\nNa Figura 1 é apresentada um correlograma das variáveis explicativas. Por meio do gráfico, observou-se que as variáveis explicativas apresentavam uma alta correlação, ou seja, há indicativos de problema de multicolinearidade.\n\n\nShow code\n\nmtcars %>% \n  select(-vs,-am, -mpg) %>% \n  ggpairs() \n\n\n\n\nFigure 1: Matriz de correlação das variáveis explicativas quantitativas\n\n\n\nNa Figura 2 são apresentados os gráficos de dispersão, na qual observou-se que uma relação linear da variável resposta com as variáveis , ,  e . Nas demais variáveis, a relação tende a ser não linear.\n\n\nShow code\n\n# Gráfico de dispersão\n\nfig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point() +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)')\n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point() +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)')\n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point() +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point() +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point() +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)')\n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point() +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point() +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point() +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\n#grid.arrange(fig2, fig3, fig4, fig5, fig6, ncol = 3, nrow = 2)\n\ngrid.arrange(fig1, fig2, fig3, fig4, fig5, fig6, fig7, fig8, ncol = 3, nrow = 3)\n\n\n\n\nFigure 2: Gráfico de dispersão\n\n\n\nNas Figuras 3-5 são apresentados os gráficos de dispersão em função de outras covariáveis.\n\n\nShow code\n\n# Gráfico de dispersão com pontos estratificados\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  #geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') \n\ngrid.arrange(ffig2, ffig3, ffig4, ffig5, ffig6, ffig7, ffig8,\n             ncol = 2, nrow = 4)\n\n\n\n\nFigure 3: Gráfico de dispersão com pontos estratificados pelo número de cilindros\n\n\n\n\n\nShow code\n\n# Gráfico de dispersão com pontos estratificados\n\nffig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  #geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'top')\n\ngrid.arrange(ffig1, ffig2, ffig3, ffig4, ffig5, ffig6, ffig7, ffig8,\n             ncol = 2, nrow = 4)\n\n\n\n\nFigure 4: Gráfico de dispersão com pontos estratificados pelo formato do motor\n\n\n\n\n\nShow code\n\n# Gráfico de dispersão com pontos estratificados\n\nffig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  #geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'top')\n\ngrid.arrange(ffig1, ffig2, ffig3, ffig4, ffig5, ffig6, ffig7, ffig8,\n             ncol = 2, nrow = 4)\n\n\n\n\nFigure 5: Gráfico de dispersão com pontos estratificados pelo tipo de transmissão\n\n\n\n\n\nShow code\n\n# Gráfico de dispersão com pontos estratificados\n\nffig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE)\n\ngrid.arrange(ffig1, ffig2, ffig3, ffig4, ffig5, ffig6, ffig8,\n             ncol = 4, nrow = 2)\n\n\n\nNa Figura 6 são apresentados os boxplots, na qual observou-se que há uma possível diferença entre o formato do motor em relação a eficiência do carro, assim como há uma diferença entre o tipo de transmissão.\n\n\nShow code\n\n# Boxplot\n\nfig9 <- mtcars %>% \n  ggplot(aes(x=as.factor(cyl),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)') \n\nfig10 <- mtcars %>% \n  ggplot(aes(x=as.factor(vs),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Formato do motor', y = 'Eficiência (mpg)') \n\nfig11 <- mtcars %>% \n  ggplot(aes(x=as.factor(am),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Tipo de transmissão', y = 'Eficiência (mpg)') \n\nfig12 <- mtcars %>% \n  ggplot(aes(x=as.factor(gear),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') \n\nfig13 <- mtcars %>% \n  mutate(carb_novo=ifelse(carb<=2,0,1)) %>% \n  ggplot(aes(x=as.factor(carb_novo),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') \n\ngrid.arrange(fig10, fig11, ncol = 2, nrow = 1)\n\n\n\n\nFigure 6: Boxplot\n\n\n\nModelagem\nO modelo de regressão linear múltiplo, como definido em James et al. (2013) é dado por\n\\[\\begin{equation}\\label{eq:1}\\bf{Y}=\\beta_0+\\beta_1\\bf{X}_1+\\ldots+\\beta_p\\bf{X}_p+\\mathbf{\\varepsilon},\\end{equation}\\] em que \\(\\bf{Y}\\) representa a variável resposta, \\(\\bf{X}_1,\\ldots, \\bf{X}_p\\) é o vetor de variáveis explicativas, \\(\\beta_0,\\ldots, \\beta_p\\) são os parâmetros a serem estimados e \\(\\bf{\\varepsilon}\\) é o vetor de termos aleatórios do modelo.\nEntão, dado o conjunto de dados , o modelo de regressão (1), reescrito em função do conjunto de dados  é dado por \\[mpg_i = \\beta_0 + \\beta_1cyl_i + \\beta_2disp_i + \\beta_3hp_i + \\beta_4drat_i + \\beta_5wt_i + \\ldots + \\beta_9gear_i + \\beta_{10}carb_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\] sendo este, denominado de modelo completo. Os parâmetros \\(\\beta_0,\\ldots, \\beta_{10}\\) foram estimados pelo método de mínimos quadrados com auxílio computacional do software . Além disso, o efeito das variáveis explicativadas sobre a variável resposta {mpg} foram testadas considerando as seguintes hipóteses estatísticas \\[H_0: \\beta_j=0 \\quad vs \\quad H_a: \\beta_j\\neq 0, j=0,1,\\ldots, 10.\\]\nNessse cenário, obteve-se os seguintes resultados:\n\\(\\checkmark\\) Modelo completo\nAs estimativas, bem os erros padrões e os \\(p-valores\\) dos parâmetros do modelo completo foram obtidas pelo código\n\n\n\nShow code\n\nmod_completo <- lm(mpg ~ ., data=mtcars)\nsummary(mod_completo)\n\n\n\ne apresentadas na Tabela 2. Os resultados apresentados nessa tabela indicam que nenhuma da variáveis explicativas tem alguma relação com a eficiência do carro, pois o \\(p\\)-valor é maior do o nível de significância e consequentemente, levando a rejeição da hipótese nula.\nPor outro lado, na análise exploratório foi identificado o problema de multicolinearidade. Dessa forma, o fator de inflação da variância (VIF) foi calculo pelo seguinte código\n\n\nShow code\n\ncar::vif(mod_completo)\n\n\n\ne os valores apresentados na Tabela 3. Segundo James et al. (2013), variáveis explicativas cujo VIF for maior do que cinco podem ser removidas do modelo como uma das soluções para o problema. Nessa situação, de acordo com a Tabela 3, as variáveis explicativas , ,  e  foram mantidas no modelo. Justifica-se a permanência da variável  em função do comportamento linear quando comparado com as demains variáveis quantativas contínuas (Figura 2).\n\n\nShow code\n\noptions(scipen=1, digits=3)\nmod_completo %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo completo\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 2: Estimativas dos parâmetros do modelo completo\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n12.303\n\n\n18.718\n\n\n0.657\n\n\n0.518\n\n\ncyl\n\n\n-0.111\n\n\n1.045\n\n\n-0.107\n\n\n0.916\n\n\ndisp\n\n\n0.013\n\n\n0.018\n\n\n0.747\n\n\n0.463\n\n\nhp\n\n\n-0.021\n\n\n0.022\n\n\n-0.987\n\n\n0.335\n\n\ndrat\n\n\n0.787\n\n\n1.635\n\n\n0.481\n\n\n0.635\n\n\nwt\n\n\n-3.715\n\n\n1.894\n\n\n-1.961\n\n\n0.063\n\n\nqsec\n\n\n0.821\n\n\n0.731\n\n\n1.123\n\n\n0.274\n\n\nvs\n\n\n0.318\n\n\n2.105\n\n\n0.151\n\n\n0.881\n\n\nam\n\n\n2.520\n\n\n2.057\n\n\n1.225\n\n\n0.234\n\n\ngear\n\n\n0.655\n\n\n1.493\n\n\n0.439\n\n\n0.665\n\n\ncarb\n\n\n-0.199\n\n\n0.829\n\n\n-0.241\n\n\n0.812\n\n\n\n\nShow code\n\nout_vif1 <- car::vif(mod_completo) \n\nkbl(out_vif1, booktabs = T, caption = 'Fator de inflação da variância das variáveis explicativas', longtable = T, col.names = c('VIF')) %>% \n  kable_styling(position = 'center',latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 3: Fator de inflação da variância das variáveis explicativas\n\n\n\n\nVIF\n\n\ncyl\n\n\n15.37\n\n\ndisp\n\n\n21.62\n\n\nhp\n\n\n9.83\n\n\ndrat\n\n\n3.38\n\n\nwt\n\n\n15.16\n\n\nqsec\n\n\n7.53\n\n\nvs\n\n\n4.97\n\n\nam\n\n\n4.65\n\n\ngear\n\n\n5.36\n\n\ncarb\n\n\n7.91\n\n\n\\(\\checkmark\\) Modelo reduzido\nmod_red0: modelo reduzido 1\n\\[mpg_i = \\beta_0 + \\beta_4drat_i + \\beta_5wt_i + \\beta_7vs_i + \\beta_{8}am_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\]\ncujas estimativas dos parâmetros são obtidas por meio do seguinte código\n\n\n\nShow code\n\nmod_red1 <- lm(mpg ~ drat + wt + vs + am, data=mtcars)\nsummary(mod_red1)\n\n\n\ne os resultados apresentados na Tabela 4. Como a hipótese nula não foi rejeitada para os coeficientes associados as variáveis  (\\(p\\)-valor = 0,000) e  (\\(p\\)-valor = 0,016), ou seja, o peso e o formato do motor tem um possível efeito sobre a eficiência do carro. Entretanto, especialistas em mecânica acreditam o tipo de transmissão tem alguma influência sobre o consumo médio de um automável. Por essa razão, a variável  ainda foi mantida no modelo. Além disso, na Figura 5 foi observado uma possível interação entre o tipo de transmissão e o peso do carro.\n\n\nShow code\n\noptions(scipen=1, digits=3)\nmod_red1 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 1\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 4: Estimativas dos parâmetros do modelo reduzido 1\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n27.573\n\n\n6.874\n\n\n4.011\n\n\n0.000\n\n\ndrat\n\n\n0.682\n\n\n1.559\n\n\n0.438\n\n\n0.665\n\n\nwt\n\n\n-3.699\n\n\n0.932\n\n\n-3.967\n\n\n0.000\n\n\nvs\n\n\n3.452\n\n\n1.348\n\n\n2.561\n\n\n0.016\n\n\nam\n\n\n1.115\n\n\n1.736\n\n\n0.642\n\n\n0.526\n\n\nmod_red2: modelo reduzido 2\n\\[mpg_i = \\beta_0  + \\beta_{7}vs_i + \\beta_{5}wt_i + \\beta_{8}am_i + \\beta_{58}wt_i\\times am_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\]\ncujas estimativas dos parâmetros são obtidas por meio do seguinte código\n\n\n\nShow code\n\nmod_red2 <- lm(mpg ~ vs + wt*am, data=mtcars)\nsummary(mod_red2)\n\n\n\ne os resultados apresentados na Tabela 5. De acordo com essa tabela, a hipótese nula foi rejeitada em todos os casos, pois o \\(p\\)-valor foi menor do que o nível de significância. Dessa forma, o formato do motor e assim como a interação entre peso e tipo de transmissão tem algum efeito sobre a eficiência do carro.\n\n\nShow code\n\noptions(scipen=1, digits=3)\nmod_red2 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 2\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 5: Estimativas dos parâmetros do modelo reduzido 2\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n26.25\n\n\n3.346\n\n\n7.85\n\n\n0.000\n\n\nvs\n\n\n2.93\n\n\n1.095\n\n\n2.68\n\n\n0.012\n\n\nwt\n\n\n-2.70\n\n\n0.818\n\n\n-3.30\n\n\n0.003\n\n\nam\n\n\n14.32\n\n\n3.866\n\n\n3.70\n\n\n0.001\n\n\nwt:am\n\n\n-4.66\n\n\n1.329\n\n\n-3.51\n\n\n0.002\n\n\nmod_red3: modelo reduzido 3\nLevando em consideração a análise exploratória e a opinião de especialistas em mecânica, um modelo alternativo é dado por\n\\[mpg_i = \\beta_0  + \\beta_{5}wt_i + \\beta_{16}cyl6_i + \\beta_{18}cyl8_i + \\beta_{56}wt_i\\times cyl6_i + \\beta_{58}wt_i\\times cyl8_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\]\ncujas estimativas dos parâmetros são obtidas por meio do seguinte código\n\n\n\nShow code\n\nmod_red3 <- lm(mpg ~ wt*factor(cyl), data=mtcars)\nsummary(mod_red3)\n\n\n\ne os resultados apresentados na Tabela 6. Como a variável  foi categorizada para simplificar a interpertação do efeito da interação, duas variáveis dummies foram criadas, assumindo a categoria  como casela de referência. Logo, verificou-se uma possível relação do peso, assim como do efeito da interação entre peso e número de cilindro sobre a eficiência do carro, uma vez que a hipótese de nula foi rejeitada.\n\n\n\nShow code\n\noptions(scipen=1, digits=3)\nmod_red3 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 3\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 6: Estimativas dos parâmetros do modelo reduzido 3\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n39.57\n\n\n3.19\n\n\n12.39\n\n\n0.000\n\n\nwt\n\n\n-5.65\n\n\n1.36\n\n\n-4.15\n\n\n0.000\n\n\nfactor(cyl)6\n\n\n-11.16\n\n\n9.36\n\n\n-1.19\n\n\n0.244\n\n\nfactor(cyl)8\n\n\n-15.70\n\n\n4.84\n\n\n-3.25\n\n\n0.003\n\n\nwt:factor(cyl)6\n\n\n2.87\n\n\n3.12\n\n\n0.92\n\n\n0.366\n\n\nwt:factor(cyl)8\n\n\n3.46\n\n\n1.63\n\n\n2.12\n\n\n0.043\n\n\nNa Tabela 7 são apresentados os valores de R2 e R2 ajustado para os três modelos reduzidos estimados. Os valores obtidos indicam que o modelo mod_red2 é mais adequado entre os três modelos estimados, seguido do modelo mod_red3 e mod_red1. Entretanto, os valores de R2 ajustados não são suficientes para determinar a adequação do modelo. À vistsa disso, uma análise de resíduo foi realizada.\n\n\nShow code\n\nmodelo <- c('mod_red1','mod_red2','mod_red3')\nr2 <- c(0.809,0.868,0.862)\nr2_adj <- c(0.781,0.849,0.835)\nr2_df <- data.frame(Modelo=modelo,R2=r2, R2_ajustado=r2_adj)\n\nkbl(r2_df, booktabs = T, caption = 'Valores de R2 e R2 ajustados dos modelos reduzidos', longtable = T, align = 'c') %>% \n  kable_styling(position = 'center',latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 7: Valores de R2 e R2 ajustados dos modelos reduzidos\n\n\nModelo\n\n\nR2\n\n\nR2_ajustado\n\n\nmod_red1\n\n\n0.809\n\n\n0.781\n\n\nmod_red2\n\n\n0.868\n\n\n0.849\n\n\nmod_red3\n\n\n0.862\n\n\n0.835\n\n\nDiagnóstico do Modelo\nDados completo\nPara cada modelo reduzido estimado foi realizado uma análise de resíduo e os resultados são apresentados nas Figuras 7, 8 e 9, respectivamente.\n\\(\\checkmark\\) Modelo reduzido 1\nDe acordo com a Figura 7:\nResiduals vs Fitted: uma leve semelhança com uma parábola com concavidade voltada para cima, ou seja, temos um possível padrão não linear entre as variáveis.\nNormal Q-Q: A maior parte dos pontos encontra-se em torno da linha tracejada, exceto pelos pontos , ,  e outros dois pontos não identificados na parte inferior da figura. O que indica que esses três pontos são possíveis outliers.\nScale-Location: aparentemente os resíduos aparecem espalhados aleatoriamente, o que indica que a suposição de homocedasticidade é satisfeita, ou seja, a variância é constante.\nResiduals vs Leverage: como todos os pontos são menores do que a distância de Cook, temos evidências de que não há pontos de alavanca.\n\\(\\checkmark\\) Modelo reduzido 2\nDe acordo com a Figura 8:\nResiduals vs Fitted: os resíduos não mostram nenhum padrão, uma vez que a linha vermelha se parece com uma linha reta.\nNormal Q-Q: A maior parte dos pontos encontra-se afastada da linha tracejada e além disso, os carros ,  e  foram apontados como possíveis outliers.\nScale-Location: aparentemente os resíduos aparecem espalhados aleatoriamente, o que indica que a suposição de homocedasticidade é satisfeita, ou seja, a variância é constante.\nResiduals vs Leverage: como todos os pontos são menores do que a distância de Cook, temos evidências de que não há pontos de alavanca.\n\\(\\checkmark\\) Modelo reduzido 3\nDe acordo com a Figura 9:\nResiduals vs Fitted: os resíduos não mostram nenhum padrão, uma vez que a linha vermelha se parece com uma linha reta.\nNormal Q-Q: Alguns pontos encontra-se afastada da linha tracejada e além disso, os carros ,  e  foram apontados como possíveis outliers.\nScale-Location: aparentemente os resíduos aparecem espalhados aleatoriamente, o que indica que a suposição de homocedasticidade é satisfeita, ou seja, a variância é constante.\nResiduals vs Leverage: como todos os pontos são menores do que a distância de Cook, temos evidências de que não há pontos de alavanca.\n\n\nShow code\n\npar(mfrow = c(2, 2))\nplot(mod_red1)\n\n\n\n\nFigure 7: Gráfico de resíduos do modelo reduzido 1\n\n\n\n\n\n\nShow code\n\npar(mfrow = c(2, 2))\nplot(mod_red2)\n\n\n\n\nFigure 8: Gráfico de resíduos do modelo reduzido 2\n\n\n\n\n\n\nShow code\n\npar(mfrow = c(2, 2))\nplot(mod_red3)\n\n\n\n\nFigure 9: Gráfico de resíduos do modelo reduzido 3\n\n\n\n\nDados reduzidos\nO modelo mod_red1 apresentou o menor valor de R2 ajustado e na análise de resíduo apontou a possível falta de um termo quadrático no modelo. Por essas razões, o modelo foi descartado para nova avaliação.\nEm relação aos modelos mod_red2 e mod_red3 foi realizado uma nova análise removendo os carros identificados como possíveis outliers.\n\\(\\checkmark\\) Modelo reduzido 2\nOs resultados são apresentados na Tabela 8 e na Figura 10 indicam que o formato do motor e o efeito da interação permanecem sendo significativos para explicar a variabilidade presente na eficiência do carro. Além disso, os pontos estãos mais próximos da linha tracejada no gráfico Normal Q-Q. Entretanto, pelo gráfico Scale-Location, há evidências de heterogeneidade de variâncias e outros carros foram identificados como possíveis outliers.\n\n\n\nShow code\n\nmtcars_red <- mtcars %>% \n  slice(-8L, -20L, -18L)\nmod_red21 <- lm(mpg ~ vs + wt*am, data=mtcars_red)\nsummary(mod_red21)\n\n\n\n\n\nShow code\n\noptions(scipen=1, digits=3)\nmod_red21 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 2 sem os possíveis outliers\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 8: Estimativas dos parâmetros do modelo reduzido 2 sem os possíveis outliers\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n26.94\n\n\n2.545\n\n\n10.59\n\n\n0.000\n\n\nvs\n\n\n1.87\n\n\n0.859\n\n\n2.18\n\n\n0.040\n\n\nwt\n\n\n-2.85\n\n\n0.621\n\n\n-4.58\n\n\n0.000\n\n\nam\n\n\n12.34\n\n\n3.074\n\n\n4.01\n\n\n0.001\n\n\nwt:am\n\n\n-4.13\n\n\n1.041\n\n\n-3.97\n\n\n0.001\n\n\n\n\nShow code\n\npar(mfrow = c(2, 2))\nplot(mod_red21)\n\n\n\n\nFigure 10: Gráfico de resíduos do modelo reduzido 2 sem outliers\n\n\n\n\\(\\checkmark\\) Modelo reduzido 3\nOs resultados são apresentados na Tabela 9 e na Figura 11 indicam que não houve grandes mudanças nos gráficos de resíduos. Porém, houve uma mudança na significância da interação entre  e  e também, novos foram identificados como possíveis outliers.\n\n\n\nShow code\n\nmtcars_red1 <- mtcars %>% \n  slice(-18L, -20L, -21L)\nmod_red31 <- lm(mpg ~ wt*factor(cyl), data=mtcars_red1)\nsummary(mod_red31)\n\n\n\n\n\nShow code\n\noptions(scipen=1, digits=3)\nmod_red31 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 3 sem os possíveis outliers\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 9: Estimativas dos parâmetros do modelo reduzido 3 sem os possíveis outliers\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n36.06\n\n\n2.61\n\n\n13.816\n\n\n0.000\n\n\nwt\n\n\n-4.45\n\n\n1.08\n\n\n-4.109\n\n\n0.000\n\n\nfactor(cyl)6\n\n\n-7.65\n\n\n7.21\n\n\n-1.061\n\n\n0.300\n\n\nfactor(cyl)8\n\n\n-12.19\n\n\n3.81\n\n\n-3.198\n\n\n0.004\n\n\nwt:factor(cyl)6\n\n\n1.67\n\n\n2.40\n\n\n0.696\n\n\n0.494\n\n\nwt:factor(cyl)8\n\n\n2.26\n\n\n1.28\n\n\n1.764\n\n\n0.091\n\n\n\n\nShow code\n\npar(mfrow = c(2, 2))\nplot(mod_red31)\n\n\n\n\nFigure 11: Gráfico de resíduos do modelo reduzido 3 sem outliers\n\n\n\nConclusão e Discussão\nDiante do exposto, o modelo mais adequado para explicar a variabiliade presente na eficiência dos carros modelos 1973-1974 é o modelo mod_red3. A opção por esse modelo foi em função dos gráficos dos resíduos se manterem com o mesmo padrão com ou sem os carros ,  e , apontados como possíveis outliers. Esses carros não foram identificados como pontos de alavanca, entretanto, são pontos influentes, pois a significância de um dos parâmetros do modelo foi alterada. Dessa forma, seria interessante levantar mais informações sobre esses carros, antes de removê-los por definitivo do conjunto de dados.\nPortanto, o modelo mod_red3 estimado é dado por \\[\\hat{mpg}_i = 39,57  -5,65wt_i -11,16cyl6_i -15,70cyl8_i + 2,87 wt_i\\times cyl6_i + 3,46wt_i\\times cyl8_i, \\quad i=1,\\ldots, 32,\\] A partir do modelo estimado, as seguintes interpretações podem ser feitas:\nwt: com \\(p\\)-valor=0,00o; temos evidências de que a cada 1000 libras que se aumenta no carro há uma redução de -5,65 mpg na eficiência média.\ncyl6: com \\(p\\)-valor = 0,244; temos indicativos de que não existe diferença significativa entre quatro cilindros (casela de referência) e seis cilindros em relação eficiência média.\ncyl8: com \\(p\\)-valor = 0,003; temos sinais de que existe diferença significativa entre quatro cilindros (casela de referência) e oito cilindros em relação eficiência média.\nPortanto, marginalmente, há o efeito do peso e do número de cilindros\nwt:cyl6: com \\(p\\)-valor = 0,366; temos evidências de que não existe diferença significativa entre a inclinação de quatro cilindros (casela de referência) e de seis cilindros em relação a eficiência média.\nwt:cyl8: com \\(p\\)-valor = 0,043; temos evidências de que existe diferença significativa entre a inclinação de quatro cilindros (casela de referência) e de oito cilindros em relação a eficiência média.\nPortanto, temos efeito da interação entre peso e número de cilindro do carro. Dessa forma, a hipótese de que modificações na estrutura do automóvel aumenta o seu consumo médio foi validada. Nesse caso, as modificações no peso e no número de cilindros do carro podem explicar a variabilidade presente no consumo médio de gasolina.\nPor fim, informações como relação peso e torque poderiam ser utilizadas no lugar de peso e potência. Outra informações que poderia ser utilizada é o tipo de carro, uma vez que carros esportivos são bem diferentes de sedãs.\nAgradecimentos\nAo professor Athos Damiani pelas aulas e dedicação ao curso. Aos mecânicos Marcelo Prataviera e Taka Kurihara e, também, aos alunos do curso de Engenharia Mecânica da UTFPR/Londrina, João Pedro Alves Cordeiro dos Santos e Pedro Henrique Barion pelo auxílio na compreensão das estruturas de um carro.\nReferências bibliográficas\nALMEIDA FILHO, G.M. Programa INOVAR-AUTO: atendimento das metas de eficiência energética e suas externalidades. 2018. Dissertação (Mestrado em Ciências) - Universidade de São Paulo, São Paulo.\nCRISE petrolífera de 1973. Wikipedia. Disponível em: https://pt.wikipedia.org/wiki/Crise_petrol%C3%ADfera_de_1973. Acesso em: 28 de jan. de 2021. \nFUEL efficiency. Wikipedia. Disponível em: https://en.wikipedia.org/wiki/Fuel_efficiency. Acesso em: 28 de jan. de 2021.\nHENDERSON, H.V.; VELLEMAN. P.F. Building multiple regression models interactively. Biometrics, v.37, p.391-411, 1981. \nHOCKING, R.R. The analysis and selection of variables in linear regression. Biometrics, v.32, p.1-49, 1976. \nJAMES, G.; WITTEN, D.; HASTIE. T.; TIBSHIRANI, R. An Introduction to Statistical Learning with Applications in R. New York: Springer, 2013. \nR Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL: https://www.R-project.org/ \nTOP reasons for supporting cleaner, more efficient vehicles. Global fuel economy initiative. Disponível em: https://www.globalfueleconomy.org/media/45140/top-reasons-leaflet.pdf. Acesso em: 28 de jan. de 2021.\n\n\n\n",
    "preview": "posts/2021-02-05-anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974/anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-05-05T13:47:31-03:00",
    "input_file": "anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974.utf8.md"
  },
  {
    "path": "posts/2021-02-04-curso-r-regresso-linear-br-exerccios-rlsm/",
    "title": "Exercícios RLSM",
    "description": "Resolução da lista de exercícios do Curso de Regressão Linear com R de janeiro de 2021.",
    "author": [
      {
        "name": "Elizabeth Mie Hashimoto",
        "url": "https://www.linkedin.com/in/elizabeth-mie-hashimoto-a416a917/"
      }
    ],
    "date": "2021-01-25",
    "categories": [],
    "contents": "\n\nContents\nPacotes\nDados\nExercício 1\nExercício 2\nExercício 3\nExercício 4\nExercício 5\nExercício 6\nExercício 7\nExercício 8\nExercício 9\nExercício 10\n\nPacotes\n\n\nShow code\n\nlibrary(tidyverse) # manipulacao de data.frame\nlibrary(MASS) # dados Boston\nlibrary(broom)\n\n\n\nDados\nO banco de dados Boston apresenta registros de valores medianos das casas (medv) de 506 bairros de Boston. O objetivo é identificar quais das 13 variáveis explicativas estão associadas com esses valores e usá-las para fazer predições de preços das casas.\n\n\nShow code\n\nglimpse(Boston)\n\n\nRows: 506\nColumns: 14\n$ crim    <dbl> 0.00632, 0.02731, 0.02729, 0.03237, 0.06905, 0.02985…\n$ zn      <dbl> 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 12.5, 12.5, 12.…\n$ indus   <dbl> 2.31, 7.07, 7.07, 2.18, 2.18, 2.18, 7.87, 7.87, 7.87…\n$ chas    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ nox     <dbl> 0.538, 0.469, 0.469, 0.458, 0.458, 0.458, 0.524, 0.5…\n$ rm      <dbl> 6.575, 6.421, 7.185, 6.998, 7.147, 6.430, 6.012, 6.1…\n$ age     <dbl> 65.2, 78.9, 61.1, 45.8, 54.2, 58.7, 66.6, 96.1, 100.…\n$ dis     <dbl> 4.0900, 4.9671, 4.9671, 6.0622, 6.0622, 6.0622, 5.56…\n$ rad     <int> 1, 2, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4…\n$ tax     <dbl> 296, 242, 242, 222, 222, 222, 311, 311, 311, 311, 31…\n$ ptratio <dbl> 15.3, 17.8, 17.8, 18.7, 18.7, 18.7, 15.2, 15.2, 15.2…\n$ black   <dbl> 396.90, 396.90, 392.83, 394.63, 396.90, 394.12, 395.…\n$ lstat   <dbl> 4.98, 9.14, 4.03, 2.94, 5.33, 5.21, 12.43, 19.15, 29…\n$ medv    <dbl> 24.0, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5…\n\n\n\nShow code\n\n# Descrição das variáveis\nhelp(Boston)\n\n\n\nExercício 1\nFaça um gráfico de dispersão entre medv e rm.\n\n\nShow code\n\nBoston %>% \n  ggplot() +\n  geom_point(aes(x = rm, y = medv)) +\n  labs(x = 'Número médio de quartos por habitação', y = 'Preço mediano das habitações do bairro (em 1000 dólares)')\n\n\n\n\nExercício 2\nAjuste um modelo de regressão linear simples utilizando medv como resposta e rm como explicativa e guarde em objeto chamado mod_simples. Consulte o summary(mod_simples) em seguida.\n\n\nShow code\n\nmod_simples <- lm(medv ~ rm, data=Boston)\nsummary(mod_simples)\n\n\n\nCall:\nlm(formula = medv ~ rm, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.346  -2.547   0.090   2.986  39.433 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -34.671      2.650  -13.08   <2e-16 ***\nrm             9.102      0.419   21.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.616 on 504 degrees of freedom\nMultiple R-squared:  0.4835,    Adjusted R-squared:  0.4825 \nF-statistic: 471.8 on 1 and 504 DF,  p-value: < 2.2e-16\n\nExercício 3\nSabendo que medv é o preço mediano das habitações do bairro e o rm é o número médio de quartos por habitação,\ninterprete o parâmetro (Intercept).\n\\(\\blacktriangleright\\) Resposta: Nesse caso, -34.671 \\(\\times\\) 1000 dólares é a média do preço mediano das habitações quando temos zero quartos por habitação.\ninterprete o parâmetro rm.\n\\(\\blacktriangleright\\) Resposta: A cada um quarto por habitação que aumentamos por habitação, temos um acréscimo de 9.102 \\(\\times\\) 1000 dólares na média do preço mediano das habitações.\no número de quartos está associado com o valor da habitação? Por quê?\n\\(\\blacktriangleright\\) Resposta: Sim, pois ao nível de significância de 5%, rejeitamos a hipótese nula (\\(H_0: \\beta_1=0\\)), uma vez que o \\(p\\)-valor é menor do que 0,001. Dessa forma, temos evidências de que o preço mediano das habitações tem alguma relação com o número médio de quartos por habitação.\nExercício 4\nConsulte as saídas das funções\ncoef(mod_simples): mostra apenas as estimativas dos coeficientes de regressão.\nconfint(mod_simples): mostra o intervalo de 95% de confiança das estimativas dos coeficientes de regressão.\npredict(mod_simples): calcula os valores preditos do preço mediano das habitações, isto é, \\(\\hat{\\mbox{medv}}=-34,671+9,102 rm\\).\npredict(mod_simples, interval = \"confidence\"): calcula os valores preditos do preço mediano das habitações e o intervalo de 95% de confiança de cada valor predito.\naugment(mod_simples): cria um data frame com valores de medv, rm, valores preditos, resíduo e distância de Cook.\n\n\nShow code\n\ncoef(mod_simples)\n\n\n(Intercept)          rm \n -34.670621    9.102109 \n\nShow code\n\nconfint(mod_simples)\n\n\n                 2.5 %     97.5 %\n(Intercept) -39.876641 -29.464601\nrm            8.278855   9.925363\n\nShow code\n\npredict(mod_simples) %>% head(n=10L)\n\n\n       1        2        3        4        5        6        7 \n25.17575 23.77402 30.72803 29.02594 30.38215 23.85594 20.05126 \n       8        9       10 \n21.50760 16.58335 19.97844 \n\nShow code\n\npredict(mod_simples, interval = \"confidence\") %>% head(n=10L)\n\n\n        fit      lwr      upr\n1  25.17575 24.55039 25.80110\n2  23.77402 23.18536 24.36269\n3  30.72803 29.78817 31.66790\n4  29.02594 28.20203 29.84984\n5  30.38215 29.46676 31.29755\n6  23.85594 23.26582 24.44606\n7  20.05126 19.43134 20.67118\n8  21.50760 20.92234 22.09285\n9  16.58335 15.79375 17.37296\n10 19.97844 19.35611 20.60078\n\nShow code\n\naugment(mod_simples)\n\n\n# A tibble: 506 x 8\n    medv    rm .fitted  .resid    .hat .sigma     .cooksd .std.resid\n   <dbl> <dbl>   <dbl>   <dbl>   <dbl>  <dbl>       <dbl>      <dbl>\n 1  24    6.58    25.2 -1.18   0.00231   6.62 0.0000367      -0.178 \n 2  21.6  6.42    23.8 -2.17   0.00205   6.62 0.000111       -0.329 \n 3  34.7  7.18    30.7  3.97   0.00523   6.62 0.000952        0.602 \n 4  33.4  7.00    29.0  4.37   0.00402   6.62 0.000885        0.662 \n 5  36.2  7.15    30.4  5.82   0.00496   6.62 0.00194         0.882 \n 6  28.7  6.43    23.9  4.84   0.00206   6.62 0.000555        0.733 \n 7  22.9  6.01    20.1  2.85   0.00227   6.62 0.000212        0.431 \n 8  27.1  6.17    21.5  5.59   0.00203   6.62 0.000727        0.846 \n 9  16.5  5.63    16.6 -0.0834 0.00369   6.62 0.000000295    -0.0126\n10  18.9  6.00    20.0 -1.08   0.00229   6.62 0.0000306      -0.163 \n# … with 496 more rows\n\nExercício 5\nUsando o data.frame gerado por augment(mod_simples) faça um gráfico de medv versus rm e em seguida desenhe a reta ajustada do mod_simples.\n\n\nShow code\n\nboston_pred <- augment(mod_simples)\n\nboston_pred %>% \n  ggplot() +\n  geom_point(aes(x = rm, y = medv)) +\n  geom_line(aes(x = rm, y = .fitted), color=\"red\") +\n  labs(x = 'Número médio de quartos por habitação', y = 'Preço mediano das habitações do bairro (em 1000 dólares)')\n\n\n\n\nExercício 6\nFaça um gráfico de resíduos. Coloque os resíduos no eixo Y e os valores ajustados no eixo X.\n\n\nShow code\n\nboston_pred %>% \n  ggplot() +\n  geom_point(aes(x = .fitted, y = .std.resid)) +\n  geom_hline(yintercept=0, linetype=\"dashed\") +\n  labs(x = 'Valores ajustados', y = 'Resíduos')\n\n\n\n\nExercício 7\nObserve os gráficos de plot(mod_simples).\n\n\nShow code\n\nplot(mod_simples)\n\n\n\n\nApenas pela inspeção visual, responda: existem outliers? Eles são pontos de alavanca?\n\\(\\blacktriangleright\\) Resposta: Por meio das figuras, observamos que os pontos \\(\\sharp366\\), \\(\\sharp369\\) e \\(\\sharp373\\) são possíveis outliers. O gráfico de Residuals vs Leverage indica que não são pontos de alavanca.\nExercício 8\nAjuste um modelo mod_multiplo para medv explicado por rm e crim. Consulte o summary(mod_multiplo) em seguida.\n\n\nShow code\n\nmod_multiplo <- lm(medv ~ rm + crim, data=Boston)\nsummary(mod_multiplo)\n\n\n\nCall:\nlm(formula = medv ~ rm + crim, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.608  -2.835  -0.380   2.592  38.839 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -29.24472    2.58809 -11.300   <2e-16 ***\nrm            8.39107    0.40485  20.726   <2e-16 ***\ncrim         -0.26491    0.03307  -8.011    8e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.237 on 503 degrees of freedom\nMultiple R-squared:  0.542, Adjusted R-squared:  0.5401 \nF-statistic: 297.6 on 2 and 503 DF,  p-value: < 2.2e-16\n\nExercício 9\nQual modelo ficou melhor: mod_simples ou mod_multiplo? Qual critério você utilizou para decidir o melhor?\n\\(\\blacktriangleright\\) Resposta: O mod_multiplo parece ser melhor do que o mod_simples, porque, considerando o R2 ajustado, o R2 ajustado do mod_multiplo (0,5401) é maior do que o R2 ajustado do mod_simples (0,4825). Além disso, a variável crim é significativa (\\(p\\)-valor < 0,001) para explicar a variablidade presente na média do preço mediano das habitações, considerando um nível de significância de 5%.\nPor outro lado, pelos resíduos, ambos os modelos tem problemas com em relação a normalidade dos resíduos e com uma possível relação não linear entre a variável resposta e as variáveis explicativas. O que indica que o modelo mod_multiplo pode ser melhorado.\n\n\nShow code\n\n# Resíduo modelo múltiplo\nplot(mod_multiplo)\n\n\n\n\n\n\nShow code\n\nwith(Boston,plot(crim,medv))\n\n\n\nExercício 10\nAjuste um modelo mod_completo para medv explicado por todas as demais colunas. DICA: na fórmula medv ~ ., o ponto significa “todas as variáveis, tirando medv”.\nConsulte o summary(mod_completo) em seguida.\n\n\nShow code\n\nmod_completo <- lm(medv ~ ., data=Boston)\nsummary(mod_completo)\n\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nQual modelo ficou melhor: mod_simples, mod_multiplo ou mod_completo?\n\\(\\blacktriangleright\\) Resposta: Novamente considerando o R2 ajustado, o modelo mais adequado entre os três modelos é o mod_completo, pois tem o R2 ajustado é igual a 0,7338; que é maior do que o R2 ajustados dos demais modelos. Além disso, as variáveis explicativas, exceto indus e age, foram signifitivas ao nível de significância de 5%.\nEm relação aos resíduos, o modelo completo tem o mesmo problema dos outros dois modelos. Nesse caso, o modelo completo também pode ser melhorado.\n\n\nShow code\n\n# Resíduo modelo completo\nplot(mod_completo)\n\n\n\n\nO valor estimado para o termo rm variou entre os três modelos? Por qual razão você acha que isso aconteceu?\n\\(\\blacktriangleright\\) Resposta: Sim, a estimativa para o termo rm variou devido a inclusão de variáveis de explicativas no modelo.\n\n\n\n",
    "preview": "posts/2021-02-04-curso-r-regresso-linear-br-exerccios-rlsm/curso-r-regresso-linear-br-exerccios-rlsm_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-05-05T13:47:42-03:00",
    "input_file": "curso-r-regresso-linear-br-exerccios-rlsm.utf8.md"
  },
  {
    "path": "posts/2021-02-05-tcc/",
    "title": "TCC",
    "description": "Resolução do TCC do curso de Regressão Linear com R de janeiro de 2021.",
    "author": [
      {
        "name": "Ricardo Feliz Okamoto",
        "url": "https://www.linkedin.com/in/ricardo-feliz-okamoto-a20344171/"
      }
    ],
    "date": "2021-01-25",
    "categories": [],
    "contents": "\n\nContents\nIntrodução\nDefinição do problema\nDescrição básica da origem e da coleta dos dados\nHipótese do estudo\nSumários das variáveis (univariadas)\nGráficos de duas variáveis\n\nModelagem\nBaseline model\nMulticolinearidade e Interações\n\nDiagnóstico do modelo\nConclusão e discussão\n\nIntrodução\nA eficiência dos carros é uma das principais características que a indústria automobilística tenta optimizar. Melhorar a eficiência de um carro significa aumentar a quantidade de quilômetros que os carros conseguem rodar consumindo menos combustível. Não só para a indústria automobilística esse tema tem importância, como também para qualquer cidadão que esteja preocupado em gastar menos (afinal de contas, mais quilômetros rodados com menos combustível significa uma conta menor no fim do mês de gasolina), e também para qualquer pessoa com consciência ambiental, que deseja diminuir a quantidade de combustíveis fósseis que são queimados por dia.\nDefinição do problema\nDada a relevância de se estudar este problema, é que eu me guio pela indagção de quais características do carro explicam sua a eficiência (milhas por galão de combustível)?\nDescrição básica da origem e da coleta dos dados\nPara estudar isso, utilizarei a base de dados mtcars. Essa base inclui 32 linhas e 11 colunas. Cada observação é um modelo de carro diferente; e cada coluna é uma característica desse carro. Ao todo, portanto, temos 11 características de 32 modelos de carro para comparar.\nA eficiência está representada nesta base de dados pela coluna mpg, que é a quantidade de milhas rodadas por galão de combustível (miles per galon).\nHipótese do estudo\nMinha hipótese é a de que as seguintes variáveis são relevantes para se explicar a eficiciência dos carros:\ncyl;\nhp;\nwt;\nvs;\nam;\ngear;\ncarb.\nSumários das variáveis (univariadas)\nVariável dependente\n\n\nShow code\n\nggplot(mtcars, aes(mpg)) +\n  geom_histogram(fill = \"steelblue\") +\n  geom_vline(aes(xintercept=mean(mpg)),\n            color=\"blue\", linetype=\"dashed\", size=1)\n\n\n\n\nA começar pela variável de interesse, mpg, observamos a seguinte distribuição dos modelos de carro por eficiência. A média de eficiência é de aproximadamente 20 mpg. Temos 18 modelos de carro abaixo da média e 14 modelos acima dela, sendo que o modelo com a pior eficiência roda apenas 10.40 milhas por galão, enquanto o modelo mais eficiente roda mais que o triplo disso, com 33.90 milhas por galão.\n\n\nShow code\n\nsummary(mtcars$mpg)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\nVariáveis explicativas\nQuanto às variáveis explicativas, temos os seguintes gráficos.\n\n\nShow code\n\nggplot(mtcars, aes(cyl)) +\n  geom_histogram(fill = \"steelblue\") \n\n\n\n\nOs cilindros são onde o combustível é queimado. Há apenas três tipos de carros e cilindros: carros com 4 cilindros, 6 cilindros ou 8 cilindros. O que vemos é que a maioria dos carros possui 8 cilindros, seguido de carros com 4 cilindros e, em terceiro lugar, carros com 6 cilindros. Essa característica se relaciona com a eficiência porque quanto mais cilindros existem, maior é a queima de combustível e, portanto, maior é a geração de poder para o carro.\n\n\nShow code\n\nggplot(mtcars, aes(hp)) +\n  geom_histogram(fill = \"steelblue\") +\n  geom_vline(aes(xintercept=mean(hp)),\n            color=\"blue\", linetype=\"dashed\", size=1) +\n    geom_vline(aes(xintercept=median(hp)),\n            color=\"red\", linetype=\"dashed\", size=1)\n\n\n\n\nQuanto ao gross horsepower (hp), essa característica diz respeito aos cavalos do carro. De forma genérica, o horsepower é uma indicação do quanto que o veículo consegue se mover sozinho. Quanto mais cavalos, mais rápido o carro consegue ser. Essa característica se relaciona com a eficiência porque carros com menos horsepower necessitam de mais energia para se movimentarem e, do contrário, carros com mais horsepower necessitam de menos energia para se movimentarem. Dito de outra maneira, quanto maior o horsepower, maior é a eficicência, porque menor é o gasto energético.\nVemos que a distribuição do horsepower é assimétrica para a direita (right skewed) ao compararmos a média (azul) com a mediana (vermelho).\n\n\nShow code\n\nggplot(mtcars, aes(wt)) +\n  geom_histogram(fill = \"steelblue\") +\n  geom_vline(aes(xintercept=mean(wt)),\n            color=\"blue\", linetype=\"dashed\", size=1) +\n    geom_vline(aes(xintercept=median(wt)),\n            color=\"red\", linetype=\"dashed\", size=1) +\n  xlab(\"wt \\n (1000 lbs)\")\n\n\n\n\nOutra variável de interesse é o peso do carro. Quanto mais pesado é um caro, espera-se que menos eficiente ele seja.\nO que vemos desse dado é uma grande concentração de valores que giram entorno da média de aproxidamente 3200 libras.\n\n\nShow code\n\nggplot(mtcars, aes(vs)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(name = \"Engine \\n (0 = V-shaped, 1 = straight)\", breaks = c(0,1))\n\n\n\n\nA seguir, temos o tipo de motor. Essa variável é binária, ela assume apenas dois valores: ou o motoro é V-shaped, ou ele é straight. Na base de dados, essa característica está representada na coluna vs. Esperamos que o tipo de motor influencie na eficiência, porque é justamente no motor em que o consumo de combustível ocorre.\n\n\nShow code\n\nggplot(mtcars, aes(am)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(name = \"Transmission \\n (0 = Automatic, 1 = Manual)\", breaks = c(0,1)) \n\n\n\n\nOutra característica que esperamos que se relacione com a eficiência é o tipo de transmissão, se é manual (1) ou automático (0). Vemos que existem nessa base de dados mais carros automáticos do que manuais.\n\n\nShow code\n\nggplot(mtcars, aes(gear)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(breaks = c(3,4,5)) \n\n\n\n\nAlém disso, temos a quantidade de marchas que um carro possui. Existem carros apenas de 3, 4 ou 5 marchas. Pensamos que a marcha se relaciona com a eficiciência porque ela controla a quantidade de poder disponível do motor.\n\n\nShow code\n\nggplot(mtcars, aes(carb)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(breaks=c(1:8))\n\n\n\n\nPor fim, existe a quantidade de carburadores por carro. Os carburadores são o dispositivo dos carros que misturam ar e combustível para combustões internas. Espera-se que essa variável também se relacione com a eficiência do carro.\nGráficos de duas variáveis\n\n\nShow code\n\np_cyl <- ggplot(mtcars, aes(cyl, mpg)) +\n  geom_point()\n\np_hp <- ggplot(mtcars, aes(hp, mpg)) +\n  geom_point()\n\np_vs <- ggplot(mtcars, aes(vs, mpg)) +\n  geom_point()\n\np_am <- ggplot(mtcars, aes(am, mpg)) +\n  geom_point()\n\np_gear <- ggplot(mtcars, aes(gear, mpg)) +\n  geom_point()\n\np_carb <- ggplot(mtcars, aes(carb, mpg)) +\n  geom_point()\n\ng1 <- gridExtra::grid.arrange(\n  p_cyl, \n  p_hp, \n  nrow = 2\n)\n\n\n\nShow code\n\ng2 <- gridExtra::grid.arrange(\n  p_vs, \n  p_am, \n  nrow = 2\n)\n\n\n\nShow code\n\ng3 <- gridExtra::grid.arrange(\n  p_gear, \n  p_carb,\n  nrow = 2\n)\n\n\n\n\nModelagem\nBaseline model\nA fórmula básica, da qual partiremos, é a seguinte:\n\\[\n\\operatorname{baseline\\ model:\\ mpg} = \\beta_{0} + \\beta_{1}(\\operatorname{cyl}) + \\beta_{2}(\\operatorname{hp}) + + \\beta_{3}(\\operatorname{wt}) + \\beta_{4}(\\operatorname{vs}) + \\beta_{5}(\\operatorname{am}) + \\beta_{6}(\\operatorname{gear}) + \\beta_{7}(\\operatorname{carb}) + \\epsilon\n\\] Essa equação de regressão ainda não representa a especificação final do modelo. É possível que algumas dessas variáveis não possuem efeito estatisticamente relevante sobre a variável de interesse mpg. Ou ainda pode ser que haja multicolinearidade entre algumas variáveis, ou algum tipo de interação, ou relação polinomial. Então esta não é a versão ajustada do modelo, mas é o modelo inicial, o qual chamarei de “baseline model”.\nQuando rodamos a regressão, a nossa fórmula fica especificada com os seguintes coeficientes:\n\\[\n\\operatorname{baseline\\ model:\\ mpg} = 30.25 - 0.38(\\operatorname{cyl}) - 0.02(\\operatorname{hp}) - 2.18(\\operatorname{wt}) + 97(\\operatorname{vs}) + 2.11(\\operatorname{am}) + 0.66(\\operatorname{gear}) - 0.62(\\operatorname{carb}) + \\epsilon\n\\] Esses parâmetros ficam melhor resumidos na tabela a seguir:\n\n\nShow code\n\nbaseline <- lm(mpg~cyl + hp + wt + vs + am + gear + carb, mtcars)\nsummary(baseline)\n\n\n\nCall:\nlm(formula = mpg ~ cyl + hp + wt + vs + am + gear + carb, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2242 -1.4538 -0.4293  1.4548  5.2956 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 30.25034    8.61471   3.511  0.00179 **\ncyl         -0.38285    0.87852  -0.436  0.66688   \nhp          -0.01859    0.01710  -1.088  0.28762   \nwt          -2.18465    1.02244  -2.137  0.04302 * \nvs           0.96917    1.85506   0.522  0.60615   \nam           2.11755    1.88907   1.121  0.27340   \ngear         0.65975    1.43338   0.460  0.64946   \ncarb        -0.62289    0.58164  -1.071  0.29485   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.578 on 24 degrees of freedom\nMultiple R-squared:  0.8583,    Adjusted R-squared:  0.817 \nF-statistic: 20.77 on 7 and 24 DF,  p-value: 9.689e-09\n\nOlhando para esse teste, conseguimos ver que apenas dois coeficientes possuem signficância estatística: o intercepto (B0) e o coeficiente relativo ao peso do carro (B2). O teste de hipótese relativo ao B0 indica que com 99.99% de certeza conseguimos rejeitar a hipótese nula de que o intercepto é igual a 0. Já o teste de hipótese relativo ao B2 indica que com 95% de certza conseguimos rejeitar a hipótese nula de que a relação entre aquele coeficiente com a variável de interesse (mpg) é 0. Todos os demais coeficientes não conseguem ter a hipótese nula rejeitada, isto é, não é possível dizer que a relação dessas variáveis explicativas com a variável de resposta seja diferente de 0.\nA partir disso, poderíamos ser levados a concluir que a única variável que explica a eficiência do motor é o peso do carro. Mas temos de tomar cuidado com essa conclusão. Ela é muito precipitada. O que pode estar acontecendo é que pode haver multicolinearidade ou interação entre as variáveis. Nesses casos, o efeito de uma variável sobre Y estaria sendo “roubado” e, por isso, ele fica invisível e não conseguimos rejeitar a hipótese nula de que o coeficiente é diferente de 0.\nMulticolinearidade e Interações\nAnálise de cyl e hp\nPara tentar desmistificar isso, precisamos avaliar as variáveis individualmente. Quando rodamos um modelo para cada variável, a história é outra. Todos os coeficientes se tornam estatisticamente significantes.\n\n\nShow code\n\ncyl_model <- lm(mpg~cyl, mtcars)\nhp_model <- lm(mpg~hp, mtcars)\nwt_model <- lm(mpg~wt, mtcars)\nvs_model <- lm(mpg~vs, mtcars)\nam_model <- lm(mpg~am, mtcars)\ngear_model <- lm(mpg~gear, mtcars)\ncarb_model <- lm(mpg~carb, mtcars)\n\njtools::export_summs(cyl_model, hp_model, wt_model, vs_model, am_model, gear_model, carb_model, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 20.09 20.09 16.62 17.15\npt) *** *** *** *** ***\n(0.57)   (0.68)   (0.54)   (1.08)   (1.12)  \n         \ncyl -5.14                                \n***\n(0.58)                                  \n \nhp         -4.68                        \n***\n        (0.69)                          \n \nwt                 -5.23                \n***\n                (0.55)                  \n \nvs                         7.94 ***        \n                        (1.63)          \n \nam                                 7.24 ***\n                                (1.76)  \n \ngear                                        \n                                       \ncarb                                        \n                                       \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.73     0.60     0.75     0.44     0.36    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5, Model 6, Model 7\n6/8 columns shown.\n\nComparando, então, esses resultados com a equação que inclui todas as variáveis, podemos levantar fortes suspeitas de que existe multicolinearidade no nosso baseline model. Para diagnosticar a multicolinearidade, podemos usar o VIF.\n\n\nShow code\n\ncar::vif(baseline)\n\n\n      cyl        hp        wt        vs        am      gear      carb \n11.480450  6.409021  4.667601  4.076992  4.143941  5.216024  4.116132 \n\nO VIF nos dá alguns valores a que temos de nos atentar. Primeiro, observamos que o VIF do cyl é o maior de todos. Ele está acima de 5. Acima de 5 todos VIF é problemático. Outra variável problemática é hp. Além disso, há gear. Entretanto, como ele está apenas um pouco acima de 5, vou deixá-lo para uma análise posterior. O que eu vou testar agora é o que acontece com as demais variáveis ao retirar o cyl e hp.\n\n\nShow code\n\nbaseline_sem_cyl_e_hp <- lm(mpg~wt + vs + am + gear + carb, mtcars)\ncar::vif(baseline_sem_cyl_e_hp)\n\n\n      wt       vs       am     gear     carb \n4.395138 2.090715 3.881481 4.510498 3.160047 \n\nDe fato, o VIF das variáveis diminuem. Agora não temos nenhum VIF que passe de 5. Entretanto, acho que seria cauteloso nos determos melhor em wt, gear e am, pois seus valores são os mais próximos de 5.\nComecemos pela análise de wt, rodando separadamente um modelo com wt e apenas uma outra variável.\nAnálise de wt\n\n\nShow code\n\nwt1 <- lm(mpg~wt+vs, mtcars)\nwt2 <- lm(mpg~wt+am, mtcars)\nwt3 <- lm(mpg~wt+gear, mtcars)\nwt4 <- lm(mpg~wt+carb, mtcars)\n\njtools::export_summs(wt_model, wt1, wt2, wt3, wt4, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 18.71 20.10 20.09 20.09\npt) *** *** *** *** ***\n(0.54)   (0.72)   (0.83)   (0.55)   (0.50)  \n         \nwt -5.23 -4.35 -5.24 -5.37 -4.66\n*** *** *** *** ***\n(0.55)   (0.60)   (0.77)   (0.68)   (0.56)  \n         \nvs         3.15                           \n        (1.19)                          \n \nam                 -0.02                   \n \n                (1.55)                  \n \ngear                         -0.24           \n \n                        (0.68)          \n \ncarb                                 -1.33  \n                                (0.56)  \n \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.75     0.80     0.75     0.75     0.79    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5\n\nO que nós observamos com essa tabela de regressão é que nenhuma variável causa um distúrbio muito grande no coeficiente de wt. Se houvesse multicolinearidade entre wt e outra variável, então o desvio padrão do coeficiente iria disparar, o valor do coeficiente mudaria bruscamente, a significância estatística diminuiria e o R2 iria aumentar muito também. Mas o que vemos, na verdade, é uma relativa estabilidade em todos esses de wt para cada modelo. É “relativa” porque os valores não são idênticos, mas tampouco são discrepantes. Rodando um VIF para cada um dos modelos de regressão múltipla, observamos que todos os valores VIFs estão abaixo de 2.\nPassemo a análise para gear.\nAnálise de gear\n\n\nShow code\n\ngear1 <- lm(mpg~gear+vs, mtcars)\ngear2 <- lm(mpg~gear+am, mtcars)\ngear3 <- lm(mpg~gear+wt, mtcars)\ngear4 <- lm(mpg~gear+carb, mtcars)\n\njtools::export_summs(gear_model, gear1, gear2, gear3, gear4, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 17.00 17.19 20.09 20.09\npt) *** *** *** *** ***\n(0.95)   (0.98)   (1.49)   (0.55)   (0.57)  \n         \ngear 2.89   2.16   0.06     -0.24    4.11 ***\n \n(0.97)   (0.76)   (1.47)   (0.68)   (0.60)  \n         \nvs         7.06 ***                        \n        (1.50)                          \n \nam                 7.14                   \n                (2.95)                  \n \nwt                         -5.37        **\n                        (0.68)          \n \ncarb                                 -4.45\n***\n                                (0.60)  \n \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.23     0.56     0.36     0.75     0.73    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5\n\nRepetindo o mesmo teste, mas agora com o foco na variável gear, nós observamos um ponto interessante: a adição da variável wt faz com que gear perca totalmente a sua significância estatística. Lembrando da tabela anterior (sobre a mudança do coeficiente wt com a adição de outras variáveis), vemos que gear não influencia o valor de wt, mas que o invereso acontece. Podemos, então, avaliar se existe alguma interação entre wt e gear.\n\n\nShow code\n\ninteracao_gear_wt <- lm(mpg~gear*wt, mtcars)\n\np1 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = gear)) +\n  scale_color_gradient2(midpoint=4, low=\"#c19615\", mid=\"#1594c2\" ,high=\"#16c298\", space=\"Lab\") +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  theme(legend.position = 'bottom')\n\np2 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = gear)) +\n  scale_color_gradient2(midpoint=4, low=\"#c19615\", mid=\"#1594c2\" ,high=\"#16c298\", space=\"Lab\") +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  facet_wrap(~ gear, ncol=2, scales=\"free\") +\n  guides(colour = \"none\")\n\ngridExtra::grid.arrange(p1, p2, widths=c(1.5,2))\n\n\n\n\nVemos, por esse gráfico, que para cada diferente gear o efeito de wt sobre y não muda, a relação sempre é negativa.\nLevando tudo isso em consideração, podemos concluir que gear e wt não possuem nem uma relação multicolinear, nem realizam uma interação entre si. A única obseração que nos sobra é que todo o efeito que gear desempenha sobre mpg já está sendo captado por wt. Devemos, então, excluir gear do nosso modelo, a fim de ter um modelo mais parcimonioso.\nFalta agora apenas a análise de am.\nAnálise de am\n\n\nShow code\n\nam1 <- lm(mpg~am+vs, mtcars)\nam2 <- lm(mpg~am+gear, mtcars)\nam3 <- lm(mpg~am+wt, mtcars)\nam4 <- lm(mpg~am+carb, mtcars)\n\njtools::export_summs(am_model, am1, am2, am3, am4, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 17.15 14.59 17.19 20.10 16.98\npt) *** *** *** *** ***\n(1.12)   (0.93)   (1.49)   (0.83)   (0.78)  \n         \nam 7.24 *** 6.07 *** 7.14    -0.02    7.65 **\n \n(1.76)   (1.27)   (2.95)   (1.55)   (1.22)  \n         \nvs         6.93 ***                        \n        (1.26)                          \n \ngear                 0.06                    \n                (1.47)                  \n \nwt                         -5.24        \n***\n                        (0.77)          \n \ncarb                                 -3.54\n***\n                                (0.61)  \n \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.36     0.69     0.36     0.75     0.70    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5\n\nO que observamos é que am, igual ao que ocorre com gear perde toda a sua significância estatística com a adição de wt. Entretanto, o inverso não é verdadeiro: am não retira o efeito de wt. Vamos então realizar a mesma análise de interação am com wt\n\n\nShow code\n\np3 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = am)) +\n  #scale_color_gradient2(midpoint=4, low=\"#c19615\", mid=\"#1594c2\" ,high=\"#16c298\", space=\"Lab\") +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  theme(legend.position = 'bottom')\n\n\np4 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = am)) +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  facet_wrap(~ am, ncol=2, scales=\"free\") +\n  guides(colour = \"none\")\n\n\ngridExtra::grid.arrange(p3, p4, widths=c(1.5,2))\n\n\n\n\nNovamente, o que observamos é que am não influencia o resultado de wt. Não há nem multicolineridade, nem interação. A melhor solução, portanto, é retirar am do modelo.\nAnálise de vs e carb\nAté aqui vimos que cyl e hp tinham multicolinearidade com as demais variáveis porque possuíam VIFs extremamente altos. Então excluímos eles do modelo. Vimos também que os efeitos de gear e de am sobre mpg eram absorvidos por wt. Então também excluímos eles, a fim de deixar o modelo mais parcimonioso.\nDas 7 variáveis inciais, portanto, sobraram 3: wt, vs e carb. Já análisamos wt. Falta apenas vs e carb.\nSe começarmos rodando uma regressão com as três variáveis faltantes, observamos que, combinadas com wt, tanto carb quanto vs perdem sua significância estatística.\n\n\nShow code\n\na <- lm(mpg~wt + vs + carb, mtcars)\nsummary(a)\n\n\n\nCall:\nlm(formula = mpg ~ wt + vs + carb, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0980 -2.3545  0.1704  1.2852  5.6616 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  34.3808     2.5190  13.648 6.75e-14 ***\nwt           -4.3036     0.6118  -7.035 1.19e-07 ***\nvs            2.3489     1.3062   1.798   0.0829 .  \ncarb         -0.5234     0.3751  -1.395   0.1739    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.735 on 28 degrees of freedom\nMultiple R-squared:  0.8139,    Adjusted R-squared:  0.794 \nF-statistic: 40.83 on 3 and 28 DF,  p-value: 2.349e-10\n\nIsso não indica multicolinearidade porque os VIFs das variáveis são muito baixos.\n\n\nShow code\n\ncar::vif(a)\n\n\n      wt       vs     carb \n1.484433 1.795593 1.520735 \n\nAssim, temos que fazer uma análise mais minuciosa sobre o comportamento dos coeficientes ao adicionarmos as variáveis uma a uma.\n\n\nShow code\n\nwt1 <- lm(mpg~wt+vs, mtcars)\nwt4 <- lm(mpg~wt+carb, mtcars)\nwt5 <- lm(mpg~vs+carb, mtcars)\n\njtools::export_summs(wt_model, vs_model, carb_model, wt1, wt4, wt5, a, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 16.62 20.09 18.71 20.09\npt) *** *** *** *** ***\n(0.54)   (1.08)   (0.90)   (0.72)   (0.50)  \n         \nwt -5.23                 -4.35 -4.66\n*** *** ***\n(0.55)                   (0.60)   (0.56)  \n     \nvs         7.94 ***         3.15 *          \n        (1.63)           (1.19)          \n   \ncarb                 -3.32         -1.33    \n                (0.92)           (0.56)  \n   \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.75     0.44     0.30     0.80     0.79    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation.  p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5, Model 6, Model 7\n6/8 columns shown.\n\nO que observamos é que as variáveis vs e carb, sem a presença de wt possuem uma significância estatística alta, a 99,999% (Modelos 1, 2 e 3). Combinadas individualmente com wt, elas ainda mantém sua significância estatística (modelos 4 e 5), mas a 95% de certeza. Em um modelo sem wt, mas com ambas as variáveis vse carb, o que observamos é que carb perde sua significância, enquanto vs se mantém significante a 99% (modelo 6).\nPara continuar a análise, iremos observar o que acontece quando as variáveis interagem entre si.\n\n\nShow code\n\nwt6 <- lm(mpg~wt+vs+wt*vs, mtcars)\nwt7 <- lm(mpg~wt+carb+wt*carb, mtcars)\nwt8 <- lm(mpg~carb+vs+carb*vs, mtcars)\n\njtools::export_summs(wt_model, wt6, wt7, wt8, scale=TRUE)\n\n\n────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4\n───────────────────────────────────────────────────── (Intercept 20.09 *** 18.27 *** 19.34 *** 17.06 ***\n)\n(0.54)    (0.69)    (0.53)    (1.19)   \nwt -5.23 *** -3.43 *** -4.81 ***        \n(0.55)    (0.68)    (0.52)           \nvs         2.41            5.37   \n        (1.15)            (2.07)   \nwt:vs         -2.85                   \n        (1.19)                   \ncarb                 -1.16    -0.90    \n                (0.52)    (1.13)   \nwt:carb                 1.81           \n                (0.68)           \ncarb:vs                         -2.45    \n                        (2.21)   \n───────────────────────────────────────────────────── N 32        32        32        32       \nR2 0.75     0.83     0.83     0.51    \n────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. ** p < 0.001; **\np < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4\n\nO que observamos com as interações é que, quando vs e carb interagem individualmente com wt, todos os coeficientes se mantém estatisticamente relevantes (modelos 2 e 3). Entretanto, quando realizamos uma interação apenas entre essas duas variáveis, carb perde sua significância (modelo 4). Se carb perde a significância quando interage com vs, então vou optar por manter no modelo apenas vs, a fim de garantir um modelo mais parcimonioso.\nConclusão parcial\nCom todas as alterações no modelo, ficamos apenas com duas variáveis no final e uma interação:\n\\[\n\\operatorname{adjusted \\ model:\\ mpg} = \\beta_{0} + \\beta_{1}(\\operatorname{wt}) + \\beta_{2}(\\operatorname{vs}) + \\beta_{3}(\\operatorname{wt*vs}) + \\epsilon\n\\]\nCalculando os coeficientes, ficamos com o seguinte modelo: \\[\n\\operatorname{adjusted \\ model:\\ mpg} = 29.53 - 3.50(\\operatorname{wt}) + 11.77(\\operatorname{vs}) - 2.90(\\operatorname{wt*vs}) + \\epsilon\n\\]\nDiagnóstico do modelo\nPor fim, resta apenas avaliar se o modelo ficou bom ou não.\n\n\nShow code\n\nplot(adjusted)\n\n\n\n\nA começar pelo gráfico de resíduos, há duas observações improtantes. Primeiro, os resíduos não ficaram iguais a zero. Isso é bom, uma vez que resíduo 0 significaria um sobreajuste do modelo. Seria tão artificial que seria um modelo ruim. A segunda obseravção importante é que a forma como os resíduos se distribuem não possui nenhum padrão. A distribuição aleatória dos resíduos indica um modelo saudável.\nAlém disso, analisando o gráfico que nos indica a distância de Cook e o efeito alavanca de outliers, o que observamos é que não existem leverage outliers. Os pontos estão bem distantes da região de cook.\nConclusão e discussão\nNo fim, portanto, podemos concluir que a melhor explicação que podemos dar para a eficiência dos carros envolve o peso (wt) e o tipo de motor (vs). Essas variáveis interagem entre si, porque cada tipo de motor possui um peso diferente.\nComo uma de nossas variáveis é binária, o intercepto se torna uma casela de referência. Essa casela indica a eficiência do carro cujo motor é V-shaped e não pesa nada (algo que só é possível em condições de laboratório, quando anulamos a gravidade). Este motor (v-shaped, sem peso) roda 29.53 milhas por galão de combustível. Se mudarmos o motor para um motor straight, então a eficiência aumenta em 11 milhas por galão, em média, ficando, aproximadamente, 41 mpg. Mas isso só se aplica também nas condições ideais sem gravidade, em que o peso permanece 0.\nQuando começamos a considerar a variável de peso, então a interpretação do modelo se modifica ligeiramente, por causa da interação. No caso do motor V-shaped, para cada 1000 libras que o carro ganha, a sua eficiência diminui em 3.5 milhas por galão. Para o motor straight, a cada 1000 libras que o carro ganha, então a eficiência do motor diminui em média 5.9 milhas por galão.\n\n\n\n",
    "preview": "posts/2021-02-05-tcc/tcc_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-05-05T13:47:03-03:00",
    "input_file": "tcc.utf8.md"
  }
]
