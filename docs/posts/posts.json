[
  {
    "path": "posts/2021-02-05-anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974/",
    "title": "Análise do Consumo Médio de Combustível de Carros Modelos 1973/1974",
    "description": "O conjunto de dados, denominado de `mtcars`, foi obtido a partir das edições de março, abril, junho e julho de 1974 da revista *Motor Trend* para um estudo realizado por Hocking (1976) e posteriormente, reportado por Henderson e Velleman (1981). Os dados, em questão, são referentes ao consumo de gasolina e dez características físicas de 32 automóveis modelos 1973-1974.",
    "author": [
      {
        "name": "Elizabeth Mie Hashimoto",
        "url": "https://www.linkedin.com/in/elizabeth-mie-hashimoto-a416a917/"
      }
    ],
    "date": "2021-02-05",
    "categories": [],
    "contents": "\n\nShow code\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(gtsummary)\nlibrary(xtable)\n\n\n\nVERSÃO PDF\nIntrodução\nNa crise petrolífera de 1973, membros da Organização dos Países Árabes Exportadores de Petróleo (OPAEP) aplicaram sanções em protesto ao apoio dos Estados Unidos e outras nações à Israel durante a Guerra do Yom Kippur. O conflito resultou no aumento do preço do petróleo de três dólares por barril para cerca de 12 doláres no mundo inteiro, sendo que os preços fixados para os Estados Unidos foram ainda maiores.\nComo uma alternativa à alta do preço do petróleo no mercado mundial, os Estados Unidos iniciaram um programa de eficiência energética, conhecido como Corporate Average Fuel Economy (CAFE), com o propósito de reduzir o consumo de combustível de carros, pick-ups, minivans e SUVs (Almeida Filho, 2018).\nAcredita-se que a melhoria no consumo médio de combustível dos automóveis leva à redução das contas de importação de petróleo, ou seja, pode resultar em economias estimadas nas contas anuais de importação de petróleo no valor de 300 bilhões de dólares em 2025 e 600 bilhões em 2050 (Global fuel economy initiative, 2021). Por outro lado, a eficiência do combustível depende de muitas características do veículo, incluindo as especificações do motor, resistência aerodinâmica, peso, combustível e entre outros atributos.\nNesse contexto, buscou-se validar a hipótese de que modificações na estrutura do automóvel aumenta o seu consumo médio. Portanto, o presente trabalho teve como objetivo identificar quais características do carro explica a sua eficiência medida em milhas por galão. As análises foram feitas utilizando o software R versão 4.0.3, considerando um nível de significância de 5%.\nAnálise Exploratória\nO conjunto de dados, denominado de mtcars, foi obtido a partir das edições de março, abril, junho e julho de 1974 da revista Motor Trend para um estudo realizado por Hocking (1976) e posteriormente, reportado por Henderson e Velleman (1981). Os dados, em questão, são referentes ao consumo de gasolina e dez características físicas de 32 automóveis modelos 1973-1974. O mesmo está disponível na biblioteca datasets do software R para consulta.\nDessa forma, de acordo com a hipótese formulada, as variáveis observadas no conjunto de dados são definidas como:\n\n\\(\\checkmark\\) Variável resposta\nmpg: eficiência (milhas por galão de combustível).\n\\(\\checkmark\\) Variável explicativa\ncyl: número de cilindros.\ndisp: cilindradas (polegada cúbica).\nhp: potência bruta (HP).\ndrat: relação de eixo traseiro.\nwt: peso (1000 libras).\nqsec: tempo no quarto de milha (segundos).\nvs: formato do motor (0 = V e 1 = linha).\nam: tipo de transmissão (0 = automático e 1 = manual).\ngear: número de marchas para frente.\ncarb: número de carburadores.\nPara reduzir as informações do conjunto de dados, estatísticas descritivas de cada uma das variáveis quantitativas foram obtidas e apresentadas na Tabela 1. Os resultados mostram que não há nenhuma dado faltante e portanto, não há necessidade de imputar valores. Além disso, em média, a eficiência dos carros é de 20,09 mpg e são carros com 2 carburadores, seis cilindros e peso de 3,22 \\(\\times 1000\\) libras.\n\nShow code\nresumo <- mtcars %>%\n  select(-am,-vs) %>% \n  pivot_longer(everything()) %>%\n  group_by(name) %>% \n  summarise_at(\"value\", \n               list(Missing =~sum(is.na(.)),media=~mean(.),\n                    desvPad=~sd(.), minimo=~min(.),\n                    Q1=~quantile(.,0.25),med=~median(.),\n                    Q3=~quantile(.,0.75),maxi=~max(.))) %>% \n  mutate_if(is.numeric, format, digits=3,nsmall = 2)\n\ncolnames(resumo) <- c('Variável', 'Missing', 'Média',\n                      'Desvio padrão', 'Mínimo', 'Q1',\n                      'Mediana', 'Q3', 'Máximo')\nkbl(resumo, booktabs = T, caption = 'Estatísticas descritivas das variáveis de natureza quantitativa', longtable = T) %>% \n  kable_styling(position = 'center',latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 1: Estatísticas descritivas das variáveis de natureza quantitativa\n\n\nVariável\n\n\nMissing\n\n\nMédia\n\n\nDesvio padrão\n\n\nMínimo\n\n\nQ1\n\n\nMediana\n\n\nQ3\n\n\nMáximo\n\n\ncarb\n\n\n0\n\n\n2.81\n\n\n1.615\n\n\n1.00\n\n\n2.00\n\n\n2.00\n\n\n4.00\n\n\n8.00\n\n\ncyl\n\n\n0\n\n\n6.19\n\n\n1.786\n\n\n4.00\n\n\n4.00\n\n\n6.00\n\n\n8.00\n\n\n8.00\n\n\ndisp\n\n\n0\n\n\n230.72\n\n\n123.939\n\n\n71.10\n\n\n120.83\n\n\n196.30\n\n\n326.00\n\n\n472.00\n\n\ndrat\n\n\n0\n\n\n3.60\n\n\n0.535\n\n\n2.76\n\n\n3.08\n\n\n3.70\n\n\n3.92\n\n\n4.93\n\n\ngear\n\n\n0\n\n\n3.69\n\n\n0.738\n\n\n3.00\n\n\n3.00\n\n\n4.00\n\n\n4.00\n\n\n5.00\n\n\nhp\n\n\n0\n\n\n146.69\n\n\n68.563\n\n\n52.00\n\n\n96.50\n\n\n123.00\n\n\n180.00\n\n\n335.00\n\n\nmpg\n\n\n0\n\n\n20.09\n\n\n6.027\n\n\n10.40\n\n\n15.43\n\n\n19.20\n\n\n22.80\n\n\n33.90\n\n\nqsec\n\n\n0\n\n\n17.85\n\n\n1.787\n\n\n14.50\n\n\n16.89\n\n\n17.71\n\n\n18.90\n\n\n22.90\n\n\nwt\n\n\n0\n\n\n3.22\n\n\n0.978\n\n\n1.51\n\n\n2.58\n\n\n3.33\n\n\n3.61\n\n\n5.42\n\n\nNa Figura 1 é apresentada um correlograma das variáveis explicativas. Por meio do gráfico, observou-se que as variáveis explicativas apresentavam uma alta correlação, ou seja, há indicativos de problema de multicolinearidade.\n\nShow code\nmtcars %>% \n  select(-vs,-am, -mpg) %>% \n  ggpairs() \n\n\n\n\nFigure 1: Matriz de correlação das variáveis explicativas quantitativas\n\n\n\nNa Figura 2 são apresentados os gráficos de dispersão, na qual observou-se que uma relação linear da variável resposta com as variáveis , ,  e . Nas demais variáveis, a relação tende a ser não linear.\n\nShow code\n# Gráfico de dispersão\n\nfig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point() +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)')\n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point() +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)')\n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point() +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point() +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point() +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)')\n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point() +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point() +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\nfig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point() +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') \n  #+ geom_smooth(method = lm, se = FALSE)\n\n#grid.arrange(fig2, fig3, fig4, fig5, fig6, ncol = 3, nrow = 2)\n\ngrid.arrange(fig1, fig2, fig3, fig4, fig5, fig6, fig7, fig8, ncol = 3, nrow = 3)\n\n\n\n\nFigure 2: Gráfico de dispersão\n\n\n\nNas Figuras 3-5 são apresentados os gráficos de dispersão em função de outras covariáveis.\n\nShow code\n# Gráfico de dispersão com pontos estratificados\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  #geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') +\n  theme(legend.position = 'none')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(cyl))) +\n  geom_smooth(method = lm, aes(colour = factor(cyl)), se = FALSE) +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') \n\ngrid.arrange(ffig2, ffig3, ffig4, ffig5, ffig6, ffig7, ffig8,\n             ncol = 2, nrow = 4)\n\n\n\n\nFigure 3: Gráfico de dispersão com pontos estratificados pelo número de cilindros\n\n\n\n\nShow code\n# Gráfico de dispersão com pontos estratificados\n\nffig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  #geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'none')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(vs))) +\n  geom_smooth(method = lm, aes(colour = factor(vs)), se = FALSE) +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') + \n  theme(legend.position = 'top')\n\ngrid.arrange(ffig1, ffig2, ffig3, ffig4, ffig5, ffig6, ffig7, ffig8,\n             ncol = 2, nrow = 4)\n\n\n\n\nFigure 4: Gráfico de dispersão com pontos estratificados pelo formato do motor\n\n\n\n\nShow code\n# Gráfico de dispersão com pontos estratificados\n\nffig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Cilindradas (in^3)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Potência (HP)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Relação de eixo traseiro', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Peso (1000 lb)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  #geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Tempo (s)', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig7 <- mtcars %>% \n  ggplot(aes(x=gear,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'none')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(am))) +\n  geom_smooth(method = lm, aes(colour = factor(am)), se = FALSE) +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') +  \n  theme(legend.position = 'top')\n\ngrid.arrange(ffig1, ffig2, ffig3, ffig4, ffig5, ffig6, ffig7, ffig8,\n             ncol = 2, nrow = 4)\n\n\n\n\nFigure 5: Gráfico de dispersão com pontos estratificados pelo tipo de transmissão\n\n\n\n\nShow code\n# Gráfico de dispersão com pontos estratificados\n\nffig1 <- mtcars %>% \n  ggplot(aes(x=cyl,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig2 <- mtcars %>% \n  ggplot(aes(x=disp,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig3 <- mtcars %>% \n  ggplot(aes(x=hp,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig4 <- mtcars %>% \n  ggplot(aes(x=drat,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig5 <- mtcars %>% \n  ggplot(aes(x=wt,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig6 <- mtcars %>% \n  ggplot(aes(x=qsec,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE) +\n  theme(legend.position = 'top')\n\nffig8 <- mtcars %>% \n  ggplot(aes(x=carb,y=mpg)) +\n  geom_point(aes(colour = factor(gear))) +\n  geom_smooth(method = lm, aes(colour = factor(gear)), se = FALSE)\n\ngrid.arrange(ffig1, ffig2, ffig3, ffig4, ffig5, ffig6, ffig8,\n             ncol = 4, nrow = 2)\n\n\n\nNa Figura 6 são apresentados os boxplots, na qual observou-se que há uma possível diferença entre o formato do motor em relação a eficiência do carro, assim como há uma diferença entre o tipo de transmissão.\n\nShow code\n# Boxplot\n\nfig9 <- mtcars %>% \n  ggplot(aes(x=as.factor(cyl),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Número de cilindros', y = 'Eficiência (mpg)') \n\nfig10 <- mtcars %>% \n  ggplot(aes(x=as.factor(vs),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Formato do motor', y = 'Eficiência (mpg)') \n\nfig11 <- mtcars %>% \n  ggplot(aes(x=as.factor(am),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Tipo de transmissão', y = 'Eficiência (mpg)') \n\nfig12 <- mtcars %>% \n  ggplot(aes(x=as.factor(gear),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Número de marchas', y = 'Eficiência (mpg)') \n\nfig13 <- mtcars %>% \n  mutate(carb_novo=ifelse(carb<=2,0,1)) %>% \n  ggplot(aes(x=as.factor(carb_novo),y=mpg)) +\n  geom_boxplot() +\n  labs(x = 'Número de carburadores', y = 'Eficiência (mpg)') \n\ngrid.arrange(fig10, fig11, ncol = 2, nrow = 1)\n\n\n\n\nFigure 6: Boxplot\n\n\n\nModelagem\nO modelo de regressão linear múltiplo, como definido em James et al. (2013) é dado por\n\\[\\begin{equation}\\label{eq:1}\\bf{Y}=\\beta_0+\\beta_1\\bf{X}_1+\\ldots+\\beta_p\\bf{X}_p+\\mathbf{\\varepsilon},\\end{equation}\\] em que \\(\\bf{Y}\\) representa a variável resposta, \\(\\bf{X}_1,\\ldots, \\bf{X}_p\\) é o vetor de variáveis explicativas, \\(\\beta_0,\\ldots, \\beta_p\\) são os parâmetros a serem estimados e \\(\\bf{\\varepsilon}\\) é o vetor de termos aleatórios do modelo.\nEntão, dado o conjunto de dados , o modelo de regressão (1), reescrito em função do conjunto de dados  é dado por \\[mpg_i = \\beta_0 + \\beta_1cyl_i + \\beta_2disp_i + \\beta_3hp_i + \\beta_4drat_i + \\beta_5wt_i + \\ldots + \\beta_9gear_i + \\beta_{10}carb_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\] sendo este, denominado de modelo completo. Os parâmetros \\(\\beta_0,\\ldots, \\beta_{10}\\) foram estimados pelo método de mínimos quadrados com auxílio computacional do software . Além disso, o efeito das variáveis explicativadas sobre a variável resposta {mpg} foram testadas considerando as seguintes hipóteses estatísticas \\[H_0: \\beta_j=0 \\quad vs \\quad H_a: \\beta_j\\neq 0, j=0,1,\\ldots, 10.\\]\nNessse cenário, obteve-se os seguintes resultados:\n\n\\(\\checkmark\\) Modelo completo\nAs estimativas, bem os erros padrões e os \\(p-valores\\) dos parâmetros do modelo completo foram obtidas pelo código\n\n\nShow code\nmod_completo <- lm(mpg ~ ., data=mtcars)\nsummary(mod_completo)\n\n\n\ne apresentadas na Tabela 2. Os resultados apresentados nessa tabela indicam que nenhuma da variáveis explicativas tem alguma relação com a eficiência do carro, pois o \\(p\\)-valor é maior do o nível de significância e consequentemente, levando a rejeição da hipótese nula.\nPor outro lado, na análise exploratório foi identificado o problema de multicolinearidade. Dessa forma, o fator de inflação da variância (VIF) foi calculo pelo seguinte código\n\nShow code\ncar::vif(mod_completo)\n\n\n\ne os valores apresentados na Tabela 3. Segundo James et al. (2013), variáveis explicativas cujo VIF for maior do que cinco podem ser removidas do modelo como uma das soluções para o problema. Nessa situação, de acordo com a Tabela 3, as variáveis explicativas , ,  e  foram mantidas no modelo. Justifica-se a permanência da variável  em função do comportamento linear quando comparado com as demains variáveis quantativas contínuas (Figura 2).\n\nShow code\noptions(scipen=1, digits=3)\nmod_completo %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo completo\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 2: Estimativas dos parâmetros do modelo completo\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n12.303\n\n\n18.718\n\n\n0.657\n\n\n0.518\n\n\ncyl\n\n\n-0.111\n\n\n1.045\n\n\n-0.107\n\n\n0.916\n\n\ndisp\n\n\n0.013\n\n\n0.018\n\n\n0.747\n\n\n0.463\n\n\nhp\n\n\n-0.021\n\n\n0.022\n\n\n-0.987\n\n\n0.335\n\n\ndrat\n\n\n0.787\n\n\n1.635\n\n\n0.481\n\n\n0.635\n\n\nwt\n\n\n-3.715\n\n\n1.894\n\n\n-1.961\n\n\n0.063\n\n\nqsec\n\n\n0.821\n\n\n0.731\n\n\n1.123\n\n\n0.274\n\n\nvs\n\n\n0.318\n\n\n2.105\n\n\n0.151\n\n\n0.881\n\n\nam\n\n\n2.520\n\n\n2.057\n\n\n1.225\n\n\n0.234\n\n\ngear\n\n\n0.655\n\n\n1.493\n\n\n0.439\n\n\n0.665\n\n\ncarb\n\n\n-0.199\n\n\n0.829\n\n\n-0.241\n\n\n0.812\n\n\n\nShow code\nout_vif1 <- car::vif(mod_completo) \n\nkbl(out_vif1, booktabs = T, caption = 'Fator de inflação da variância das variáveis explicativas', longtable = T, col.names = c('VIF')) %>% \n  kable_styling(position = 'center',latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 3: Fator de inflação da variância das variáveis explicativas\n\n\n\n\nVIF\n\n\ncyl\n\n\n15.37\n\n\ndisp\n\n\n21.62\n\n\nhp\n\n\n9.83\n\n\ndrat\n\n\n3.38\n\n\nwt\n\n\n15.16\n\n\nqsec\n\n\n7.53\n\n\nvs\n\n\n4.97\n\n\nam\n\n\n4.65\n\n\ngear\n\n\n5.36\n\n\ncarb\n\n\n7.91\n\n\n\n\\(\\checkmark\\) Modelo reduzido\nmod_red0: modelo reduzido 1\n\\[mpg_i = \\beta_0 + \\beta_4drat_i + \\beta_5wt_i + \\beta_7vs_i + \\beta_{8}am_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\]\ncujas estimativas dos parâmetros são obtidas por meio do seguinte código\n\n\nShow code\nmod_red1 <- lm(mpg ~ drat + wt + vs + am, data=mtcars)\nsummary(mod_red1)\n\n\n\ne os resultados apresentados na Tabela 4. Como a hipótese nula não foi rejeitada para os coeficientes associados as variáveis  (\\(p\\)-valor = 0,000) e  (\\(p\\)-valor = 0,016), ou seja, o peso e o formato do motor tem um possível efeito sobre a eficiência do carro. Entretanto, especialistas em mecânica acreditam o tipo de transmissão tem alguma influência sobre o consumo médio de um automável. Por essa razão, a variável  ainda foi mantida no modelo. Além disso, na Figura 5 foi observado uma possível interação entre o tipo de transmissão e o peso do carro.\n\nShow code\noptions(scipen=1, digits=3)\nmod_red1 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 1\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 4: Estimativas dos parâmetros do modelo reduzido 1\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n27.573\n\n\n6.874\n\n\n4.011\n\n\n0.000\n\n\ndrat\n\n\n0.682\n\n\n1.559\n\n\n0.438\n\n\n0.665\n\n\nwt\n\n\n-3.699\n\n\n0.932\n\n\n-3.967\n\n\n0.000\n\n\nvs\n\n\n3.452\n\n\n1.348\n\n\n2.561\n\n\n0.016\n\n\nam\n\n\n1.115\n\n\n1.736\n\n\n0.642\n\n\n0.526\n\n\n\nmod_red2: modelo reduzido 2\n\\[mpg_i = \\beta_0  + \\beta_{7}vs_i + \\beta_{5}wt_i + \\beta_{8}am_i + \\beta_{58}wt_i\\times am_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\]\ncujas estimativas dos parâmetros são obtidas por meio do seguinte código\n\n\nShow code\nmod_red2 <- lm(mpg ~ vs + wt*am, data=mtcars)\nsummary(mod_red2)\n\n\n\ne os resultados apresentados na Tabela 5. De acordo com essa tabela, a hipótese nula foi rejeitada em todos os casos, pois o \\(p\\)-valor foi menor do que o nível de significância. Dessa forma, o formato do motor e assim como a interação entre peso e tipo de transmissão tem algum efeito sobre a eficiência do carro.\n\nShow code\noptions(scipen=1, digits=3)\nmod_red2 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 2\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 5: Estimativas dos parâmetros do modelo reduzido 2\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n26.25\n\n\n3.346\n\n\n7.85\n\n\n0.000\n\n\nvs\n\n\n2.93\n\n\n1.095\n\n\n2.68\n\n\n0.012\n\n\nwt\n\n\n-2.70\n\n\n0.818\n\n\n-3.30\n\n\n0.003\n\n\nam\n\n\n14.32\n\n\n3.866\n\n\n3.70\n\n\n0.001\n\n\nwt:am\n\n\n-4.66\n\n\n1.329\n\n\n-3.51\n\n\n0.002\n\n\n\nmod_red3: modelo reduzido 3\nLevando em consideração a análise exploratória e a opinião de especialistas em mecânica, um modelo alternativo é dado por\n\\[mpg_i = \\beta_0  + \\beta_{5}wt_i + \\beta_{16}cyl6_i + \\beta_{18}cyl8_i + \\beta_{56}wt_i\\times cyl6_i + \\beta_{58}wt_i\\times cyl8_i + \\varepsilon_i, \\quad i=1,\\ldots, 32,\\]\ncujas estimativas dos parâmetros são obtidas por meio do seguinte código\n\n\nShow code\nmod_red3 <- lm(mpg ~ wt*factor(cyl), data=mtcars)\nsummary(mod_red3)\n\n\n\ne os resultados apresentados na Tabela 6. Como a variável  foi categorizada para simplificar a interpertação do efeito da interação, duas variáveis dummies foram criadas, assumindo a categoria  como casela de referência. Logo, verificou-se uma possível relação do peso, assim como do efeito da interação entre peso e número de cilindro sobre a eficiência do carro, uma vez que a hipótese de nula foi rejeitada.\n\n\nShow code\noptions(scipen=1, digits=3)\nmod_red3 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 3\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 6: Estimativas dos parâmetros do modelo reduzido 3\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n39.57\n\n\n3.19\n\n\n12.39\n\n\n0.000\n\n\nwt\n\n\n-5.65\n\n\n1.36\n\n\n-4.15\n\n\n0.000\n\n\nfactor(cyl)6\n\n\n-11.16\n\n\n9.36\n\n\n-1.19\n\n\n0.244\n\n\nfactor(cyl)8\n\n\n-15.70\n\n\n4.84\n\n\n-3.25\n\n\n0.003\n\n\nwt:factor(cyl)6\n\n\n2.87\n\n\n3.12\n\n\n0.92\n\n\n0.366\n\n\nwt:factor(cyl)8\n\n\n3.46\n\n\n1.63\n\n\n2.12\n\n\n0.043\n\n\nNa Tabela 7 são apresentados os valores de R2 e R2 ajustado para os três modelos reduzidos estimados. Os valores obtidos indicam que o modelo mod_red2 é mais adequado entre os três modelos estimados, seguido do modelo mod_red3 e mod_red1. Entretanto, os valores de R2 ajustados não são suficientes para determinar a adequação do modelo. À vistsa disso, uma análise de resíduo foi realizada.\n\nShow code\nmodelo <- c('mod_red1','mod_red2','mod_red3')\nr2 <- c(0.809,0.868,0.862)\nr2_adj <- c(0.781,0.849,0.835)\nr2_df <- data.frame(Modelo=modelo,R2=r2, R2_ajustado=r2_adj)\n\nkbl(r2_df, booktabs = T, caption = 'Valores de R2 e R2 ajustados dos modelos reduzidos', longtable = T, align = 'c') %>% \n  kable_styling(position = 'center',latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 7: Valores de R2 e R2 ajustados dos modelos reduzidos\n\n\nModelo\n\n\nR2\n\n\nR2_ajustado\n\n\nmod_red1\n\n\n0.809\n\n\n0.781\n\n\nmod_red2\n\n\n0.868\n\n\n0.849\n\n\nmod_red3\n\n\n0.862\n\n\n0.835\n\n\nDiagnóstico do Modelo\nDados completo\nPara cada modelo reduzido estimado foi realizado uma análise de resíduo e os resultados são apresentados nas Figuras 7, 8 e 9, respectivamente.\n\n\\(\\checkmark\\) Modelo reduzido 1\nDe acordo com a Figura 7:\nResiduals vs Fitted: uma leve semelhança com uma parábola com concavidade voltada para cima, ou seja, temos um possível padrão não linear entre as variáveis.\nNormal Q-Q: A maior parte dos pontos encontra-se em torno da linha tracejada, exceto pelos pontos , ,  e outros dois pontos não identificados na parte inferior da figura. O que indica que esses três pontos são possíveis outliers.\nScale-Location: aparentemente os resíduos aparecem espalhados aleatoriamente, o que indica que a suposição de homocedasticidade é satisfeita, ou seja, a variância é constante.\nResiduals vs Leverage: como todos os pontos são menores do que a distância de Cook, temos evidências de que não há pontos de alavanca.\n\\(\\checkmark\\) Modelo reduzido 2\nDe acordo com a Figura 8:\nResiduals vs Fitted: os resíduos não mostram nenhum padrão, uma vez que a linha vermelha se parece com uma linha reta.\nNormal Q-Q: A maior parte dos pontos encontra-se afastada da linha tracejada e além disso, os carros ,  e  foram apontados como possíveis outliers.\nScale-Location: aparentemente os resíduos aparecem espalhados aleatoriamente, o que indica que a suposição de homocedasticidade é satisfeita, ou seja, a variância é constante.\nResiduals vs Leverage: como todos os pontos são menores do que a distância de Cook, temos evidências de que não há pontos de alavanca.\n\\(\\checkmark\\) Modelo reduzido 3\nDe acordo com a Figura 9:\nResiduals vs Fitted: os resíduos não mostram nenhum padrão, uma vez que a linha vermelha se parece com uma linha reta.\nNormal Q-Q: Alguns pontos encontra-se afastada da linha tracejada e além disso, os carros ,  e  foram apontados como possíveis outliers.\nScale-Location: aparentemente os resíduos aparecem espalhados aleatoriamente, o que indica que a suposição de homocedasticidade é satisfeita, ou seja, a variância é constante.\nResiduals vs Leverage: como todos os pontos são menores do que a distância de Cook, temos evidências de que não há pontos de alavanca.\n\nShow code\npar(mfrow = c(2, 2))\nplot(mod_red1)\n\n\n\n\nFigure 7: Gráfico de resíduos do modelo reduzido 1\n\n\n\n\n\nShow code\npar(mfrow = c(2, 2))\nplot(mod_red2)\n\n\n\n\nFigure 8: Gráfico de resíduos do modelo reduzido 2\n\n\n\n\n\nShow code\npar(mfrow = c(2, 2))\nplot(mod_red3)\n\n\n\n\nFigure 9: Gráfico de resíduos do modelo reduzido 3\n\n\n\n\nDados reduzidos\nO modelo mod_red1 apresentou o menor valor de R2 ajustado e na análise de resíduo apontou a possível falta de um termo quadrático no modelo. Por essas razões, o modelo foi descartado para nova avaliação.\nEm relação aos modelos mod_red2 e mod_red3 foi realizado uma nova análise removendo os carros identificados como possíveis outliers.\n\n\\(\\checkmark\\) Modelo reduzido 2\nOs resultados são apresentados na Tabela 8 e na Figura 10 indicam que o formato do motor e o efeito da interação permanecem sendo significativos para explicar a variabilidade presente na eficiência do carro. Além disso, os pontos estãos mais próximos da linha tracejada no gráfico Normal Q-Q. Entretanto, pelo gráfico Scale-Location, há evidências de heterogeneidade de variâncias e outros carros foram identificados como possíveis outliers.\n\n\nShow code\nmtcars_red <- mtcars %>% \n  slice(-8L, -20L, -18L)\nmod_red21 <- lm(mpg ~ vs + wt*am, data=mtcars_red)\nsummary(mod_red21)\n\n\n\n\nShow code\noptions(scipen=1, digits=3)\nmod_red21 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 2 sem os possíveis outliers\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 8: Estimativas dos parâmetros do modelo reduzido 2 sem os possíveis outliers\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n26.94\n\n\n2.545\n\n\n10.59\n\n\n0.000\n\n\nvs\n\n\n1.87\n\n\n0.859\n\n\n2.18\n\n\n0.040\n\n\nwt\n\n\n-2.85\n\n\n0.621\n\n\n-4.58\n\n\n0.000\n\n\nam\n\n\n12.34\n\n\n3.074\n\n\n4.01\n\n\n0.001\n\n\nwt:am\n\n\n-4.13\n\n\n1.041\n\n\n-3.97\n\n\n0.001\n\n\n\nShow code\npar(mfrow = c(2, 2))\nplot(mod_red21)\n\n\n\n\nFigure 10: Gráfico de resíduos do modelo reduzido 2 sem outliers\n\n\n\n\n\\(\\checkmark\\) Modelo reduzido 3\nOs resultados são apresentados na Tabela 9 e na Figura 11 indicam que não houve grandes mudanças nos gráficos de resíduos. Porém, houve uma mudança na significância da interação entre  e  e também, novos foram identificados como possíveis outliers.\n\n\nShow code\nmtcars_red1 <- mtcars %>% \n  slice(-18L, -20L, -21L)\nmod_red31 <- lm(mpg ~ wt*factor(cyl), data=mtcars_red1)\nsummary(mod_red31)\n\n\n\n\nShow code\noptions(scipen=1, digits=3)\nmod_red31 %>% \n  summary() %>% \n  xtable() %>% \n  kable(caption = \"Estimativas dos parâmetros do modelo reduzido 3 sem os possíveis outliers\", \n        booktabs = T, align = \"c\",longtable = T) %>% \n  kable_styling(position = 'center',\n                latex_options = c(\"striped\", \"hold_position\"))\n\n\n\nTable 9: Estimativas dos parâmetros do modelo reduzido 3 sem os possíveis outliers\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nt value\n\n\nPr(>|t|)\n\n\n(Intercept)\n\n\n36.06\n\n\n2.61\n\n\n13.816\n\n\n0.000\n\n\nwt\n\n\n-4.45\n\n\n1.08\n\n\n-4.109\n\n\n0.000\n\n\nfactor(cyl)6\n\n\n-7.65\n\n\n7.21\n\n\n-1.061\n\n\n0.300\n\n\nfactor(cyl)8\n\n\n-12.19\n\n\n3.81\n\n\n-3.198\n\n\n0.004\n\n\nwt:factor(cyl)6\n\n\n1.67\n\n\n2.40\n\n\n0.696\n\n\n0.494\n\n\nwt:factor(cyl)8\n\n\n2.26\n\n\n1.28\n\n\n1.764\n\n\n0.091\n\n\n\nShow code\npar(mfrow = c(2, 2))\nplot(mod_red31)\n\n\n\n\nFigure 11: Gráfico de resíduos do modelo reduzido 3 sem outliers\n\n\n\nConclusão e Discussão\nDiante do exposto, o modelo mais adequado para explicar a variabiliade presente na eficiência dos carros modelos 1973-1974 é o modelo mod_red3. A opção por esse modelo foi em função dos gráficos dos resíduos se manterem com o mesmo padrão com ou sem os carros ,  e , apontados como possíveis outliers. Esses carros não foram identificados como pontos de alavanca, entretanto, são pontos influentes, pois a significância de um dos parâmetros do modelo foi alterada. Dessa forma, seria interessante levantar mais informações sobre esses carros, antes de removê-los por definitivo do conjunto de dados.\nPortanto, o modelo mod_red3 estimado é dado por \\[\\hat{mpg}_i = 39,57  -5,65wt_i -11,16cyl6_i -15,70cyl8_i + 2,87 wt_i\\times cyl6_i + 3,46wt_i\\times cyl8_i, \\quad i=1,\\ldots, 32,\\] A partir do modelo estimado, as seguintes interpretações podem ser feitas:\nwt: com \\(p\\)-valor=0,00o; temos evidências de que a cada 1000 libras que se aumenta no carro há uma redução de -5,65 mpg na eficiência média.\ncyl6: com \\(p\\)-valor = 0,244; temos indicativos de que não existe diferença significativa entre quatro cilindros (casela de referência) e seis cilindros em relação eficiência média.\ncyl8: com \\(p\\)-valor = 0,003; temos sinais de que existe diferença significativa entre quatro cilindros (casela de referência) e oito cilindros em relação eficiência média.\nPortanto, marginalmente, há o efeito do peso e do número de cilindros\nwt:cyl6: com \\(p\\)-valor = 0,366; temos evidências de que não existe diferença significativa entre a inclinação de quatro cilindros (casela de referência) e de seis cilindros em relação a eficiência média.\nwt:cyl8: com \\(p\\)-valor = 0,043; temos evidências de que existe diferença significativa entre a inclinação de quatro cilindros (casela de referência) e de oito cilindros em relação a eficiência média.\nPortanto, temos efeito da interação entre peso e número de cilindro do carro. Dessa forma, a hipótese de que modificações na estrutura do automóvel aumenta o seu consumo médio foi validada. Nesse caso, as modificações no peso e no número de cilindros do carro podem explicar a variabilidade presente no consumo médio de gasolina.\nPor fim, informações como relação peso e torque poderiam ser utilizadas no lugar de peso e potência. Outra informações que poderia ser utilizada é o tipo de carro, uma vez que carros esportivos são bem diferentes de sedãs.\nAgradecimentos\nAo professor Athos Damiani pelas aulas e dedicação ao curso. Aos mecânicos Marcelo Prataviera e Taka Kurihara e, também, aos alunos do curso de Engenharia Mecânica da UTFPR/Londrina, João Pedro Alves Cordeiro dos Santos e Pedro Henrique Barion pelo auxílio na compreensão das estruturas de um carro.\nReferências bibliográficas\nALMEIDA FILHO, G.M. Programa INOVAR-AUTO: atendimento das metas de eficiência energética e suas externalidades. 2018. Dissertação (Mestrado em Ciências) - Universidade de São Paulo, São Paulo.\nCRISE petrolífera de 1973. Wikipedia. Disponível em: https://pt.wikipedia.org/wiki/Crise_petrol%C3%ADfera_de_1973. Acesso em: 28 de jan. de 2021. \nFUEL efficiency. Wikipedia. Disponível em: https://en.wikipedia.org/wiki/Fuel_efficiency. Acesso em: 28 de jan. de 2021.\nHENDERSON, H.V.; VELLEMAN. P.F. Building multiple regression models interactively. Biometrics, v.37, p.391-411, 1981. \nHOCKING, R.R. The analysis and selection of variables in linear regression. Biometrics, v.32, p.1-49, 1976. \nJAMES, G.; WITTEN, D.; HASTIE. T.; TIBSHIRANI, R. An Introduction to Statistical Learning with Applications in R. New York: Springer, 2013. \nR Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL: https://www.R-project.org/ \nTOP reasons for supporting cleaner, more efficient vehicles. Global fuel economy initiative. Disponível em: https://www.globalfueleconomy.org/media/45140/top-reasons-leaflet.pdf. Acesso em: 28 de jan. de 2021.\n\n\n\n",
    "preview": "posts/2021-02-05-anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974/anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-02-05T16:45:57-03:00",
    "input_file": "anlise-do-consumo-mdio-de-combustvel-de-carros-modelos-19731974.utf8.md"
  },
  {
    "path": "posts/2021-02-04-curso-r-regresso-linear-br-exerccios-rlsm/",
    "title": "Exercícios RLSM",
    "description": "Resolução da lista de exercícios do Curso de Regressão Linear com R de janeiro de 2021.",
    "author": [
      {
        "name": "Elizabeth Mie Hashimoto",
        "url": "https://www.linkedin.com/in/elizabeth-mie-hashimoto-a416a917/"
      }
    ],
    "date": "2021-01-25",
    "categories": [],
    "contents": "\nPacotes\n\n\nlibrary(tidyverse) # manipulacao de data.frame\nlibrary(MASS) # dados Boston\nlibrary(broom)\n\n\n\nDados\nO banco de dados Boston apresenta registros de valores medianos das casas (medv) de 506 bairros de Boston. O objetivo é identificar quais das 13 variáveis explicativas estão associadas com esses valores e usá-las para fazer predições de preços das casas.\n\n\nglimpse(Boston)\n\n\nRows: 506\nColumns: 14\n$ crim    <dbl> 0.00632, 0.02731, 0.02729, 0.03237, 0.06905, 0.0298…\n$ zn      <dbl> 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 12.5, 12.5, 12…\n$ indus   <dbl> 2.31, 7.07, 7.07, 2.18, 2.18, 2.18, 7.87, 7.87, 7.8…\n$ chas    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ nox     <dbl> 0.538, 0.469, 0.469, 0.458, 0.458, 0.458, 0.524, 0.…\n$ rm      <dbl> 6.575, 6.421, 7.185, 6.998, 7.147, 6.430, 6.012, 6.…\n$ age     <dbl> 65.2, 78.9, 61.1, 45.8, 54.2, 58.7, 66.6, 96.1, 100…\n$ dis     <dbl> 4.0900, 4.9671, 4.9671, 6.0622, 6.0622, 6.0622, 5.5…\n$ rad     <int> 1, 2, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, …\n$ tax     <dbl> 296, 242, 242, 222, 222, 222, 311, 311, 311, 311, 3…\n$ ptratio <dbl> 15.3, 17.8, 17.8, 18.7, 18.7, 18.7, 15.2, 15.2, 15.…\n$ black   <dbl> 396.90, 396.90, 392.83, 394.63, 396.90, 394.12, 395…\n$ lstat   <dbl> 4.98, 9.14, 4.03, 2.94, 5.33, 5.21, 12.43, 19.15, 2…\n$ medv    <dbl> 24.0, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.…\n\n\n\n# Descrição das variáveis\nhelp(Boston)\n\n\n\nExercício 1\nFaça um gráfico de dispersão entre medv e rm.\n\n\nBoston %>% \n  ggplot() +\n  geom_point(aes(x = rm, y = medv)) +\n  labs(x = 'Número médio de quartos por habitação', y = 'Preço mediano das habitações do bairro (em 1000 dólares)')\n\n\n\n\nExercício 2\nAjuste um modelo de regressão linear simples utilizando medv como resposta e rm como explicativa e guarde em objeto chamado mod_simples. Consulte o summary(mod_simples) em seguida.\n\n\nmod_simples <- lm(medv ~ rm, data=Boston)\nsummary(mod_simples)\n\n\n\nCall:\nlm(formula = medv ~ rm, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.346  -2.547   0.090   2.986  39.433 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -34.671      2.650  -13.08   <2e-16 ***\nrm             9.102      0.419   21.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.616 on 504 degrees of freedom\nMultiple R-squared:  0.4835,    Adjusted R-squared:  0.4825 \nF-statistic: 471.8 on 1 and 504 DF,  p-value: < 2.2e-16\n\nExercício 3\nSabendo que medv é o preço mediano das habitações do bairro e o rm é o número médio de quartos por habitação,\ninterprete o parâmetro (Intercept).\n\\(\\blacktriangleright\\) Resposta: Nesse caso, -34.671 \\(\\times\\) 1000 dólares é a média do preço mediano das habitações quando temos zero quartos por habitação.\ninterprete o parâmetro rm.\n\\(\\blacktriangleright\\) Resposta: A cada um quarto por habitação que aumentamos por habitação, temos um acréscimo de 9.102 \\(\\times\\) 1000 dólares na média do preço mediano das habitações.\no número de quartos está associado com o valor da habitação? Por quê?\n\\(\\blacktriangleright\\) Resposta: Sim, pois ao nível de significância de 5%, rejeitamos a hipótese nula (\\(H_0: \\beta_1=0\\)), uma vez que o \\(p\\)-valor é menor do que 0,001. Dessa forma, temos evidências de que o preço mediano das habitações tem alguma relação com o número médio de quartos por habitação.\nExercício 4\nConsulte as saídas das funções\ncoef(mod_simples): mostra apenas as estimativas dos coeficientes de regressão.\nconfint(mod_simples): mostra o intervalo de 95% de confiança das estimativas dos coeficientes de regressão.\npredict(mod_simples): calcula os valores preditos do preço mediano das habitações, isto é, \\(\\hat{\\mbox{medv}}=-34,671+9,102 rm\\).\npredict(mod_simples, interval = \"confidence\"): calcula os valores preditos do preço mediano das habitações e o intervalo de 95% de confiança de cada valor predito.\naugment(mod_simples): cria um data frame com valores de medv, rm, valores preditos, resíduo e distância de Cook.\n\n\ncoef(mod_simples)\n\n\n(Intercept)          rm \n -34.670621    9.102109 \n\nconfint(mod_simples)\n\n\n                 2.5 %     97.5 %\n(Intercept) -39.876641 -29.464601\nrm            8.278855   9.925363\n\npredict(mod_simples) %>% head(n=10L)\n\n\n       1        2        3        4        5        6        7 \n25.17575 23.77402 30.72803 29.02594 30.38215 23.85594 20.05126 \n       8        9       10 \n21.50760 16.58335 19.97844 \n\npredict(mod_simples, interval = \"confidence\") %>% head(n=10L)\n\n\n        fit      lwr      upr\n1  25.17575 24.55039 25.80110\n2  23.77402 23.18536 24.36269\n3  30.72803 29.78817 31.66790\n4  29.02594 28.20203 29.84984\n5  30.38215 29.46676 31.29755\n6  23.85594 23.26582 24.44606\n7  20.05126 19.43134 20.67118\n8  21.50760 20.92234 22.09285\n9  16.58335 15.79375 17.37296\n10 19.97844 19.35611 20.60078\n\naugment(mod_simples)\n\n\n# A tibble: 506 x 8\n    medv    rm .fitted  .resid .std.resid    .hat .sigma     .cooksd\n   <dbl> <dbl>   <dbl>   <dbl>      <dbl>   <dbl>  <dbl>       <dbl>\n 1  24    6.58    25.2 -1.18      -0.178  0.00231   6.62 0.0000367  \n 2  21.6  6.42    23.8 -2.17      -0.329  0.00205   6.62 0.000111   \n 3  34.7  7.18    30.7  3.97       0.602  0.00523   6.62 0.000952   \n 4  33.4  7.00    29.0  4.37       0.662  0.00402   6.62 0.000885   \n 5  36.2  7.15    30.4  5.82       0.882  0.00496   6.62 0.00194    \n 6  28.7  6.43    23.9  4.84       0.733  0.00206   6.62 0.000555   \n 7  22.9  6.01    20.1  2.85       0.431  0.00227   6.62 0.000212   \n 8  27.1  6.17    21.5  5.59       0.846  0.00203   6.62 0.000727   \n 9  16.5  5.63    16.6 -0.0834    -0.0126 0.00369   6.62 0.000000295\n10  18.9  6.00    20.0 -1.08      -0.163  0.00229   6.62 0.0000306  \n# … with 496 more rows\n\nExercício 5\nUsando o data.frame gerado por augment(mod_simples) faça um gráfico de medv versus rm e em seguida desenhe a reta ajustada do mod_simples.\n\n\nboston_pred <- augment(mod_simples)\n\nboston_pred %>% \n  ggplot() +\n  geom_point(aes(x = rm, y = medv)) +\n  geom_line(aes(x = rm, y = .fitted), color=\"red\") +\n  labs(x = 'Número médio de quartos por habitação', y = 'Preço mediano das habitações do bairro (em 1000 dólares)')\n\n\n\n\nExercício 6\nFaça um gráfico de resíduos. Coloque os resíduos no eixo Y e os valores ajustados no eixo X.\n\n\nboston_pred %>% \n  ggplot() +\n  geom_point(aes(x = .fitted, y = .std.resid)) +\n  geom_hline(yintercept=0, linetype=\"dashed\") +\n  labs(x = 'Valores ajustados', y = 'Resíduos')\n\n\n\n\nExercício 7\nObserve os gráficos de plot(mod_simples).\n\n\nplot(mod_simples)\n\n\n\n\nApenas pela inspeção visual, responda: existem outliers? Eles são pontos de alavanca?\n\\(\\blacktriangleright\\) Resposta: Por meio das figuras, observamos que os pontos \\(\\sharp366\\), \\(\\sharp369\\) e \\(\\sharp373\\) são possíveis outliers. O gráfico de Residuals vs Leverage indica que não são pontos de alavanca.\nExercício 8\nAjuste um modelo mod_multiplo para medv explicado por rm e crim. Consulte o summary(mod_multiplo) em seguida.\n\n\nmod_multiplo <- lm(medv ~ rm + crim, data=Boston)\nsummary(mod_multiplo)\n\n\n\nCall:\nlm(formula = medv ~ rm + crim, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.608  -2.835  -0.380   2.592  38.839 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -29.24472    2.58809 -11.300   <2e-16 ***\nrm            8.39107    0.40485  20.726   <2e-16 ***\ncrim         -0.26491    0.03307  -8.011    8e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.237 on 503 degrees of freedom\nMultiple R-squared:  0.542, Adjusted R-squared:  0.5401 \nF-statistic: 297.6 on 2 and 503 DF,  p-value: < 2.2e-16\n\nExercício 9\nQual modelo ficou melhor: mod_simples ou mod_multiplo? Qual critério você utilizou para decidir o melhor?\n\\(\\blacktriangleright\\) Resposta: O mod_multiplo parece ser melhor do que o mod_simples, porque, considerando o R2 ajustado, o R2 ajustado do mod_multiplo (0,5401) é maior do que o R2 ajustado do mod_simples (0,4825). Além disso, a variável crim é significativa (\\(p\\)-valor < 0,001) para explicar a variablidade presente na média do preço mediano das habitações, considerando um nível de significância de 5%.\nPor outro lado, pelos resíduos, ambos os modelos tem problemas com em relação a normalidade dos resíduos e com uma possível relação não linear entre a variável resposta e as variáveis explicativas. O que indica que o modelo mod_multiplo pode ser melhorado.\n\n\n# Resíduo modelo múltiplo\nplot(mod_multiplo)\n\n\n\n\n\n\n\nExercício 10\nAjuste um modelo mod_completo para medv explicado por todas as demais colunas. DICA: na fórmula medv ~ ., o ponto significa “todas as variáveis, tirando medv”.\nConsulte o summary(mod_completo) em seguida.\n\n\nmod_completo <- lm(medv ~ ., data=Boston)\nsummary(mod_completo)\n\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nQual modelo ficou melhor: mod_simples, mod_multiplo ou mod_completo?\n\\(\\blacktriangleright\\) Resposta: Novamente considerando o R2 ajustado, o modelo mais adequado entre os três modelos é o mod_completo, pois tem o R2 ajustado é igual a 0,7338; que é maior do que o R2 ajustados dos demais modelos. Além disso, as variáveis explicativas, exceto indus e age, foram signifitivas ao nível de significância de 5%.\nEm relação aos resíduos, o modelo completo tem o mesmo problema dos outros dois modelos. Nesse caso, o modelo completo também pode ser melhorado.\n\n\n# Resíduo modelo completo\nplot(mod_completo)\n\n\n\n\nO valor estimado para o termo rm variou entre os três modelos? Por qual razão você acha que isso aconteceu?\n\\(\\blacktriangleright\\) Resposta: Sim, a estimativa para o termo rm variou devido a inclusão de variáveis de explicativas no modelo.\n\n\n\n",
    "preview": "posts/2021-02-04-curso-r-regresso-linear-br-exerccios-rlsm/curso-r-regresso-linear-br-exerccios-rlsm_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-02-05T15:56:13-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-05-tcc/",
    "title": "TCC",
    "description": "Resolução do TCC do curso de Regressão Linear com R de janeiro de 2021.",
    "author": [
      {
        "name": "Ricardo Feliz Okamoto",
        "url": "https://www.linkedin.com/in/ricardo-feliz-okamoto-a20344171/"
      }
    ],
    "date": "2021-01-25",
    "categories": [],
    "contents": "\nIntrodução\nA eficiência dos carros é uma das principais características que a indústria automobilística tenta optimizar. Melhorar a eficiência de um carro significa aumentar a quantidade de quilômetros que os carros conseguem rodar consumindo menos combustível. Não só para a indústria automobilística esse tema tem importância, como também para qualquer cidadão que esteja preocupado em gastar menos (afinal de contas, mais quilômetros rodados com menos combustível significa uma conta menor no fim do mês de gasolina), e também para qualquer pessoa com consciência ambiental, que deseja diminuir a quantidade de combustíveis fósseis que são queimados por dia.\nDefinição do problema\nDada a relevância de se estudar este problema, é que eu me guio pela indagção de quais características do carro explicam sua a eficiência (milhas por galão de combustível)?\nDescrição básica da origem e da coleta dos dados\nPara estudar isso, utilizarei a base de dados mtcars. Essa base inclui 32 linhas e 11 colunas. Cada observação é um modelo de carro diferente; e cada coluna é uma característica desse carro. Ao todo, portanto, temos 11 características de 32 modelos de carro para comparar.\nA eficiência está representada nesta base de dados pela coluna mpg, que é a quantidade de milhas rodadas por galão de combustível (miles per galon).\nHipótese do estudo\nMinha hipótese é a de que as seguintes variáveis são relevantes para se explicar a eficiciência dos carros:\ncyl;\nhp;\nwt;\nvs;\nam;\ngear;\ncarb.\nSumários das variáveis (univariadas)\nVariável dependente\n\nShow code\nggplot(mtcars, aes(mpg)) +\n  geom_histogram(fill = \"steelblue\") +\n  geom_vline(aes(xintercept=mean(mpg)),\n            color=\"blue\", linetype=\"dashed\", size=1)\n\n\n\n\nA começar pela variável de interesse, mpg, observamos a seguinte distribuição dos modelos de carro por eficiência. A média de eficiência é de aproximadamente 20 mpg. Temos 18 modelos de carro abaixo da média e 14 modelos acima dela, sendo que o modelo com a pior eficiência roda apenas 10.40 milhas por galão, enquanto o modelo mais eficiente roda mais que o triplo disso, com 33.90 milhas por galão.\n\nShow code\nsummary(mtcars$mpg)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\nVariáveis explicativas\nQuanto às variáveis explicativas, temos os seguintes gráficos.\n\nShow code\nggplot(mtcars, aes(cyl)) +\n  geom_histogram(fill = \"steelblue\") \n\n\n\n\nOs cilindros são onde o combustível é queimado. Há apenas três tipos de carros e cilindros: carros com 4 cilindros, 6 cilindros ou 8 cilindros. O que vemos é que a maioria dos carros possui 8 cilindros, seguido de carros com 4 cilindros e, em terceiro lugar, carros com 6 cilindros. Essa característica se relaciona com a eficiência porque quanto mais cilindros existem, maior é a queima de combustível e, portanto, maior é a geração de poder para o carro.\n\nShow code\nggplot(mtcars, aes(hp)) +\n  geom_histogram(fill = \"steelblue\") +\n  geom_vline(aes(xintercept=mean(hp)),\n            color=\"blue\", linetype=\"dashed\", size=1) +\n    geom_vline(aes(xintercept=median(hp)),\n            color=\"red\", linetype=\"dashed\", size=1)\n\n\n\n\nQuanto ao gross horsepower (hp), essa característica diz respeito aos cavalos do carro. De forma genérica, o horsepower é uma indicação do quanto que o veículo consegue se mover sozinho. Quanto mais cavalos, mais rápido o carro consegue ser. Essa característica se relaciona com a eficiência porque carros com menos horsepower necessitam de mais energia para se movimentarem e, do contrário, carros com mais horsepower necessitam de menos energia para se movimentarem. Dito de outra maneira, quanto maior o horsepower, maior é a eficicência, porque menor é o gasto energético.\nVemos que a distribuição do horsepower é assimétrica para a direita (right skewed) ao compararmos a média (azul) com a mediana (vermelho).\n\nShow code\nggplot(mtcars, aes(wt)) +\n  geom_histogram(fill = \"steelblue\") +\n  geom_vline(aes(xintercept=mean(wt)),\n            color=\"blue\", linetype=\"dashed\", size=1) +\n    geom_vline(aes(xintercept=median(wt)),\n            color=\"red\", linetype=\"dashed\", size=1) +\n  xlab(\"wt \\n (1000 lbs)\")\n\n\n\n\nOutra variável de interesse é o peso do carro. Quanto mais pesado é um caro, espera-se que menos eficiente ele seja.\nO que vemos desse dado é uma grande concentração de valores que giram entorno da média de aproxidamente 3200 libras.\n\nShow code\nggplot(mtcars, aes(vs)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(name = \"Engine \\n (0 = V-shaped, 1 = straight)\", breaks = c(0,1))\n\n\n\n\nA seguir, temos o tipo de motor. Essa variável é binária, ela assume apenas dois valores: ou o motoro é V-shaped, ou ele é straight. Na base de dados, essa característica está representada na coluna vs. Esperamos que o tipo de motor influencie na eficiência, porque é justamente no motor em que o consumo de combustível ocorre.\n\nShow code\nggplot(mtcars, aes(am)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(name = \"Transmission \\n (0 = Automatic, 1 = Manual)\", breaks = c(0,1)) \n\n\n\n\nOutra característica que esperamos que se relacione com a eficiência é o tipo de transmissão, se é manual (1) ou automático (0). Vemos que existem nessa base de dados mais carros automáticos do que manuais.\n\nShow code\nggplot(mtcars, aes(gear)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(breaks = c(3,4,5)) \n\n\n\n\nAlém disso, temos a quantidade de marchas que um carro possui. Existem carros apenas de 3, 4 ou 5 marchas. Pensamos que a marcha se relaciona com a eficiciência porque ela controla a quantidade de poder disponível do motor.\n\nShow code\nggplot(mtcars, aes(carb)) +\n  geom_histogram(fill = \"steelblue\") +\n  scale_x_continuous(breaks=c(1:8))\n\n\n\n\nPor fim, existe a quantidade de carburadores por carro. Os carburadores são o dispositivo dos carros que misturam ar e combustível para combustões internas. Espera-se que essa variável também se relacione com a eficiência do carro.\nGráficos de duas variáveis\n\nShow code\np_cyl <- ggplot(mtcars, aes(cyl, mpg)) +\n  geom_point()\n\np_hp <- ggplot(mtcars, aes(hp, mpg)) +\n  geom_point()\n\np_vs <- ggplot(mtcars, aes(vs, mpg)) +\n  geom_point()\n\np_am <- ggplot(mtcars, aes(am, mpg)) +\n  geom_point()\n\np_gear <- ggplot(mtcars, aes(gear, mpg)) +\n  geom_point()\n\np_carb <- ggplot(mtcars, aes(carb, mpg)) +\n  geom_point()\n\ng1 <- gridExtra::grid.arrange(\n  p_cyl, \n  p_hp, \n  nrow = 2\n)\n\n\nShow code\ng2 <- gridExtra::grid.arrange(\n  p_vs, \n  p_am, \n  nrow = 2\n)\n\n\nShow code\ng3 <- gridExtra::grid.arrange(\n  p_gear, \n  p_carb,\n  nrow = 2\n)\n\n\n\n\nModelagem\nBaseline model\nA fórmula básica, da qual partiremos, é a seguinte:\n\\[\n\\operatorname{baseline\\ model:\\ mpg} = \\beta_{0} + \\beta_{1}(\\operatorname{cyl}) + \\beta_{2}(\\operatorname{hp}) + + \\beta_{3}(\\operatorname{wt}) + \\beta_{4}(\\operatorname{vs}) + \\beta_{5}(\\operatorname{am}) + \\beta_{6}(\\operatorname{gear}) + \\beta_{7}(\\operatorname{carb}) + \\epsilon\n\\] Essa equação de regressão ainda não representa a especificação final do modelo. É possível que algumas dessas variáveis não possuem efeito estatisticamente relevante sobre a variável de interesse mpg. Ou ainda pode ser que haja multicolinearidade entre algumas variáveis, ou algum tipo de interação, ou relação polinomial. Então esta não é a versão ajustada do modelo, mas é o modelo inicial, o qual chamarei de “baseline model”.\nQuando rodamos a regressão, a nossa fórmula fica especificada com os seguintes coeficientes:\n\\[\n\\operatorname{baseline\\ model:\\ mpg} = 30.25 - 0.38(\\operatorname{cyl}) - 0.02(\\operatorname{hp}) - 2.18(\\operatorname{wt}) + 97(\\operatorname{vs}) + 2.11(\\operatorname{am}) + 0.66(\\operatorname{gear}) - 0.62(\\operatorname{carb}) + \\epsilon\n\\] Esses parâmetros ficam melhor resumidos na tabela a seguir:\n\nShow code\nbaseline <- lm(mpg~cyl + hp + wt + vs + am + gear + carb, mtcars)\nsummary(baseline)\n\n\n\nCall:\nlm(formula = mpg ~ cyl + hp + wt + vs + am + gear + carb, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2242 -1.4538 -0.4293  1.4548  5.2956 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 30.25034    8.61471   3.511  0.00179 **\ncyl         -0.38285    0.87852  -0.436  0.66688   \nhp          -0.01859    0.01710  -1.088  0.28762   \nwt          -2.18465    1.02244  -2.137  0.04302 * \nvs           0.96917    1.85506   0.522  0.60615   \nam           2.11755    1.88907   1.121  0.27340   \ngear         0.65975    1.43338   0.460  0.64946   \ncarb        -0.62289    0.58164  -1.071  0.29485   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.578 on 24 degrees of freedom\nMultiple R-squared:  0.8583,    Adjusted R-squared:  0.817 \nF-statistic: 20.77 on 7 and 24 DF,  p-value: 9.689e-09\n\nOlhando para esse teste, conseguimos ver que apenas dois coeficientes possuem signficância estatística: o intercepto (B0) e o coeficiente relativo ao peso do carro (B2). O teste de hipótese relativo ao B0 indica que com 99.99% de certeza conseguimos rejeitar a hipótese nula de que o intercepto é igual a 0. Já o teste de hipótese relativo ao B2 indica que com 95% de certza conseguimos rejeitar a hipótese nula de que a relação entre aquele coeficiente com a variável de interesse (mpg) é 0. Todos os demais coeficientes não conseguem ter a hipótese nula rejeitada, isto é, não é possível dizer que a relação dessas variáveis explicativas com a variável de resposta seja diferente de 0.\nA partir disso, poderíamos ser levados a concluir que a única variável que explica a eficiência do motor é o peso do carro. Mas temos de tomar cuidado com essa conclusão. Ela é muito precipitada. O que pode estar acontecendo é que pode haver multicolinearidade ou interação entre as variáveis. Nesses casos, o efeito de uma variável sobre Y estaria sendo “roubado” e, por isso, ele fica invisível e não conseguimos rejeitar a hipótese nula de que o coeficiente é diferente de 0.\nMulticolinearidade e Interações\nAnálise de cyl e hp\nPara tentar desmistificar isso, precisamos avaliar as variáveis individualmente. Quando rodamos um modelo para cada variável, a história é outra. Todos os coeficientes se tornam estatisticamente significantes.\n\nShow code\ncyl_model <- lm(mpg~cyl, mtcars)\nhp_model <- lm(mpg~hp, mtcars)\nwt_model <- lm(mpg~wt, mtcars)\nvs_model <- lm(mpg~vs, mtcars)\nam_model <- lm(mpg~am, mtcars)\ngear_model <- lm(mpg~gear, mtcars)\ncarb_model <- lm(mpg~carb, mtcars)\n\njtools::export_summs(cyl_model, hp_model, wt_model, vs_model, am_model, gear_model, carb_model, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 20.09 20.09 16.62 17.15\npt) *** *** *** *** ***\n(0.57)   (0.68)   (0.54)   (1.08)   (1.12)  \n         \ncyl -5.14                                \n***\n(0.58)                                  \n \nhp         -4.68                        \n***\n        (0.69)                          \n \nwt                 -5.23                \n***\n                (0.55)                  \n \nvs                         7.94 ***        \n                        (1.63)          \n \nam                                 7.24 ***\n                                (1.76)  \n \ngear                                        \n                                       \ncarb                                        \n                                       \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.73     0.60     0.75     0.44     0.36    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5, Model 6, Model 7\n6/8 columns shown.\n\nComparando, então, esses resultados com a equação que inclui todas as variáveis, podemos levantar fortes suspeitas de que existe multicolinearidade no nosso baseline model. Para diagnosticar a multicolinearidade, podemos usar o VIF.\n\nShow code\ncar::vif(baseline)\n\n\n      cyl        hp        wt        vs        am      gear      carb \n11.480450  6.409021  4.667601  4.076992  4.143941  5.216024  4.116132 \n\nO VIF nos dá alguns valores a que temos de nos atentar. Primeiro, observamos que o VIF do cyl é o maior de todos. Ele está acima de 5. Acima de 5 todos VIF é problemático. Outra variável problemática é hp. Além disso, há gear. Entretanto, como ele está apenas um pouco acima de 5, vou deixá-lo para uma análise posterior. O que eu vou testar agora é o que acontece com as demais variáveis ao retirar o cyl e hp.\n\nShow code\nbaseline_sem_cyl_e_hp <- lm(mpg~wt + vs + am + gear + carb, mtcars)\ncar::vif(baseline_sem_cyl_e_hp)\n\n\n      wt       vs       am     gear     carb \n4.395138 2.090715 3.881481 4.510498 3.160047 \n\nDe fato, o VIF das variáveis diminuem. Agora não temos nenhum VIF que passe de 5. Entretanto, acho que seria cauteloso nos determos melhor em wt, gear e am, pois seus valores são os mais próximos de 5.\nComecemos pela análise de wt, rodando separadamente um modelo com wt e apenas uma outra variável.\nAnálise de wt\n\nShow code\nwt1 <- lm(mpg~wt+vs, mtcars)\nwt2 <- lm(mpg~wt+am, mtcars)\nwt3 <- lm(mpg~wt+gear, mtcars)\nwt4 <- lm(mpg~wt+carb, mtcars)\n\njtools::export_summs(wt_model, wt1, wt2, wt3, wt4, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 18.71 20.10 20.09 20.09\npt) *** *** *** *** ***\n(0.54)   (0.72)   (0.83)   (0.55)   (0.50)  \n         \nwt -5.23 -4.35 -5.24 -5.37 -4.66\n*** *** *** *** ***\n(0.55)   (0.60)   (0.77)   (0.68)   (0.56)  \n         \nvs         3.15                           \n        (1.19)                          \n \nam                 -0.02                   \n \n                (1.55)                  \n \ngear                         -0.24           \n \n                        (0.68)          \n \ncarb                                 -1.33  \n                                (0.56)  \n \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.75     0.80     0.75     0.75     0.79    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5\n\nO que nós observamos com essa tabela de regressão é que nenhuma variável causa um distúrbio muito grande no coeficiente de wt. Se houvesse multicolinearidade entre wt e outra variável, então o desvio padrão do coeficiente iria disparar, o valor do coeficiente mudaria bruscamente, a significância estatística diminuiria e o R2 iria aumentar muito também. Mas o que vemos, na verdade, é uma relativa estabilidade em todos esses de wt para cada modelo. É “relativa” porque os valores não são idênticos, mas tampouco são discrepantes. Rodando um VIF para cada um dos modelos de regressão múltipla, observamos que todos os valores VIFs estão abaixo de 2.\nPassemo a análise para gear.\nAnálise de gear\n\nShow code\ngear1 <- lm(mpg~gear+vs, mtcars)\ngear2 <- lm(mpg~gear+am, mtcars)\ngear3 <- lm(mpg~gear+wt, mtcars)\ngear4 <- lm(mpg~gear+carb, mtcars)\n\njtools::export_summs(gear_model, gear1, gear2, gear3, gear4, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 17.00 17.19 20.09 20.09\npt) *** *** *** *** ***\n(0.95)   (0.98)   (1.49)   (0.55)   (0.57)  \n         \ngear 2.89   2.16   0.06     -0.24    4.11 ***\n \n(0.97)   (0.76)   (1.47)   (0.68)   (0.60)  \n         \nvs         7.06 ***                        \n        (1.50)                          \n \nam                 7.14                   \n                (2.95)                  \n \nwt                         -5.37        **\n                        (0.68)          \n \ncarb                                 -4.45\n***\n                                (0.60)  \n \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.23     0.56     0.36     0.75     0.73    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5\n\nRepetindo o mesmo teste, mas agora com o foco na variável gear, nós observamos um ponto interessante: a adição da variável wt faz com que gear perca totalmente a sua significância estatística. Lembrando da tabela anterior (sobre a mudança do coeficiente wt com a adição de outras variáveis), vemos que gear não influencia o valor de wt, mas que o invereso acontece. Podemos, então, avaliar se existe alguma interação entre wt e gear.\n\nShow code\ninteracao_gear_wt <- lm(mpg~gear*wt, mtcars)\n\np1 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = gear)) +\n  scale_color_gradient2(midpoint=4, low=\"#c19615\", mid=\"#1594c2\" ,high=\"#16c298\", space=\"Lab\") +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  theme(legend.position = 'bottom')\n\np2 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = gear)) +\n  scale_color_gradient2(midpoint=4, low=\"#c19615\", mid=\"#1594c2\" ,high=\"#16c298\", space=\"Lab\") +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  facet_wrap(~ gear, ncol=2, scales=\"free\") +\n  guides(colour = \"none\")\n\ngridExtra::grid.arrange(p1, p2, widths=c(1.5,2))\n\n\n\n\nVemos, por esse gráfico, que para cada diferente gear o efeito de wt sobre y não muda, a relação sempre é negativa.\nLevando tudo isso em consideração, podemos concluir que gear e wt não possuem nem uma relação multicolinear, nem realizam uma interação entre si. A única obseração que nos sobra é que todo o efeito que gear desempenha sobre mpg já está sendo captado por wt. Devemos, então, excluir gear do nosso modelo, a fim de ter um modelo mais parcimonioso.\nFalta agora apenas a análise de am.\nAnálise de am\n\nShow code\nam1 <- lm(mpg~am+vs, mtcars)\nam2 <- lm(mpg~am+gear, mtcars)\nam3 <- lm(mpg~am+wt, mtcars)\nam4 <- lm(mpg~am+carb, mtcars)\n\njtools::export_summs(am_model, am1, am2, am3, am4, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 17.15 14.59 17.19 20.10 16.98\npt) *** *** *** *** ***\n(1.12)   (0.93)   (1.49)   (0.83)   (0.78)  \n         \nam 7.24 *** 6.07 *** 7.14    -0.02    7.65 **\n \n(1.76)   (1.27)   (2.95)   (1.55)   (1.22)  \n         \nvs         6.93 ***                        \n        (1.26)                          \n \ngear                 0.06                    \n                (1.47)                  \n \nwt                         -5.24        \n***\n                        (0.77)          \n \ncarb                                 -3.54\n***\n                                (0.61)  \n \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.36     0.69     0.36     0.75     0.70    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. *** p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5\n\nO que observamos é que am, igual ao que ocorre com gear perde toda a sua significância estatística com a adição de wt. Entretanto, o inverso não é verdadeiro: am não retira o efeito de wt. Vamos então realizar a mesma análise de interação am com wt\n\nShow code\np3 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = am)) +\n  #scale_color_gradient2(midpoint=4, low=\"#c19615\", mid=\"#1594c2\" ,high=\"#16c298\", space=\"Lab\") +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  theme(legend.position = 'bottom')\n\n\np4 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point(aes(color = am)) +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"#a3a3a3\") +\n  facet_wrap(~ am, ncol=2, scales=\"free\") +\n  guides(colour = \"none\")\n\n\ngridExtra::grid.arrange(p3, p4, widths=c(1.5,2))\n\n\n\n\nNovamente, o que observamos é que am não influencia o resultado de wt. Não há nem multicolineridade, nem interação. A melhor solução, portanto, é retirar am do modelo.\nAnálise de vs e carb\nAté aqui vimos que cyl e hp tinham multicolinearidade com as demais variáveis porque possuíam VIFs extremamente altos. Então excluímos eles do modelo. Vimos também que os efeitos de gear e de am sobre mpg eram absorvidos por wt. Então também excluímos eles, a fim de deixar o modelo mais parcimonioso.\nDas 7 variáveis inciais, portanto, sobraram 3: wt, vs e carb. Já análisamos wt. Falta apenas vs e carb.\nSe começarmos rodando uma regressão com as três variáveis faltantes, observamos que, combinadas com wt, tanto carb quanto vs perdem sua significância estatística.\n\nShow code\na <- lm(mpg~wt + vs + carb, mtcars)\nsummary(a)\n\n\n\nCall:\nlm(formula = mpg ~ wt + vs + carb, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0980 -2.3545  0.1704  1.2852  5.6616 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  34.3808     2.5190  13.648 6.75e-14 ***\nwt           -4.3036     0.6118  -7.035 1.19e-07 ***\nvs            2.3489     1.3062   1.798   0.0829 .  \ncarb         -0.5234     0.3751  -1.395   0.1739    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.735 on 28 degrees of freedom\nMultiple R-squared:  0.8139,    Adjusted R-squared:  0.794 \nF-statistic: 40.83 on 3 and 28 DF,  p-value: 2.349e-10\n\nIsso não indica multicolinearidade porque os VIFs das variáveis são muito baixos.\n\nShow code\ncar::vif(a)\n\n\n      wt       vs     carb \n1.484433 1.795593 1.520735 \n\nAssim, temos que fazer uma análise mais minuciosa sobre o comportamento dos coeficientes ao adicionarmos as variáveis uma a uma.\n\nShow code\nwt1 <- lm(mpg~wt+vs, mtcars)\nwt4 <- lm(mpg~wt+carb, mtcars)\nwt5 <- lm(mpg~vs+carb, mtcars)\n\njtools::export_summs(wt_model, vs_model, carb_model, wt1, wt4, wt5, a, scale=TRUE)\n\n\n─────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4 Model 5\n──────────────────────────────────────────────────────── (Interce 20.09 16.62 20.09 18.71 20.09\npt) *** *** *** *** ***\n(0.54)   (1.08)   (0.90)   (0.72)   (0.50)  \n         \nwt -5.23                 -4.35 -4.66\n*** *** ***\n(0.55)                   (0.60)   (0.56)  \n     \nvs         7.94 ***         3.15 *          \n        (1.63)           (1.19)          \n   \ncarb                 -3.32         -1.33    \n                (0.92)           (0.56)  \n   \n──────────────────────────────────────────────────────── N 32       32       32       32       32      \n         \nR2 0.75     0.44     0.30     0.80     0.79    \n─────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation.  p < 0.001;\n** p < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4, Model 5, Model 6, Model 7\n6/8 columns shown.\n\nO que observamos é que as variáveis vs e carb, sem a presença de wt possuem uma significância estatística alta, a 99,999% (Modelos 1, 2 e 3). Combinadas individualmente com wt, elas ainda mantém sua significância estatística (modelos 4 e 5), mas a 95% de certeza. Em um modelo sem wt, mas com ambas as variáveis vse carb, o que observamos é que carb perde sua significância, enquanto vs se mantém significante a 99% (modelo 6).\nPara continuar a análise, iremos observar o que acontece quando as variáveis interagem entre si.\n\nShow code\nwt6 <- lm(mpg~wt+vs+wt*vs, mtcars)\nwt7 <- lm(mpg~wt+carb+wt*carb, mtcars)\nwt8 <- lm(mpg~carb+vs+carb*vs, mtcars)\n\njtools::export_summs(wt_model, wt6, wt7, wt8, scale=TRUE)\n\n\n────────────────────────────────────────────────────────────────── Model 1 Model 2 Model 3 Model 4\n───────────────────────────────────────────────────── (Intercept 20.09 *** 18.27 *** 19.34 *** 17.06 ***\n)\n(0.54)    (0.69)    (0.53)    (1.19)   \nwt -5.23 *** -3.43 *** -4.81 ***        \n(0.55)    (0.68)    (0.52)           \nvs         2.41            5.37   \n        (1.15)            (2.07)   \nwt:vs         -2.85                   \n        (1.19)                   \ncarb                 -1.16    -0.90    \n                (0.52)    (1.13)   \nwt:carb                 1.81           \n                (0.68)           \ncarb:vs                         -2.45    \n                        (2.21)   \n───────────────────────────────────────────────────── N 32        32        32        32       \nR2 0.75     0.83     0.83     0.51    \n────────────────────────────────────────────────────────────────── All continuous predictors are mean-centered and\nscaled by 1 standard deviation. ** p < 0.001; **\np < 0.01; * p < 0.05.\nColumn names: names, Model 1, Model 2, Model 3, Model 4\n\nO que observamos com as interações é que, quando vs e carb interagem individualmente com wt, todos os coeficientes se mantém estatisticamente relevantes (modelos 2 e 3). Entretanto, quando realizamos uma interação apenas entre essas duas variáveis, carb perde sua significância (modelo 4). Se carb perde a significância quando interage com vs, então vou optar por manter no modelo apenas vs, a fim de garantir um modelo mais parcimonioso.\nConclusão parcial\nCom todas as alterações no modelo, ficamos apenas com duas variáveis no final e uma interação:\n\\[\n\\operatorname{adjusted \\ model:\\ mpg} = \\beta_{0} + \\beta_{1}(\\operatorname{wt}) + \\beta_{2}(\\operatorname{vs}) + \\beta_{3}(\\operatorname{wt*vs}) + \\epsilon\n\\]\nCalculando os coeficientes, ficamos com o seguinte modelo: \\[\n\\operatorname{adjusted \\ model:\\ mpg} = 29.53 - 3.50(\\operatorname{wt}) + 11.77(\\operatorname{vs}) - 2.90(\\operatorname{wt*vs}) + \\epsilon\n\\]\nDiagnóstico do modelo\nPor fim, resta apenas avaliar se o modelo ficou bom ou não.\n\nShow code\nplot(adjusted)\n\n\n\n\nA começar pelo gráfico de resíduos, há duas observações improtantes. Primeiro, os resíduos não ficaram iguais a zero. Isso é bom, uma vez que resíduo 0 significaria um sobreajuste do modelo. Seria tão artificial que seria um modelo ruim. A segunda obseravção importante é que a forma como os resíduos se distribuem não possui nenhum padrão. A distribuição aleatória dos resíduos indica um modelo saudável.\nAlém disso, analisando o gráfico que nos indica a distância de Cook e o efeito alavanca de outliers, o que observamos é que não existem leverage outliers. Os pontos estão bem distantes da região de cook.\nConclusão e discussão\nNo fim, portanto, podemos concluir que a melhor explicação que podemos dar para a eficiência dos carros envolve o peso (wt) e o tipo de motor (vs). Essas variáveis interagem entre si, porque cada tipo de motor possui um peso diferente.\nComo uma de nossas variáveis é binária, o intercepto se torna uma casela de referência. Essa casela indica a eficiência do carro cujo motor é V-shaped e não pesa nada (algo que só é possível em condições de laboratório, quando anulamos a gravidade). Este motor (v-shaped, sem peso) roda 29.53 milhas por galão de combustível. Se mudarmos o motor para um motor straight, então a eficiência aumenta em 11 milhas por galão, em média, ficando, aproximadamente, 41 mpg. Mas isso só se aplica também nas condições ideais sem gravidade, em que o peso permanece 0.\nQuando começamos a considerar a variável de peso, então a interpretação do modelo se modifica ligeiramente, por causa da interação. No caso do motor V-shaped, para cada 1000 libras que o carro ganha, a sua eficiência diminui em 3.5 milhas por galão. Para o motor straight, a cada 1000 libras que o carro ganha, então a eficiência do motor diminui em média 5.9 milhas por galão.\n\n\n\n",
    "preview": "posts/2021-02-05-tcc/tcc_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-02-05T15:56:30-03:00",
    "input_file": {}
  }
]
